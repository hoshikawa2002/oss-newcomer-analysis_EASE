[
  {
    "pr_number": 13943,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 12789,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 13943,
      "title": "Raise exception instead of assert benchmark_args_utils.py",
      "body": "# What does this PR do?\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes #12789 \r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/master/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/master/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/master/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- albert, bert, xlm: @LysandreJik\r\n- blenderbot, bart, marian, pegasus, encoderdecoder,  t5: @patrickvonplaten, @patil-suraj\r\n- longformer, reformer, transfoxl, xlnet: @patrickvonplaten\r\n- fsmt: @stas00\r\n- funnel: @sgugger\r\n- gpt2: @patrickvonplaten, @LysandreJik\r\n- rag: @patrickvonplaten, @lhoestq\r\n- tensorflow: @LysandreJik\r\n\r\nLibrary:\r\n\r\n- benchmarks: @patrickvonplaten\r\n- deepspeed: @stas00\r\n- ray/raytune: @richardliaw, @amogkam\r\n- text generation: @patrickvonplaten\r\n- tokenizers: @n1t0, @LysandreJik\r\n- trainer: @sgugger\r\n- pipelines: @LysandreJik\r\n\r\nDocumentation: @sgugger\r\n\r\nHF projects:\r\n\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nExamples:\r\n\r\n- maintained examples (not research project or legacy): @sgugger, @patil-suraj\r\n- research_projects/bert-loses-patience: @JetRunner\r\n- research_projects/distillation: @VictorSanh\r\n\r\n -->\r\n",
      "body_length": 677,
      "created_at": "2021-10-09T14:12:28Z",
      "updated_at": "2021-10-10T00:14:50Z",
      "closed_at": "2021-10-10T00:14:14Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 2,
      "deletions": 3,
      "files_changed": 1,
      "commits_count": 1,
      "review_count": 0,
      "comment_count": 1,
      "pr_size": 5,
      "avg_commit_msg_length": 33.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {},
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\n\r\n\r\n\r\n\r\nFixes #12789 \r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/master/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/master/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/master/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.",
      "body_cleaned_length": 1065,
      "template_removed_length": 2087,
      "template_reduction_percentage": 66.21192893401016,
      "author_type": "User"
    },
    "username": "LuisFerTR"
  },
  {
    "pr_number": 15037,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 14642,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 15037,
      "title": "Wrap Roberta integration test forward passes with torch.no_grad()",
      "body": "# What does this PR do?\r\nThis PR wraps forward passes in Roberta integration tests with torch.no_grad(). See issue #14642 \r\n\r\nFixes #14642 \r\n[Issue link](https://github.com/huggingface/transformers/issues/14642)\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/master/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/master/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/master/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n@NielsRogge @LysandreJik @sgugger \r\n",
      "body_length": 1117,
      "created_at": "2022-01-05T02:01:01Z",
      "merged_at": "2022-01-06T13:48:50Z",
      "merged": true,
      "time_to_merge_hours": 35.79694444444444,
      "state": "MERGED",
      "additions": 6,
      "deletions": 3,
      "files_changed": 1,
      "commits_count": 1,
      "review_count": 1,
      "comment_count": 0,
      "commit_messages": [
        "wrapped forward passes in torch.no_grad()"
      ],
      "avg_commit_msg_length": 41.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": true,
      "has_docs": false,
      "test_files": [
        "tests/test_modeling_roberta.py"
      ],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\nThis PR wraps forward passes in Roberta integration tests with torch.no_grad(). See issue #14642 \r\n\r\nFixes #14642 \r\n[Issue link](https://github.com/huggingface/transformers/issues/14642)\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/master/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/master/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/master/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n@NielsRogge @LysandreJik @sgugger",
      "body_cleaned_length": 1114,
      "template_removed_length": 3,
      "template_reduction_percentage": 0.26857654431512984,
      "author_type": "User"
    },
    "username": "mattchurgin"
  },
  {
    "pr_number": 15795,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 15739,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 15795,
      "title": "Support PEP 563 for HfArgumentParser",
      "body": "# What does this PR do?\r\n\r\nFixes #15739, support for [PEP 563](https://www.python.org/dev/peps/pep-0563/) is added, making it possible to write `from __future__ import annotations` in the file of dataclasses for `HfArgumentParser`. But this will not be available for Python with a version lower than 3.7, thus adding `from __future__ import annotations` in the test is currently infeasible because `__future__` imports should always occur at the beginning of the file. Instead, I write a test case with string literal annotations.\r\n\r\n## Before submitting\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/master/CONTRIBUTING.md#start-contributing-pull-requests), Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes?\r\n- [x] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n@LysandreJik \r\n",
      "body_length": 1037,
      "created_at": "2022-02-23T18:01:27Z",
      "merged_at": "2022-03-17T17:51:38Z",
      "merged": true,
      "time_to_merge_hours": 527.8363888888889,
      "state": "MERGED",
      "additions": 109,
      "deletions": 82,
      "files_changed": 2,
      "commits_count": 8,
      "review_count": 2,
      "comment_count": 9,
      "commit_messages": [
        "Support PEP 563 for HfArgumentParser",
        "Fix issues for Python 3.6",
        "Add test for string literal annotation for HfArgumentParser",
        "Remove wrong comment",
        "Fix typo",
        "Improve code readability\n\nCo-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>",
        "Use `isinstance` to compare types to pass quality check",
        "Fix style"
      ],
      "avg_commit_msg_length": 39.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": true,
      "has_docs": false,
      "test_files": [
        "tests/utils/test_hf_argparser.py"
      ],
      "doc_files": [],
      "file_types": {
        "py": 2
      },
      "review_states": {
        "COMMENTED": 1,
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nFixes #15739, support for [PEP 563](https://www.python.org/dev/peps/pep-0563/) is added, making it possible to write `from __future__ import annotations` in the file of dataclasses for `HfArgumentParser`. But this will not be available for Python with a version lower than 3.7, thus adding `from __future__ import annotations` in the test is currently infeasible because `__future__` imports should always occur at the beginning of the file. Instead, I write a test case with string literal annotations.\r\n\r\n## Before submitting\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/master/CONTRIBUTING.md#start-contributing-pull-requests), Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes?\r\n- [x] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n@LysandreJik",
      "body_cleaned_length": 1034,
      "template_removed_length": 3,
      "template_reduction_percentage": 0.28929604628736744,
      "author_type": "User"
    },
    "username": "function2-llx"
  },
  {
    "pr_number": 15972,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 15971,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 15972,
      "title": "Make `pos` optional in `PerceiverAudioPreprocessor` to avoid crashing `PerceiverModel` operation",
      "body": "Updates `PerceiverAudioPreprocessor` `forward()` implementation to match most other preprocessors / postprocessors.\r\n\r\nFixes #15971.\r\n",
      "body_length": 134,
      "created_at": "2022-03-07T20:27:59Z",
      "merged_at": "2022-03-09T14:48:53Z",
      "merged": true,
      "time_to_merge_hours": 42.348333333333336,
      "state": "MERGED",
      "additions": 1,
      "deletions": 1,
      "files_changed": 1,
      "commits_count": 1,
      "review_count": 1,
      "comment_count": 2,
      "commit_messages": [
        "Make `pos` optional to avoid crashing `PerceiverModel` operation\n\nUpdates `PerceiverAudioPreprocessor` `forward()` implementation to match most other preprocessors / postprocessors"
      ],
      "avg_commit_msg_length": 180.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "Updates `PerceiverAudioPreprocessor` `forward()` implementation to match most other preprocessors / postprocessors.\r\n\r\nFixes #15971.",
      "body_cleaned_length": 132,
      "template_removed_length": 2,
      "template_reduction_percentage": 1.4925373134328357,
      "author_type": "User"
    },
    "username": "basilevh"
  },
  {
    "pr_number": 17082,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 15735,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 17082,
      "title": "Fix DeBERTa token_type_ids",
      "body": "# What does this PR do?\r\n\r\nThis PR fixes #15735. It changes the behavior of `DebertaTokenizer` and `DebertaTokenizerFast` when passing pair inputs. Before, the token type IDs were all `0`. This PR changes this so that the `token_type_id`s for the tokens of the second sentence are `1`. \r\n\r\nIt also adds a test case to test this behavior (`DebertaTokenizationTest.test_token_type_ids`). Failed before, passes now.\r\n\r\n## Before submitting\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case. https://github.com/huggingface/transformers/issues/15735\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [x] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n@LysandreJik?",
      "body_length": 1391,
      "created_at": "2022-05-04T11:51:41Z",
      "merged_at": "2022-05-04T16:23:37Z",
      "merged": true,
      "time_to_merge_hours": 4.532222222222222,
      "state": "MERGED",
      "additions": 10,
      "deletions": 4,
      "files_changed": 4,
      "commits_count": 2,
      "review_count": 2,
      "comment_count": 2,
      "commit_messages": [
        "Add failing test case",
        "Fix type_id creation for slow and fast tokenizer"
      ],
      "avg_commit_msg_length": 34.5,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": true,
      "has_docs": false,
      "test_files": [
        "tests/models/deberta/test_tokenization_deberta.py"
      ],
      "doc_files": [],
      "file_types": {
        "py": 4
      },
      "review_states": {
        "APPROVED": 2
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nThis PR fixes #15735. It changes the behavior of `DebertaTokenizer` and `DebertaTokenizerFast` when passing pair inputs. Before, the token type IDs were all `0`. This PR changes this so that the `token_type_id`s for the tokens of the second sentence are `1`. \r\n\r\nIt also adds a test case to test this behavior (`DebertaTokenizationTest.test_token_type_ids`). Failed before, passes now.\r\n\r\n## Before submitting\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case. https://github.com/huggingface/transformers/issues/15735\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [x] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n@LysandreJik?",
      "body_cleaned_length": 1391,
      "template_removed_length": 0,
      "template_reduction_percentage": 0.0,
      "author_type": "User"
    },
    "username": "deutschmn"
  },
  {
    "pr_number": 17027,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 16308,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 17027,
      "title": "Add XLNet OnnxConfig",
      "body": "# What does this PR do?\r\n\r\n1. Add XLNet OnnxConfig to make this model available for conversion.\r\n2. In order to make the onnx export work, I had to remove the `**kwargs` argument in the `forward` function of the `XLNet` models. Seems like the `**kwargs` was on deprecation warning anyway and removing it didn't break any tests. Here is the reproduction and the error log of the OnnxExport if the `**kwargs` argument doesn't get removed.\r\n\r\n\r\n```\r\nfrom typing import Mapping, OrderedDict \r\nfrom pathlib import Path\r\n\r\nfrom transformers.onnx import OnnxConfig, export\r\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\r\n\r\nclass XLNetOnnxConfig(OnnxConfig):\r\n    @property\r\n    def inputs(self) -> Mapping[str, Mapping[int, str]]:\r\n        if self.task == \"multiple-choice\":\r\n            dynamic_axis = {0: \"batch\", 1: \"choice\", 2: \"sequence\"}\r\n        else:\r\n            dynamic_axis = {0: \"batch\", 1: \"sequence\"}\r\n        return OrderedDict(\r\n            [\r\n                (\"input_ids\", dynamic_axis),\r\n                (\"attention_mask\", dynamic_axis),\r\n                (\"token_type_ids\", dynamic_axis)\r\n            ]\r\n        )\r\n \r\nconfig = AutoConfig.from_pretrained(\"xlnet-base-cased\")\r\nonnx_config = XLNetOnnxConfig(config, task=\"sequence-classification\")\r\n\r\nonnx_path = Path(\"model.onnx\")\r\nbase_model = AutoModel.from_pretrained(\"xlnet-base-cased\")\r\ntokenizer = AutoTokenizer.from_pretrained(\"xlnet-base-cased\")\r\n\r\nonnx_inputs, onnx_outputs = export(tokenizer, base_model, onnx_config, onnx_config.default_onnx_opset, onnx_path)\r\n```\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\nInput In [1], in <module>\r\n     28 base_model = AutoModel.from_pretrained(\"xlnet-base-cased\")\r\n     29 tokenizer = AutoTokenizer.from_pretrained(\"xlnet-base-cased\")\r\n---> 31 onnx_inputs, onnx_outputs = export(tokenizer, base_model, onnx_config, onnx_config.default_onnx_opset, onnx_path)\r\n\r\nFile /opt/homebrew/lib/python3.9/site-packages/transformers/onnx/convert.py:116, in export(tokenizer, model, config, opset, output)\r\n    113     config.patch_ops()\r\n    115     # export can works with named args but the dict containing named args as to be last element of the args tuple\r\n--> 116     export(\r\n    117         model,\r\n    118         (model_inputs,),\r\n    119         f=output.as_posix(),\r\n    120         input_names=list(config.inputs.keys()),\r\n    121         output_names=onnx_outputs,\r\n    122         dynamic_axes={name: axes for name, axes in chain(config.inputs.items(), config.outputs.items())},\r\n    123         do_constant_folding=True,\r\n    124         use_external_data_format=config.use_external_data_format(model.num_parameters()),\r\n    125         enable_onnx_checker=True,\r\n    126         opset_version=opset,\r\n    127     )\r\n    129     config.restore_ops()\r\n    131 return matched_inputs, onnx_outputs\r\n\r\nFile /opt/homebrew/lib/python3.9/site-packages/torch/onnx/__init__.py:316, in export(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\r\n     38 r\"\"\"\r\n     39 Exports a model into ONNX format. If ``model`` is not a\r\n     40 :class:`torch.jit.ScriptModule` nor a :class:`torch.jit.ScriptFunction`, this runs\r\n   (...)\r\n    312     model to the file ``f`` even if this is raised.\r\n    313 \"\"\"\r\n    315 from torch.onnx import utils\r\n--> 316 return utils.export(model, args, f, export_params, verbose, training,\r\n    317                     input_names, output_names, operator_export_type, opset_version,\r\n    318                     _retain_param_name, do_constant_folding, example_outputs,\r\n    319                     strip_doc_string, dynamic_axes, keep_initializers_as_inputs,\r\n    320                     custom_opsets, enable_onnx_checker, use_external_data_format)\r\n\r\nFile /opt/homebrew/lib/python3.9/site-packages/torch/onnx/utils.py:107, in export(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\r\n    102 if use_external_data_format is not None:\r\n    103     warnings.warn(\"`use_external_data_format' is deprecated and ignored. Will be removed in next \"\r\n    104                   \"PyTorch release. The code will work as it is False if models are not larger than 2GB, \"\r\n    105                   \"Otherwise set to False because of size limits imposed by Protocol Buffers.\")\r\n--> 107 _export(model, args, f, export_params, verbose, training, input_names, output_names,\r\n    108         operator_export_type=operator_export_type, opset_version=opset_version,\r\n    109         do_constant_folding=do_constant_folding, example_outputs=example_outputs,\r\n    110         dynamic_axes=dynamic_axes, keep_initializers_as_inputs=keep_initializers_as_inputs,\r\n    111         custom_opsets=custom_opsets, use_external_data_format=use_external_data_format)\r\n\r\nFile /opt/homebrew/lib/python3.9/site-packages/torch/onnx/utils.py:724, in _export(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, use_external_data_format, onnx_shape_inference)\r\n    720     dynamic_axes = {}\r\n    721 _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\r\n    723 graph, params_dict, torch_out = \\\r\n--> 724     _model_to_graph(model, args, verbose, input_names,\r\n    725                     output_names, operator_export_type,\r\n    726                     example_outputs, val_do_constant_folding,\r\n    727                     fixed_batch_size=fixed_batch_size,\r\n    728                     training=training,\r\n    729                     dynamic_axes=dynamic_axes)\r\n    731 # TODO: Don't allocate a in-memory string for the protobuf\r\n    732 defer_weight_export = export_type is not ExportTypes.PROTOBUF_FILE\r\n\r\nFile /opt/homebrew/lib/python3.9/site-packages/torch/onnx/utils.py:493, in _model_to_graph(model, args, verbose, input_names, output_names, operator_export_type, example_outputs, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\r\n    490 if isinstance(args, (torch.Tensor, int, float, bool)):\r\n    491     args = (args, )\r\n--> 493 graph, params, torch_out, module = _create_jit_graph(model, args)\r\n    495 params_dict = _get_named_param_dict(graph, params)\r\n    497 graph = _optimize_graph(graph, operator_export_type,\r\n    498                         _disable_torch_constant_prop=_disable_torch_constant_prop,\r\n    499                         fixed_batch_size=fixed_batch_size, params_dict=params_dict,\r\n    500                         dynamic_axes=dynamic_axes, input_names=input_names,\r\n    501                         module=module)\r\n\r\nFile /opt/homebrew/lib/python3.9/site-packages/torch/onnx/utils.py:437, in _create_jit_graph(model, args)\r\n    435     return graph, params, torch_out, None\r\n    436 else:\r\n--> 437     graph, torch_out = _trace_and_get_graph_from_model(model, args)\r\n    438     state_dict = _unique_state_dict(model)\r\n    439     params = list(state_dict.values())\r\n\r\nFile /opt/homebrew/lib/python3.9/site-packages/torch/onnx/utils.py:388, in _trace_and_get_graph_from_model(model, args)\r\n    381 def _trace_and_get_graph_from_model(model, args):\r\n    382 \r\n    383     # A basic sanity check: make sure the state_dict keys are the same\r\n    384     # before and after running the model.  Fail fast!\r\n    385     orig_state_dict_keys = _unique_state_dict(model).keys()\r\n    387     trace_graph, torch_out, inputs_states = \\\r\n--> 388         torch.jit._get_trace_graph(model, args, strict=False, _force_outplace=False, _return_inputs_states=True)\r\n    389     warn_on_static_input_change(inputs_states)\r\n    391     if orig_state_dict_keys != _unique_state_dict(model).keys():\r\n\r\nFile /opt/homebrew/lib/python3.9/site-packages/torch/jit/_trace.py:1166, in _get_trace_graph(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\r\n   1164 if not isinstance(args, tuple):\r\n   1165     args = (args,)\r\n-> 1166 outs = ONNXTracedModule(f, strict, _force_outplace, return_inputs, _return_inputs_states)(*args, **kwargs)\r\n   1167 return outs\r\n\r\nFile /opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py:1102, in Module._call_impl(self, *input, **kwargs)\r\n   1098 # If we don't have any hooks, we want to skip the rest of the logic in\r\n   1099 # this function, and just call forward.\r\n   1100 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\r\n   1101         or _global_forward_hooks or _global_forward_pre_hooks):\r\n-> 1102     return forward_call(*input, **kwargs)\r\n   1103 # Do not call functions when jit is used\r\n   1104 full_backward_hooks, non_full_backward_hooks = [], []\r\n\r\nFile /opt/homebrew/lib/python3.9/site-packages/torch/jit/_trace.py:127, in ONNXTracedModule.forward(self, *args)\r\n    124     else:\r\n    125         return tuple(out_vars)\r\n--> 127 graph, out = torch._C._create_graph_by_tracing(\r\n    128     wrapper,\r\n    129     in_vars + module_state,\r\n    130     _create_interpreter_name_lookup_fn(),\r\n    131     self.strict,\r\n    132     self._force_outplace,\r\n    133 )\r\n    135 if self._return_inputs:\r\n    136     return graph, outs[0], ret_inputs[0]\r\n\r\nFile /opt/homebrew/lib/python3.9/site-packages/torch/jit/_trace.py:118, in ONNXTracedModule.forward.<locals>.wrapper(*args)\r\n    116 if self._return_inputs_states:\r\n    117     inputs_states.append(_unflatten(in_args, in_desc))\r\n--> 118 outs.append(self.inner(*trace_inputs))\r\n    119 if self._return_inputs_states:\r\n    120     inputs_states[0] = (inputs_states[0], trace_inputs)\r\n\r\nFile /opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py:1102, in Module._call_impl(self, *input, **kwargs)\r\n   1098 # If we don't have any hooks, we want to skip the rest of the logic in\r\n   1099 # this function, and just call forward.\r\n   1100 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\r\n   1101         or _global_forward_hooks or _global_forward_pre_hooks):\r\n-> 1102     return forward_call(*input, **kwargs)\r\n   1103 # Do not call functions when jit is used\r\n   1104 full_backward_hooks, non_full_backward_hooks = [], []\r\n\r\nFile /opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py:1090, in Module._slow_forward(self, *input, **kwargs)\r\n   1088         recording_scopes = False\r\n   1089 try:\r\n-> 1090     result = self.forward(*input, **kwargs)\r\n   1091 finally:\r\n   1092     if recording_scopes:\r\n\r\nTypeError: forward() takes from 1 to 14 positional arguments but 15 were given​\r\n```\r\n\r\nFixes #16308\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case. #16308\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n@ChainYo for the OnnxConfig\r\n@patrickvonplaten and @sgugger for the changes in `modeling_xlnet.py`\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- albert, bert, xlm: @LysandreJik\r\n- blenderbot, bart, marian, pegasus, encoderdecoder,  t5: @patrickvonplaten, @patil-suraj\r\n- longformer, reformer, transfoxl, xlnet: @patrickvonplaten\r\n- fsmt: @stas00\r\n- funnel: @sgugger\r\n- gpt2: @patrickvonplaten, @LysandreJik\r\n- rag: @patrickvonplaten, @lhoestq\r\n- tensorflow: @LysandreJik\r\n\r\nLibrary:\r\n\r\n- benchmarks: @patrickvonplaten\r\n- deepspeed: @stas00\r\n- ray/raytune: @richardliaw, @amogkam\r\n- text generation: @patrickvonplaten\r\n- tokenizers: @n1t0, @LysandreJik\r\n- trainer: @sgugger\r\n- pipelines: @LysandreJik\r\n\r\nDocumentation: @sgugger\r\n\r\nHF projects:\r\n\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nExamples:\r\n\r\n- maintained examples (not research project or legacy): @sgugger, @patil-suraj\r\n- research_projects/bert-loses-patience: @JetRunner\r\n- research_projects/distillation: @VictorSanh\r\n\r\n -->\r\n",
      "body_length": 11689,
      "created_at": "2022-04-30T14:55:51Z",
      "updated_at": "2022-10-08T15:02:24Z",
      "closed_at": "2022-10-08T15:02:24Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 47,
      "deletions": 16,
      "files_changed": 6,
      "commits_count": 10,
      "review_count": 14,
      "comment_count": 11,
      "pr_size": 63,
      "avg_commit_msg_length": 15.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": true,
      "has_docs": true,
      "test_files": [
        "tests/onnx/test_onnx_v2.py"
      ],
      "doc_files": [
        "docs/source/en/serialization.mdx"
      ],
      "file_types": {
        "mdx": 1,
        "py": 5
      },
      "review_states": {
        "COMMENTED": 14
      },
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\n1. Add XLNet OnnxConfig to make this model available for conversion.\r\n2. In order to make the onnx export work, I had to remove the `**kwargs` argument in the `forward` function of the `XLNet` models. Seems like the `**kwargs` was on deprecation warning anyway and removing it didn't break any tests. Here is the reproduction and the error log of the OnnxExport if the `**kwargs` argument doesn't get removed.\r\n\r\n\r\n```\r\nfrom typing import Mapping, OrderedDict \r\nfrom pathlib import Path\r\n\r\nfrom transformers.onnx import OnnxConfig, export\r\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\r\n\r\nclass XLNetOnnxConfig(OnnxConfig):\r\n    @property\r\n    def inputs(self) -> Mapping[str, Mapping[int, str]]:\r\n        if self.task == \"multiple-choice\":\r\n            dynamic_axis = {0: \"batch\", 1: \"choice\", 2: \"sequence\"}\r\n        else:\r\n            dynamic_axis = {0: \"batch\", 1: \"sequence\"}\r\n        return OrderedDict(\r\n            [\r\n                (\"input_ids\", dynamic_axis),\r\n                (\"attention_mask\", dynamic_axis),\r\n                (\"token_type_ids\", dynamic_axis)\r\n            ]\r\n        )\r\n \r\nconfig = AutoConfig.from_pretrained(\"xlnet-base-cased\")\r\nonnx_config = XLNetOnnxConfig(config, task=\"sequence-classification\")\r\n\r\nonnx_path = Path(\"model.onnx\")\r\nbase_model = AutoModel.from_pretrained(\"xlnet-base-cased\")\r\ntokenizer = AutoTokenizer.from_pretrained(\"xlnet-base-cased\")\r\n\r\nonnx_inputs, onnx_outputs = export(tokenizer, base_model, onnx_config, onnx_config.default_onnx_opset, onnx_path)\r\n```\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\nInput In [1], in <module>\r\n     28 base_model = AutoModel.from_pretrained(\"xlnet-base-cased\")\r\n     29 tokenizer = AutoTokenizer.from_pretrained(\"xlnet-base-cased\")\r\n---> 31 onnx_inputs, onnx_outputs = export(tokenizer, base_model, onnx_config, onnx_config.default_onnx_opset, onnx_path)\r\n\r\nFile /opt/homebrew/lib/python3.9/site-packages/transformers/onnx/convert.py:116, in export(tokenizer, model, config, opset, output)\r\n    113     config.patch_ops()\r\n    115     # export can works with named args but the dict containing named args as to be last element of the args tuple\r\n--> 116     export(\r\n    117         model,\r\n    118         (model_inputs,),\r\n    119         f=output.as_posix(),\r\n    120         input_names=list(config.inputs.keys()),\r\n    121         output_names=onnx_outputs,\r\n    122         dynamic_axes={name: axes for name, axes in chain(config.inputs.items(), config.outputs.items())},\r\n    123         do_constant_folding=True,\r\n    124         use_external_data_format=config.use_external_data_format(model.num_parameters()),\r\n    125         enable_onnx_checker=True,\r\n    126         opset_version=opset,\r\n    127     )\r\n    129     config.restore_ops()\r\n    131 return matched_inputs, onnx_outputs\r\n\r\nFile /opt/homebrew/lib/python3.9/site-packages/torch/onnx/__init__.py:316, in export(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\r\n     38 r\"\"\"\r\n     39 Exports a model into ONNX format. If ``model`` is not a\r\n     40 :class:`torch.jit.ScriptModule` nor a :class:`torch.jit.ScriptFunction`, this runs\r\n   (...)\r\n    312     model to the file ``f`` even if this is raised.\r\n    313 \"\"\"\r\n    315 from torch.onnx import utils\r\n--> 316 return utils.export(model, args, f, export_params, verbose, training,\r\n    317                     input_names, output_names, operator_export_type, opset_version,\r\n    318                     _retain_param_name, do_constant_folding, example_outputs,\r\n    319                     strip_doc_string, dynamic_axes, keep_initializers_as_inputs,\r\n    320                     custom_opsets, enable_onnx_checker, use_external_data_format)\r\n\r\nFile /opt/homebrew/lib/python3.9/site-packages/torch/onnx/utils.py:107, in export(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\r\n    102 if use_external_data_format is not None:\r\n    103     warnings.warn(\"`use_external_data_format' is deprecated and ignored. Will be removed in next \"\r\n    104                   \"PyTorch release. The code will work as it is False if models are not larger than 2GB, \"\r\n    105                   \"Otherwise set to False because of size limits imposed by Protocol Buffers.\")\r\n--> 107 _export(model, args, f, export_params, verbose, training, input_names, output_names,\r\n    108         operator_export_type=operator_export_type, opset_version=opset_version,\r\n    109         do_constant_folding=do_constant_folding, example_outputs=example_outputs,\r\n    110         dynamic_axes=dynamic_axes, keep_initializers_as_inputs=keep_initializers_as_inputs,\r\n    111         custom_opsets=custom_opsets, use_external_data_format=use_external_data_format)\r\n\r\nFile /opt/homebrew/lib/python3.9/site-packages/torch/onnx/utils.py:724, in _export(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, use_external_data_format, onnx_shape_inference)\r\n    720     dynamic_axes = {}\r\n    721 _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\r\n    723 graph, params_dict, torch_out = \\\r\n--> 724     _model_to_graph(model, args, verbose, input_names,\r\n    725                     output_names, operator_export_type,\r\n    726                     example_outputs, val_do_constant_folding,\r\n    727                     fixed_batch_size=fixed_batch_size,\r\n    728                     training=training,\r\n    729                     dynamic_axes=dynamic_axes)\r\n    731 # TODO: Don't allocate a in-memory string for the protobuf\r\n    732 defer_weight_export = export_type is not ExportTypes.PROTOBUF_FILE\r\n\r\nFile /opt/homebrew/lib/python3.9/site-packages/torch/onnx/utils.py:493, in _model_to_graph(model, args, verbose, input_names, output_names, operator_export_type, example_outputs, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\r\n    490 if isinstance(args, (torch.Tensor, int, float, bool)):\r\n    491     args = (args, )\r\n--> 493 graph, params, torch_out, module = _create_jit_graph(model, args)\r\n    495 params_dict = _get_named_param_dict(graph, params)\r\n    497 graph = _optimize_graph(graph, operator_export_type,\r\n    498                         _disable_torch_constant_prop=_disable_torch_constant_prop,\r\n    499                         fixed_batch_size=fixed_batch_size, params_dict=params_dict,\r\n    500                         dynamic_axes=dynamic_axes, input_names=input_names,\r\n    501                         module=module)\r\n\r\nFile /opt/homebrew/lib/python3.9/site-packages/torch/onnx/utils.py:437, in _create_jit_graph(model, args)\r\n    435     return graph, params, torch_out, None\r\n    436 else:\r\n--> 437     graph, torch_out = _trace_and_get_graph_from_model(model, args)\r\n    438     state_dict = _unique_state_dict(model)\r\n    439     params = list(state_dict.values())\r\n\r\nFile /opt/homebrew/lib/python3.9/site-packages/torch/onnx/utils.py:388, in _trace_and_get_graph_from_model(model, args)\r\n    381 def _trace_and_get_graph_from_model(model, args):\r\n    382 \r\n    383     # A basic sanity check: make sure the state_dict keys are the same\r\n    384     # before and after running the model.  Fail fast!\r\n    385     orig_state_dict_keys = _unique_state_dict(model).keys()\r\n    387     trace_graph, torch_out, inputs_states = \\\r\n--> 388         torch.jit._get_trace_graph(model, args, strict=False, _force_outplace=False, _return_inputs_states=True)\r\n    389     warn_on_static_input_change(inputs_states)\r\n    391     if orig_state_dict_keys != _unique_state_dict(model).keys():\r\n\r\nFile /opt/homebrew/lib/python3.9/site-packages/torch/jit/_trace.py:1166, in _get_trace_graph(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\r\n   1164 if not isinstance(args, tuple):\r\n   1165     args = (args,)\r\n-> 1166 outs = ONNXTracedModule(f, strict, _force_outplace, return_inputs, _return_inputs_states)(*args, **kwargs)\r\n   1167 return outs\r\n\r\nFile /opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py:1102, in Module._call_impl(self, *input, **kwargs)\r\n   1098 # If we don't have any hooks, we want to skip the rest of the logic in\r\n   1099 # this function, and just call forward.\r\n   1100 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\r\n   1101         or _global_forward_hooks or _global_forward_pre_hooks):\r\n-> 1102     return forward_call(*input, **kwargs)\r\n   1103 # Do not call functions when jit is used\r\n   1104 full_backward_hooks, non_full_backward_hooks = [], []\r\n\r\nFile /opt/homebrew/lib/python3.9/site-packages/torch/jit/_trace.py:127, in ONNXTracedModule.forward(self, *args)\r\n    124     else:\r\n    125         return tuple(out_vars)\r\n--> 127 graph, out = torch._C._create_graph_by_tracing(\r\n    128     wrapper,\r\n    129     in_vars + module_state,\r\n    130     _create_interpreter_name_lookup_fn(),\r\n    131     self.strict,\r\n    132     self._force_outplace,\r\n    133 )\r\n    135 if self._return_inputs:\r\n    136     return graph, outs[0], ret_inputs[0]\r\n\r\nFile /opt/homebrew/lib/python3.9/site-packages/torch/jit/_trace.py:118, in ONNXTracedModule.forward.<locals>.wrapper(*args)\r\n    116 if self._return_inputs_states:\r\n    117     inputs_states.append(_unflatten(in_args, in_desc))\r\n--> 118 outs.append(self.inner(*trace_inputs))\r\n    119 if self._return_inputs_states:\r\n    120     inputs_states[0] = (inputs_states[0], trace_inputs)\r\n\r\nFile /opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py:1102, in Module._call_impl(self, *input, **kwargs)\r\n   1098 # If we don't have any hooks, we want to skip the rest of the logic in\r\n   1099 # this function, and just call forward.\r\n   1100 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\r\n   1101         or _global_forward_hooks or _global_forward_pre_hooks):\r\n-> 1102     return forward_call(*input, **kwargs)\r\n   1103 # Do not call functions when jit is used\r\n   1104 full_backward_hooks, non_full_backward_hooks = [], []\r\n\r\nFile /opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py:1090, in Module._slow_forward(self, *input, **kwargs)\r\n   1088         recording_scopes = False\r\n   1089 try:\r\n-> 1090     result = self.forward(*input, **kwargs)\r\n   1091 finally:\r\n   1092     if recording_scopes:\r\n\r\nTypeError: forward() takes from 1 to 14 positional arguments but 15 were given​\r\n```\r\n\r\nFixes #16308\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case. #16308\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n@ChainYo for the OnnxConfig\r\n@patrickvonplaten and @sgugger for the changes in `modeling_xlnet.py`\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.",
      "body_cleaned_length": 12283,
      "template_removed_length": 1222,
      "template_reduction_percentage": 9.04850055534987,
      "author_type": "User"
    },
    "username": "sijunhe"
  },
  {
    "pr_number": 17677,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 16627,
        "labels": [
          "Core: Tokenization",
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 17677,
      "title": "Add missing tokenizer tests - Longformer",
      "body": "# What does this PR do?\r\n\r\nThis PR add tests for Longformer tokenizer copying tests from Roberta tokenizer's test suite, because those tokenizers are absolutely identical. \r\n\r\nFixes #16627\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [X] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [X] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [X] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n@SaulLu @LysandreJik \r\n\r\n",
      "body_length": 1071,
      "created_at": "2022-06-11T17:40:56Z",
      "merged_at": "2022-08-22T10:13:21Z",
      "merged": true,
      "time_to_merge_hours": 1720.5402777777779,
      "state": "MERGED",
      "additions": 305,
      "deletions": 0,
      "files_changed": 1,
      "commits_count": 7,
      "review_count": 1,
      "comment_count": 6,
      "commit_messages": [
        "Add tests for Longformer tokenizer (copied from Roberta tokenizer's tests)",
        "Add changes after linting",
        "Rename test copied from Roberta",
        "Fix path to tokenizer in @slow test",
        "move tests to proper place",
        "Fix import path of TokenizerTesterMixin",
        "Merge branch 'huggingface:main' into add-missing-tokenizer-tests-longformer"
      ],
      "avg_commit_msg_length": 43.57142857142857,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": true,
      "has_docs": false,
      "test_files": [
        "tests/models/longformer/test_tokenization_longformer.py"
      ],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nThis PR add tests for Longformer tokenizer copying tests from Roberta tokenizer's test suite, because those tokenizers are absolutely identical. \r\n\r\nFixes #16627\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [X] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [X] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [X] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n@SaulLu @LysandreJik",
      "body_cleaned_length": 1066,
      "template_removed_length": 5,
      "template_reduction_percentage": 0.4668534080298786,
      "author_type": "User"
    },
    "username": "tgadeliya"
  },
  {
    "pr_number": 18369,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 18306,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 18369,
      "title": "Migrate metric to Evaluate in Pytorch examples",
      "body": "# What does this PR do?\r\nAs metrics are being deprecated in Datasets, they need to be moved to Evaluate. This PR migrates function calls of `load_metric` from Datasets to `load` in Evaluate in Pytorch examples.\r\n\r\n\r\nFixes #18306 \r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n@sgugger ",
      "body_length": 1253,
      "created_at": "2022-07-29T23:06:00Z",
      "merged_at": "2022-08-01T11:40:26Z",
      "merged": true,
      "time_to_merge_hours": 60.57388888888889,
      "state": "MERGED",
      "additions": 72,
      "deletions": 49,
      "files_changed": 25,
      "commits_count": 2,
      "review_count": 1,
      "comment_count": 1,
      "commit_messages": [
        "Migrate metric to Evaluate in pytorch examples",
        "Remove unused imports"
      ],
      "avg_commit_msg_length": 33.5,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": true,
      "test_files": [],
      "doc_files": [
        "examples/pytorch/_tests_requirements.txt"
      ],
      "file_types": {
        "txt": 1,
        "py": 24
      },
      "review_states": {
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\nAs metrics are being deprecated in Datasets, they need to be moved to Evaluate. This PR migrates function calls of `load_metric` from Datasets to `load` in Evaluate in Pytorch examples.\r\n\r\n\r\nFixes #18306 \r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n@sgugger",
      "body_cleaned_length": 1252,
      "template_removed_length": 1,
      "template_reduction_percentage": 0.07980845969672785,
      "author_type": "User"
    },
    "username": "atturaioe"
  },
  {
    "pr_number": 18602,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 15971,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 18602,
      "title": "Remove pos arg from Perceiver's Pre/Postprocessors",
      "body": "Fix #15971\r\n@NielsRogge ",
      "body_length": 24,
      "created_at": "2022-08-12T13:21:30Z",
      "merged_at": "2022-09-26T12:50:58Z",
      "merged": true,
      "time_to_merge_hours": 1079.4911111111112,
      "state": "MERGED",
      "additions": 4,
      "deletions": 4,
      "files_changed": 1,
      "commits_count": 2,
      "review_count": 18,
      "comment_count": 2,
      "commit_messages": [
        "Remove pos arg from Perceiver's Pre/Postprocessors",
        "Revert the removed pos args in public methods"
      ],
      "avg_commit_msg_length": 47.5,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {
        "COMMENTED": 16,
        "APPROVED": 2
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "Fix #15971\r\n@NielsRogge",
      "body_cleaned_length": 23,
      "template_removed_length": 1,
      "template_reduction_percentage": 4.166666666666666,
      "author_type": "User"
    },
    "username": "aielawady"
  },
  {
    "pr_number": 19218,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 15232,
        "labels": [
          "Good First Issue",
          "Good First Documentation Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 19218,
      "title": "[Wav2Vec2] Fix None loss in doc examples",
      "body": "# What does this PR do?\r\n\r\nDoc examples in [Wav2Vec2ForPreTraining](https://huggingface.co/docs/transformers/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining.forward.example) and  [Wav2Vec2ConformerForPreTraining](https://huggingface.co/docs/transformers/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining.forward.example) produce None loss due to missing sampled_negative_indices parameter in the model. See #15232 \r\n\r\n* pass sampled_negative_indices parameter to the model to avoid getting a None loss\r\n* The sequence length is a tensor when it should be an integer. Add .item() call to address this issue.\r\n\r\nFixes #15232 \r\n\r\n\r\n## Who can review?\r\n\r\n@patrickvonplaten \r\n\r\n\r\n\r\n",
      "body_length": 708,
      "created_at": "2022-09-27T14:21:18Z",
      "merged_at": "2022-09-29T17:23:14Z",
      "merged": true,
      "time_to_merge_hours": 51.032222222222224,
      "state": "MERGED",
      "additions": 37,
      "deletions": 10,
      "files_changed": 2,
      "commits_count": 1,
      "review_count": 1,
      "comment_count": 2,
      "commit_messages": [
        "[Wav2Vec2] Fix None loss in doc examples\n\n* pass sampled_negative_indices parameter to the model to avoid getting a None loss\n* concerns doc examples for Wav2Vec2ForPreTraining and Wav2Vec2ConformerForPreTraining"
      ],
      "avg_commit_msg_length": 212.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 2
      },
      "review_states": {
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nDoc examples in [Wav2Vec2ForPreTraining](https://huggingface.co/docs/transformers/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining.forward.example) and  [Wav2Vec2ConformerForPreTraining](https://huggingface.co/docs/transformers/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining.forward.example) produce None loss due to missing sampled_negative_indices parameter in the model. See #15232 \r\n\r\n* pass sampled_negative_indices parameter to the model to avoid getting a None loss\r\n* The sequence length is a tensor when it should be an integer. Add .item() call to address this issue.\r\n\r\nFixes #15232 \r\n\r\n\r\n## Who can review?\r\n\r\n@patrickvonplaten",
      "body_cleaned_length": 699,
      "template_removed_length": 9,
      "template_reduction_percentage": 1.2711864406779663,
      "author_type": "User"
    },
    "username": "rbsteinm"
  },
  {
    "pr_number": 19403,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 19303,
        "labels": [
          "Good First Issue",
          "HACKTOBERFEST-ACCEPTED"
        ]
      }
    ],
    "pr_data": {
      "number": 19403,
      "title": "Remove dependency of Bert from Squeezebert tokenizer",
      "body": "Hi @sgugger,\r\n\r\nFixes #19303, the BertTokenizer dependency has been removed from `SqueezeBertTokenizer` and the BertTokenizerFast dependency has been removed from `SqueezeBertTokenizerFast`.\r\n\r\nI ran `pytest tests/models/squeezebert/test_tokenization_squeezebert.py`, which passed.\r\n\r\nThanks for reviewing this! :)\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [x] Did you write any new necessary tests?",
      "body_length": 1146,
      "created_at": "2022-10-07T09:48:34Z",
      "merged_at": "2022-10-07T15:32:55Z",
      "merged": true,
      "time_to_merge_hours": 5.739166666666667,
      "state": "MERGED",
      "additions": 602,
      "deletions": 14,
      "files_changed": 2,
      "commits_count": 5,
      "review_count": 4,
      "comment_count": 3,
      "commit_messages": [
        "Remove dependency of Bert from Squeezebert tokenizer",
        "run style corrections",
        "update copies from BertTokenizers",
        "Update changes and style to Squeezebert files",
        "update copies for bert-fast"
      ],
      "avg_commit_msg_length": 35.6,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 2
      },
      "review_states": {
        "COMMENTED": 3,
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "Hi @sgugger,\r\n\r\nFixes #19303, the BertTokenizer dependency has been removed from `SqueezeBertTokenizer` and the BertTokenizerFast dependency has been removed from `SqueezeBertTokenizerFast`.\r\n\r\nI ran `pytest tests/models/squeezebert/test_tokenization_squeezebert.py`, which passed.\r\n\r\nThanks for reviewing this! :)\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [x] Did you write any new necessary tests?",
      "body_cleaned_length": 1146,
      "template_removed_length": 0,
      "template_reduction_percentage": 0.0,
      "author_type": "User"
    },
    "username": "rchan26"
  },
  {
    "pr_number": 19426,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 19303,
        "labels": [
          "Good First Issue",
          "HACKTOBERFEST-ACCEPTED"
        ]
      }
    ],
    "pr_data": {
      "number": 19426,
      "title": "made tokenization_roformer independent of bert",
      "body": "# What does this PR do?\r\nRelates to issue #19303 \r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes #19303 \r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n@patrickvonplaten \r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- albert, bert, xlm: @LysandreJik\r\n- blenderbot, bart, marian, pegasus, encoderdecoder,  t5: @patrickvonplaten, @patil-suraj\r\n- longformer, reformer, transfoxl, xlnet: @patrickvonplaten\r\n- fsmt: @stas00\r\n- funnel: @sgugger\r\n- gpt2: @patrickvonplaten, @LysandreJik\r\n- rag: @patrickvonplaten, @lhoestq\r\n- tensorflow: @LysandreJik\r\n\r\nLibrary:\r\n\r\n- benchmarks: @patrickvonplaten\r\n- deepspeed: @stas00\r\n- ray/raytune: @richardliaw, @amogkam\r\n- text generation: @patrickvonplaten\r\n- tokenizers: @n1t0, @LysandreJik\r\n- trainer: @sgugger\r\n- pipelines: @LysandreJik\r\n\r\nDocumentation: @sgugger\r\n\r\nHF projects:\r\n\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nExamples:\r\n\r\n- maintained examples (not research project or legacy): @sgugger, @patil-suraj\r\n- research_projects/bert-loses-patience: @JetRunner\r\n- research_projects/distillation: @VictorSanh\r\n\r\n -->\r\n",
      "body_length": 3194,
      "created_at": "2022-10-08T11:15:57Z",
      "merged_at": "2022-10-12T14:13:10Z",
      "merged": true,
      "time_to_merge_hours": 98.95361111111112,
      "state": "MERGED",
      "additions": 232,
      "deletions": 2,
      "files_changed": 1,
      "commits_count": 5,
      "review_count": 3,
      "comment_count": 8,
      "commit_messages": [
        "made tokenization_roformer independent of bert",
        "added missing imports",
        "added missing function and import",
        "Fixed copy commands",
        "Update tokenization_roformer.py"
      ],
      "avg_commit_msg_length": 30.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {
        "COMMENTED": 2,
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\nRelates to issue #19303 \r\n\r\n\r\n\r\n\r\n\r\nFixes #19303 \r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n@patrickvonplaten",
      "body_cleaned_length": 1106,
      "template_removed_length": 2088,
      "template_reduction_percentage": 65.37257357545397,
      "author_type": "User"
    },
    "username": "naveennamani"
  },
  {
    "pr_number": 19417,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 19303,
        "labels": [
          "Good First Issue",
          "HACKTOBERFEST-ACCEPTED"
        ]
      }
    ],
    "pr_data": {
      "number": 19417,
      "title": "Make `MobileBert` tokenizers independent from `Bert`",
      "body": "# What does this PR do?\r\n\r\nCopied the code from `Bert` tokenizers into `MobileBert` tokenizers to make the latter self-contained.\r\n\r\nFixes #19303 \r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n@sgugger\r\n",
      "body_length": 634,
      "created_at": "2022-10-07T19:22:59Z",
      "updated_at": "2022-10-12T14:36:00Z",
      "closed_at": "2022-10-12T14:21:51Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 0,
      "deletions": 0,
      "files_changed": 0,
      "commits_count": 0,
      "review_count": 2,
      "comment_count": 3,
      "pr_size": 0,
      "avg_commit_msg_length": 0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {},
      "review_states": {
        "COMMENTED": 2
      },
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nCopied the code from `Bert` tokenizers into `MobileBert` tokenizers to make the latter self-contained.\r\n\r\nFixes #19303 \r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n@sgugger",
      "body_cleaned_length": 1016,
      "template_removed_length": 2,
      "template_reduction_percentage": 0.19646365422396855,
      "author_type": "User"
    },
    "username": "501Good"
  },
  {
    "pr_number": 19655,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 19303,
        "labels": [
          "Good First Issue",
          "HACKTOBERFEST-ACCEPTED"
        ]
      }
    ],
    "pr_data": {
      "number": 19655,
      "title": "Removed Bert interdependency from Funnel transformer",
      "body": "# What does this PR do?\r\nHi @sgugger,\r\n\r\nFixes #19303 \r\n- The `BertTokenizer` dependency has been removed from `FunnelTokenizer`\r\n- The `BertTokenizerFast` dependency has been removed from `FunnelTokenizerFast`\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n## Who can review?\r\n@sgugger ",
      "body_length": 1068,
      "created_at": "2022-10-16T06:05:09Z",
      "merged_at": "2022-10-17T14:04:11Z",
      "merged": true,
      "time_to_merge_hours": 31.983888888888888,
      "state": "MERGED",
      "additions": 506,
      "deletions": 19,
      "files_changed": 2,
      "commits_count": 7,
      "review_count": 5,
      "comment_count": 2,
      "commit_messages": [
        "Removed Bert interdependency from Funnel transformer",
        "passed consistency check",
        "Merge branch 'huggingface:main' into remove-bert-dependency-funnel",
        "Revert \"passed consistency check\"\n\nThis reverts commit ba55a0813549938fc54626794e666ee13a85c2d8.",
        "Fixed docstrings",
        "Merge remote-tracking branch 'origin/main' into remove-bert-dependency-funnel",
        "Merge branch 'huggingface:main' into remove-bert-dependency-funnel"
      ],
      "avg_commit_msg_length": 56.714285714285715,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 2
      },
      "review_states": {
        "COMMENTED": 4,
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\nHi @sgugger,\r\n\r\nFixes #19303 \r\n- The `BertTokenizer` dependency has been removed from `FunnelTokenizer`\r\n- The `BertTokenizerFast` dependency has been removed from `FunnelTokenizerFast`\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n## Who can review?\r\n@sgugger",
      "body_cleaned_length": 1067,
      "template_removed_length": 1,
      "template_reduction_percentage": 0.09363295880149813,
      "author_type": "User"
    },
    "username": "mukesh663"
  },
  {
    "pr_number": 19868,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 16308,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 19868,
      "title": "Add Onnx Config for ImageGPT ",
      "body": "# What does this PR do?\r\nFixes #16308\r\n\r\nAdd changes to make ImageGPT models available for Onnx conversion.\r\n\r\nWho can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n@ChainYo",
      "body_length": 291,
      "created_at": "2022-10-25T10:15:34Z",
      "merged_at": "2022-10-28T13:39:53Z",
      "merged": true,
      "time_to_merge_hours": 75.40527777777778,
      "state": "MERGED",
      "additions": 69,
      "deletions": 2,
      "files_changed": 5,
      "commits_count": 7,
      "review_count": 8,
      "comment_count": 6,
      "commit_messages": [
        "add Onnx Config for ImageGPT",
        "Merge branch 'huggingface:main' into imagegpt-onnx",
        "add generate_dummy_inputs for onnx config",
        "Merge branch 'huggingface:main' into imagegpt-onnx",
        "Merge branch 'imagegpt-onnx' of github.com:RaghavPrabhakar66/transformers into imagegpt-onnx",
        "add TYPE_CHECKING clause",
        "Update doc for generate_dummy_inputs\n\nCo-authored-by: Sylvain Gugger <35901082+sgugger@users.noreply.github.com>"
      ],
      "avg_commit_msg_length": 56.714285714285715,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": true,
      "has_docs": true,
      "test_files": [
        "tests/onnx/test_onnx_v2.py"
      ],
      "doc_files": [
        "docs/source/en/serialization.mdx"
      ],
      "file_types": {
        "mdx": 1,
        "py": 4
      },
      "review_states": {
        "COMMENTED": 6,
        "APPROVED": 2
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\nFixes #16308\r\n\r\nAdd changes to make ImageGPT models available for Onnx conversion.\r\n\r\nWho can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n@ChainYo",
      "body_cleaned_length": 291,
      "template_removed_length": 0,
      "template_reduction_percentage": 0.0,
      "author_type": "User"
    },
    "username": "RaghavPrabhakar66"
  },
  {
    "pr_number": 20084,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 20055,
        "labels": [
          "Help wanted",
          "Good First Issue",
          "Good First Documentation Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 20084,
      "title": "[Docs] Add resources of OpenAI GPT",
      "body": "# What does this PR do?\r\nAdds resources of OpenAI GPT according to [this issue](https://github.com/huggingface/transformers/issues/20055)\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes #20055 (partially)\r\n\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- albert, bert, xlm: @LysandreJik\r\n- blenderbot, bart, marian, pegasus, encoderdecoder,  t5: @patrickvonplaten, @patil-suraj\r\n- longformer, reformer, transfoxl, xlnet: @patrickvonplaten\r\n- fsmt: @stas00\r\n- funnel: @sgugger\r\n- gpt2: @patrickvonplaten, @LysandreJik\r\n- rag: @patrickvonplaten, @lhoestq\r\n- tensorflow: @LysandreJik\r\n\r\nLibrary:\r\n\r\n- benchmarks: @patrickvonplaten\r\n- deepspeed: @stas00\r\n- ray/raytune: @richardliaw, @amogkam\r\n- text generation: @patrickvonplaten\r\n- tokenizers: @n1t0, @LysandreJik\r\n- trainer: @sgugger\r\n- pipelines: @LysandreJik\r\n\r\nDocumentation: @sgugger\r\n\r\nHF projects:\r\n\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nExamples:\r\n\r\n- maintained examples (not research project or legacy): @sgugger, @patil-suraj\r\n- research_projects/bert-loses-patience: @JetRunner\r\n- research_projects/distillation: @VictorSanh\r\n\r\n -->\r\n",
      "body_length": 3269,
      "created_at": "2022-11-06T07:56:41Z",
      "merged_at": "2022-11-16T16:17:32Z",
      "merged": true,
      "time_to_merge_hours": 248.3475,
      "state": "MERGED",
      "additions": 25,
      "deletions": 0,
      "files_changed": 1,
      "commits_count": 8,
      "review_count": 6,
      "comment_count": 7,
      "commit_messages": [
        "Add resources of OpenAI GPT",
        "Delete Deploy section and add .",
        "Add scripts",
        "Update docs/source/en/model_doc/openai-gpt.mdx\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
        "Delete causal-language-modeling section",
        "Add TFOpenAIGPTLMHeadModel",
        "Add resources from community",
        "Delete a link"
      ],
      "avg_commit_msg_length": 36.75,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": true,
      "test_files": [],
      "doc_files": [
        "docs/source/en/model_doc/openai-gpt.mdx"
      ],
      "file_types": {
        "mdx": 1
      },
      "review_states": {
        "COMMENTED": 4,
        "APPROVED": 2
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\nAdds resources of OpenAI GPT according to [this issue](https://github.com/huggingface/transformers/issues/20055)\r\n\r\n\r\n\r\n\r\nFixes #20055 (partially)\r\n\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.",
      "body_cleaned_length": 1182,
      "template_removed_length": 2087,
      "template_reduction_percentage": 63.84215356378097,
      "author_type": "User"
    },
    "username": "shogohida"
  },
  {
    "pr_number": 20190,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 20055,
        "labels": [
          "Help wanted",
          "Good First Issue",
          "Good First Documentation Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 20190,
      "title": "Add clip resources to the transformers documentation",
      "body": "# What does this PR do?\r\n\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes #20055 (partially)\r\n\r\n\r\n## Before submitting\r\n- [x] This PR improves the docs of CLIP by adding common and most used resources\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case. #20055 \r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n\r\n## Who can review?\r\n\r\n@stevhliu Please can you have a look?\r\n",
      "body_length": 929,
      "created_at": "2022-11-13T14:23:17Z",
      "merged_at": "2022-11-15T18:26:46Z",
      "merged": true,
      "time_to_merge_hours": 52.058055555555555,
      "state": "MERGED",
      "additions": 19,
      "deletions": 0,
      "files_changed": 1,
      "commits_count": 4,
      "review_count": 5,
      "comment_count": 3,
      "commit_messages": [
        "WIP: Added CLIP resources from HuggingFace blog",
        "ADD: Notebooks documentation to clip",
        "Add link straight to notebook\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
        "Change notebook links to colab"
      ],
      "avg_commit_msg_length": 53.75,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": true,
      "test_files": [],
      "doc_files": [
        "docs/source/en/model_doc/clip.mdx"
      ],
      "file_types": {
        "mdx": 1
      },
      "review_states": {
        "COMMENTED": 3,
        "APPROVED": 2
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\n\r\n\r\n\r\nFixes #20055 (partially)\r\n\r\n\r\n## Before submitting\r\n- [x] This PR improves the docs of CLIP by adding common and most used resources\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case. #20055 \r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n\r\n## Who can review?\r\n\r\n@stevhliu Please can you have a look?",
      "body_cleaned_length": 894,
      "template_removed_length": 35,
      "template_reduction_percentage": 3.767491926803014,
      "author_type": "User"
    },
    "username": "ambujpawar"
  },
  {
    "pr_number": 21270,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 20055,
        "labels": [
          "Help wanted",
          "Good First Issue",
          "Good First Documentation Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 21270,
      "title": "Adding resource section to GPT-J docs",
      "body": "# What does this PR do?\r\nAdds resources section to the GPT-J documents. \r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes #20055 (issue)\r\n\r\n\r\n## Before submitting\r\n- [X] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n@sgugger @stevhliu @MKhalusova\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- text models: @ArthurZucker and @younesbelkada\r\n- vision models: @amyeroberts and @NielsRogge\r\n- speech models: @sanchit-gandhi\r\n- graph models: @clefourrier\r\n\r\nLibrary:\r\n\r\n- flax: @sanchit-gandhi\r\n- generate: @gante\r\n- pipelines: @Narsil\r\n- tensorflow: @gante and @Rocketknight1\r\n- tokenizers: @ArthurZucker\r\n- trainer: @sgugger\r\n\r\nIntegrations:\r\n\r\n- deepspeed: HF Trainer: @stas00, Accelerate: @pacman100\r\n- ray/raytune: @richardliaw, @amogkam\r\n\r\nDocumentation: @sgugger, @stevhliu and @MKhalusova\r\n\r\nHF projects:\r\n\r\n- accelerate: [different repo](https://github.com/huggingface/accelerate)\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- diffusers: [different repo](https://github.com/huggingface/diffusers)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nMaintained examples (not research project or legacy):\r\n\r\n- Flax: @sanchit-gandhi\r\n- PyTorch: @sgugger\r\n- TensorFlow: @Rocketknight1\r\n\r\n -->\r\n",
      "body_length": 3241,
      "created_at": "2023-01-23T20:55:23Z",
      "merged_at": "2023-01-30T21:48:04Z",
      "merged": true,
      "time_to_merge_hours": 168.87805555555556,
      "state": "MERGED",
      "additions": 17,
      "deletions": 0,
      "files_changed": 1,
      "commits_count": 7,
      "review_count": 8,
      "comment_count": 5,
      "commit_messages": [
        "Added resource section to GPT-J docs",
        "Added most of the links found",
        "Addressing review comments",
        "Fixing formatting",
        "Update docs/source/en/model_doc/gptj.mdx\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
        "Fixing one of the labels",
        "Merge branch 'Add_resources_for_GPT-J' of https://github.com/adit299/transformers into Add_resources_for_GPT-J\nFixed one of the labels"
      ],
      "avg_commit_msg_length": 54.142857142857146,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": true,
      "test_files": [],
      "doc_files": [
        "docs/source/en/model_doc/gptj.mdx"
      ],
      "file_types": {
        "mdx": 1
      },
      "review_states": {
        "COMMENTED": 7,
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\nAdds resources section to the GPT-J documents. \r\n\r\n\r\n\r\n\r\n\r\nFixes #20055 (issue)\r\n\r\n\r\n## Before submitting\r\n- [X] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n@sgugger @stevhliu @MKhalusova",
      "body_cleaned_length": 1149,
      "template_removed_length": 2092,
      "template_reduction_percentage": 64.54797901882135,
      "author_type": "User"
    },
    "username": "adit299"
  },
  {
    "pr_number": 21548,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 16059,
        "labels": [
          "Good First Issue",
          "HACKTOBERFEST-ACCEPTED"
        ]
      }
    ],
    "pr_data": {
      "number": 21548,
      "title": "Adding type hints to call() functions in this file",
      "body": "Co-authored by @katiele47\r\n\r\n# What does this PR do?\r\n\r\n\r\nAdded type hints to the TFMarian model by adding types to Marian model call inputs. We added these types to each call() function according to the 'MARIAN_INPUTS_DOCSTRING' documentation contained within this file. \r\n\r\n\r\n\r\nFixes #16059\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case. [Issue #16059](https://github.com/huggingface/transformers/issues/16059)\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- text models: @ArthurZucker and @younesbelkada\r\n- vision models: @amyeroberts and @NielsRogge\r\n- speech models: @sanchit-gandhi\r\n- graph models: @clefourrier\r\n\r\nLibrary:\r\n\r\n- flax: @sanchit-gandhi\r\n- generate: @gante\r\n- pipelines: @Narsil\r\n- tensorflow: @gante and @Rocketknight1\r\n- tokenizers: @ArthurZucker\r\n- trainer: @sgugger\r\n\r\nIntegrations:\r\n\r\n- deepspeed: HF Trainer: @stas00, Accelerate: @pacman100\r\n- ray/raytune: @richardliaw, @amogkam\r\n\r\nDocumentation: @sgugger, @stevhliu and @MKhalusova\r\n\r\nHF projects:\r\n\r\n- accelerate: [different repo](https://github.com/huggingface/accelerate)\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- diffusers: [different repo](https://github.com/huggingface/diffusers)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nMaintained examples (not research project or legacy):\r\n\r\n- Flax: @sanchit-gandhi\r\n- PyTorch: @sgugger\r\n- TensorFlow: @Rocketknight1\r\n\r\n -->\r\n\r\nTagging @Rocketknight1 (author of the issue)\r\n",
      "body_length": 2651,
      "created_at": "2023-02-09T19:15:28Z",
      "merged_at": "2023-02-21T16:28:33Z",
      "merged": true,
      "time_to_merge_hours": 285.21805555555557,
      "state": "MERGED",
      "additions": 72,
      "deletions": 72,
      "files_changed": 1,
      "commits_count": 10,
      "review_count": 4,
      "comment_count": 6,
      "commit_messages": [
        "Adding type hints to call() functions in this file",
        "make fixup",
        "Update src/transformers/models/marian/modeling_tf_marian.py",
        "Update src/transformers/models/marian/modeling_tf_marian.py",
        "Update src/transformers/models/marian/modeling_tf_marian.py",
        "Update src/transformers/models/marian/modeling_tf_marian.py",
        "Update src/transformers/models/marian/modeling_tf_marian.py",
        "Update src/transformers/models/marian/modeling_tf_marian.py",
        "Update src/transformers/models/marian/modeling_tf_marian.py",
        "Update src/transformers/models/marian/modeling_tf_marian.py"
      ],
      "avg_commit_msg_length": 53.2,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {
        "COMMENTED": 3,
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "Co-authored by @katiele47\r\n\r\n# What does this PR do?\r\n\r\n\r\nAdded type hints to the TFMarian model by adding types to Marian model call inputs. We added these types to each call() function according to the 'MARIAN_INPUTS_DOCSTRING' documentation contained within this file. \r\n\r\n\r\n\r\nFixes #16059\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case. [Issue #16059](https://github.com/huggingface/transformers/issues/16059)\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n\r\n\r\nTagging @Rocketknight1 (author of the issue)",
      "body_cleaned_length": 1428,
      "template_removed_length": 1223,
      "template_reduction_percentage": 46.133534515277255,
      "author_type": "User"
    },
    "username": "pmollerus23"
  },
  {
    "pr_number": 21625,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 20055,
        "labels": [
          "Help wanted",
          "Good First Issue",
          "Good First Documentation Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 21625,
      "title": "Add OPT resources to the transformers documentation",
      "body": "# What does this PR do?\r\n\r\nFixes #20055 (partially)\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n\r\n## Who can review?\r\n@stevhliu \r\nThanks in advance, if I miss anything please let me know :) ",
      "body_length": 933,
      "created_at": "2023-02-14T13:48:57Z",
      "merged_at": "2023-02-16T17:44:28Z",
      "merged": true,
      "time_to_merge_hours": 51.92527777777778,
      "state": "MERGED",
      "additions": 31,
      "deletions": 3,
      "files_changed": 1,
      "commits_count": 8,
      "review_count": 5,
      "comment_count": 3,
      "commit_messages": [
        "Add resources to OPT",
        "Merge branch 'huggingface:main' into add_opt_resources",
        "Add additional resources for OPT",
        "Remove -{\" \"} after <PipelineTag pipeline=\"question-answering\" />",
        "Change bitsnbytes to bitsandbytes",
        "Revert formatting",
        "Revert automatic format changes",
        "Remove - sign after <PipelineTag pipeline=\"question-answering\" />"
      ],
      "avg_commit_msg_length": 39.625,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": true,
      "test_files": [],
      "doc_files": [
        "docs/source/en/model_doc/opt.mdx"
      ],
      "file_types": {
        "mdx": 1
      },
      "review_states": {
        "COMMENTED": 4,
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nFixes #20055 (partially)\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n\r\n## Who can review?\r\n@stevhliu \r\nThanks in advance, if I miss anything please let me know :)",
      "body_cleaned_length": 932,
      "template_removed_length": 1,
      "template_reduction_percentage": 0.10718113612004287,
      "author_type": "User"
    },
    "username": "alissadb"
  },
  {
    "pr_number": 21675,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 14110,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 21675,
      "title": "Fix multi-gpu training error for LayoutLMv2",
      "body": "# What does this PR do?\r\n\r\nFixes #14110\r\n\r\n## Issue\r\n\r\nWhen training a LayoutLMv2 model with multiple GPUs using `torchrun --standalone --nnodes=1 --nproc_per_node=$NUM_GPUS run_layoutlmv2.py` (single node, multi-gpu), I encounter \r\n\r\n```\r\nRuntimeError: Make sure the number of processes can be divided by the number of nodes\r\n```\r\n\r\n## What this PR fixes\r\nFixes a one character typo/bug to run using multiple GPUs\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\n\r\n\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n@NielsRogge \r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- text models: @ArthurZucker and @younesbelkada\r\n- vision models: @amyeroberts\r\n- speech models: @sanchit-gandhi\r\n- graph models: @clefourrier\r\n\r\nLibrary:\r\n\r\n- flax: @sanchit-gandhi\r\n- generate: @gante\r\n- pipelines: @Narsil\r\n- tensorflow: @gante and @Rocketknight1\r\n- tokenizers: @ArthurZucker\r\n- trainer: @sgugger\r\n\r\nIntegrations:\r\n\r\n- deepspeed: HF Trainer: @stas00, Accelerate: @pacman100\r\n- ray/raytune: @richardliaw, @amogkam\r\n\r\nDocumentation: @sgugger, @stevhliu and @MKhalusova\r\n\r\nHF projects:\r\n\r\n- accelerate: [different repo](https://github.com/huggingface/accelerate)\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- diffusers: [different repo](https://github.com/huggingface/diffusers)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nMaintained examples (not research project or legacy):\r\n\r\n- Flax: @sanchit-gandhi\r\n- PyTorch: @sgugger\r\n- TensorFlow: @Rocketknight1\r\n\r\n -->\r\n",
      "body_length": 3529,
      "created_at": "2023-02-17T10:40:29Z",
      "merged_at": "2023-02-17T17:04:12Z",
      "merged": true,
      "time_to_merge_hours": 6.395277777777777,
      "state": "MERGED",
      "additions": 1,
      "deletions": 1,
      "files_changed": 1,
      "commits_count": 1,
      "review_count": 1,
      "comment_count": 2,
      "commit_messages": [
        "Fix multi-gpu training error for LayoutLMv2"
      ],
      "avg_commit_msg_length": 43.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nFixes #14110\r\n\r\n## Issue\r\n\r\nWhen training a LayoutLMv2 model with multiple GPUs using `torchrun --standalone --nnodes=1 --nproc_per_node=$NUM_GPUS run_layoutlmv2.py` (single node, multi-gpu), I encounter \r\n\r\n```\r\nRuntimeError: Make sure the number of processes can be divided by the number of nodes\r\n```\r\n\r\n## What this PR fixes\r\nFixes a one character typo/bug to run using multiple GPUs\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n@NielsRogge",
      "body_cleaned_length": 1452,
      "template_removed_length": 2077,
      "template_reduction_percentage": 58.855199773306886,
      "author_type": "User"
    },
    "username": "akkikiki"
  },
  {
    "pr_number": 21956,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 21737,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 21956,
      "title": "[Generate] Fix gradient_checkpointing and use_cache bug for BLOOM",
      "body": "Fixes #21737 for Bloom.\r\n\r\n## Before submitting\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a GitHub issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n\r\n\r\n## Who can review?\r\n\r\ncc @younesbelkada @gante ",
      "body_length": 758,
      "created_at": "2023-03-05T02:41:51Z",
      "merged_at": "2023-03-06T14:56:41Z",
      "merged": true,
      "time_to_merge_hours": 36.24722222222222,
      "state": "MERGED",
      "additions": 7,
      "deletions": 5,
      "files_changed": 1,
      "commits_count": 1,
      "review_count": 2,
      "comment_count": 1,
      "commit_messages": [
        "Step 1 - Change use_cache fix"
      ],
      "avg_commit_msg_length": 29.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {
        "APPROVED": 2
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "Fixes #21737 for Bloom.\r\n\r\n## Before submitting\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a GitHub issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n\r\n\r\n## Who can review?\r\n\r\ncc @younesbelkada @gante",
      "body_cleaned_length": 757,
      "template_removed_length": 1,
      "template_reduction_percentage": 0.13192612137203166,
      "author_type": "User"
    },
    "username": "asrimanth"
  },
  {
    "pr_number": 22253,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 21530,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 22253,
      "title": "Add `BioGPTForSequenceClassification`",
      "body": "# What does this PR do?\r\n\r\nAdd Sequence Classification support for BioGPT.\r\n\r\nFixes #21530 \r\nFixes #21535 \r\nThis PR completes the stalled PR #21535.\r\n<!---\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n-->\r\n\r\n## Who can review?\r\n@ArthurZucker @younesbelkada @NielsRogge @sgugger ",
      "body_length": 203,
      "created_at": "2023-03-19T11:45:43Z",
      "updated_at": "2023-05-01T13:20:14Z",
      "closed_at": "2023-05-01T13:17:27Z",
      "merged_at": "2023-05-01T13:17:27Z",
      "merged": true,
      "state": "MERGED",
      "time_to_merge_hours": 1033.5288888888888,
      "additions": 198,
      "deletions": 5,
      "files_changed": 8,
      "commits_count": 18,
      "review_count": 15,
      "comment_count": 8,
      "pr_size": 203,
      "avg_commit_msg_length": 55.05555555555556,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": true,
      "has_docs": true,
      "test_files": [
        "tests/models/biogpt/test_modeling_biogpt.py"
      ],
      "doc_files": [
        "docs/source/en/model_doc/biogpt.mdx",
        "docs/source/en/tasks/sequence_classification.mdx"
      ],
      "file_types": {
        "mdx": 2,
        "py": 6
      },
      "review_states": {
        "APPROVED": 4,
        "COMMENTED": 11
      },
      "has_changes_requested": false,
      "has_approved": true,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nAdd Sequence Classification support for BioGPT.\r\n\r\nFixes #21530 \r\nFixes #21535 \r\nThis PR completes the stalled PR #21535.\r\n\r\n\r\n## Who can review?\r\n@ArthurZucker @younesbelkada @NielsRogge @sgugger",
      "body_cleaned_length": 223,
      "template_removed_length": 841,
      "template_reduction_percentage": 79.04135338345864,
      "author_type": "User"
    },
    "username": "awinml"
  },
  {
    "pr_number": 22342,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 21786,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 22342,
      "title": "added biogpt token classification",
      "body": "# What does this PR do?\r\n\r\nIt add the class for BioGptForTokenClassification based on BioGpt model\r\n\r\nFixes #21786\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [x] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n@ArthurZucker @younesbelkada @NielsRogge @sgugger\r\n\r\n",
      "body_length": 797,
      "created_at": "2023-03-23T15:39:48Z",
      "updated_at": "2023-03-26T19:23:14Z",
      "closed_at": "2023-03-26T19:20:22Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 10067,
      "deletions": 1655,
      "files_changed": 76,
      "commits_count": 23,
      "review_count": 0,
      "comment_count": 2,
      "pr_size": 11722,
      "avg_commit_msg_length": 348.04347826086956,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": true,
      "has_docs": true,
      "test_files": [
        "tests/generation/test_utils.py",
        "tests/models/altclip/test_modeling_altclip.py",
        "tests/models/audio_spectrogram_transformer/test_modeling_audio_spectrogram_transformer.py",
        "tests/models/biogpt/test_modeling_biogpt.py",
        "tests/models/blenderbot_small/test_modeling_blenderbot_small.py",
        "tests/models/deta/test_modeling_deta.py",
        "tests/models/ernie_m/test_modeling_ernie_m.py",
        "tests/models/gpt_neox/test_modeling_gpt_neox.py",
        "tests/models/mega/__init__.py",
        "tests/models/mega/test_modeling_mega.py",
        "tests/models/oneformer/test_modeling_oneformer.py",
        "tests/models/resnet/test_modeling_flax_resnet.py",
        "tests/models/splinter/test_modeling_splinter.py",
        "tests/test_pipeline_mixin.py"
      ],
      "doc_files": [
        "README.md",
        "README_es.md",
        "README_hd.md",
        "README_ja.md",
        "README_ko.md",
        "README_zh-hans.md",
        "README_zh-hant.md",
        "docs/source/de/index.mdx",
        "docs/source/en/_toctree.yml",
        "docs/source/en/generation_strategies.mdx",
        "docs/source/en/index.mdx",
        "docs/source/en/model_doc/biogpt.mdx",
        "docs/source/en/model_doc/mega.mdx",
        "docs/source/en/model_doc/resnet.mdx",
        "docs/source/en/serialization.mdx",
        "docs/source/en/tasks/language_modeling.mdx",
        "docs/source/en/tasks/masked_language_modeling.mdx",
        "docs/source/en/tasks/multiple_choice.mdx",
        "docs/source/en/tasks/question_answering.mdx",
        "docs/source/en/tasks/sequence_classification.mdx",
        "docs/source/en/tasks/token_classification.mdx",
        "docs/source/es/index.mdx",
        "docs/source/it/index.mdx",
        "docs/source/ja/index.mdx",
        "docs/source/ko/index.mdx",
        "docs/source/pt/index.mdx",
        "examples/tensorflow/_tests_requirements.txt"
      ],
      "file_types": {
        "py": 44,
        "yml": 2,
        "md": 7,
        "mdx": 18,
        "txt": 1,
        "json": 1
      },
      "review_states": {},
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nIt add the class for BioGptForTokenClassification based on BioGpt model\r\n\r\nFixes #21786\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [x] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n@ArthurZucker @younesbelkada @NielsRogge @sgugger",
      "body_cleaned_length": 1178,
      "template_removed_length": 4,
      "template_reduction_percentage": 0.338409475465313,
      "author_type": "User"
    },
    "username": "upjabir"
  },
  {
    "pr_number": 23142,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 20055,
        "labels": [
          "Help wanted",
          "Good First Issue",
          "Good First Documentation Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 23142,
      "title": "Add TrOCR resources",
      "body": "# What does this PR do?\r\n\r\nAdds resources of OpenAI GPT according to https://github.com/huggingface/transformers/issues/20055\r\n\r\nFixes #20055 (partially)\r\n\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n@stevhliu \r\n",
      "body_length": 474,
      "created_at": "2023-05-04T02:09:22Z",
      "merged_at": "2023-05-05T15:29:20Z",
      "merged": true,
      "time_to_merge_hours": 37.33277777777778,
      "state": "MERGED",
      "additions": 21,
      "deletions": 0,
      "files_changed": 1,
      "commits_count": 2,
      "review_count": 2,
      "comment_count": 1,
      "commit_messages": [
        "Add TrOCR resources",
        "Made fixes suggested by stevhliu"
      ],
      "avg_commit_msg_length": 25.5,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": true,
      "test_files": [],
      "doc_files": [
        "docs/source/en/model_doc/trocr.mdx"
      ],
      "file_types": {
        "mdx": 1
      },
      "review_states": {
        "APPROVED": 2
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nAdds resources of OpenAI GPT according to https://github.com/huggingface/transformers/issues/20055\r\n\r\nFixes #20055 (partially)\r\n\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n@stevhliu",
      "body_cleaned_length": 471,
      "template_removed_length": 3,
      "template_reduction_percentage": 0.6329113924050633,
      "author_type": "User"
    },
    "username": "huangperry"
  },
  {
    "pr_number": 24510,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 16136,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 24510,
      "title": "Show a warning for missing attention masks when pad_token_id is not None",
      "body": "# What does this PR do?\r\n\r\nFixes #16136\r\n\r\nShows a one-time warning message when the pad_token_id is not None and no attention masks are given. \r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? #16136 \r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [x] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n@gante @ydshieh",
      "body_length": 1129,
      "created_at": "2023-06-27T01:44:15Z",
      "merged_at": "2023-06-30T12:19:39Z",
      "merged": true,
      "time_to_merge_hours": 82.59,
      "state": "MERGED",
      "additions": 140,
      "deletions": 1,
      "files_changed": 12,
      "commits_count": 6,
      "review_count": 5,
      "comment_count": 10,
      "commit_messages": [
        "Adding warning messages to BERT for missing attention masks\n\nThese warning messages when there are pad tokens within the input ids and\nno attention masks are given. The warning message should only show up once.",
        "Adding warning messages to BERT for missing attention masks\n\nThese warning messages are shown when the pad_token_id is not None\nand no attention masks are given. The warning message should only\nshow up once.",
        "Ran fix copies to copy over the changes to some of the other models",
        "Add logger.warning_once.cache_clear() to the test",
        "Shows warning when there are no attention masks and input_ids start/end with pad tokens",
        "Using warning_once() instead and fix indexing in input_ids check"
      ],
      "avg_commit_msg_length": 114.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": true,
      "has_docs": false,
      "test_files": [
        "tests/models/bert/test_modeling_bert.py",
        "tests/test_modeling_utils.py"
      ],
      "doc_files": [],
      "file_types": {
        "py": 12
      },
      "review_states": {
        "COMMENTED": 3,
        "APPROVED": 2
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nFixes #16136\r\n\r\nShows a one-time warning message when the pad_token_id is not None and no attention masks are given. \r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? #16136 \r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [x] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n@gante @ydshieh",
      "body_cleaned_length": 1129,
      "template_removed_length": 0,
      "template_reduction_percentage": 0.0,
      "author_type": "User"
    },
    "username": "hackyon"
  },
  {
    "pr_number": 24856,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 12789,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 24856,
      "title": "Replace assert statements with exceptions",
      "body": "# What does this PR do?\r\n\r\nI have replaced the assert statements with appropriate exceptions in the directory `src/transformers/models/` with all models beginning with `a` and `b` letters.\r\n\r\nAlso, I have corrected error handling at places where except statements were handling AssertionError, even thought it was never to be raised. Here is an example:\r\n\r\n```\r\ntry:\r\n    if pointer.shape != array.shape:\r\n        raise ValueError(f\"Pointer shape {pointer.shape} and array shape {array.shape} mismatched\")\r\nexcept AssertionError as e:    # Incorrect line\r\n    e.args += (pointer.shape, array.shape)\r\n    raise\r\n```\r\n\r\nI changed the above to:\r\n\r\n```\r\ntry:\r\n    if pointer.shape != array.shape:\r\n        raise ValueError(f\"Pointer shape {pointer.shape} and array shape {array.shape} mismatched\")\r\nexcept ValueError as e:    # Corrected the line\r\n    e.args += (pointer.shape, array.shape)\r\n    raise\r\n```\r\n\r\nFixes #12789 \r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n@ArthurZucker @sgugger \r\n",
      "body_length": 1806,
      "created_at": "2023-07-17T12:56:38Z",
      "merged_at": "2023-07-17T18:32:44Z",
      "merged": true,
      "time_to_merge_hours": 5.601666666666667,
      "state": "MERGED",
      "additions": 20,
      "deletions": 21,
      "files_changed": 8,
      "commits_count": 22,
      "review_count": 1,
      "comment_count": 1,
      "commit_messages": [
        "Changed AssertionError to ValueError\n\ntry-except block was using AssesrtionError in except statement while the expected error is value error. Fixed the same.",
        "Changed AssertionError to ValueError\n\ntry-except block was using AssesrtionError in except statement while the expected error is ValueError. Fixed the same.\nNote: While raising the ValueError args are passed to it, but later added again while handling the error (See the code snippet)",
        "Changed AssertionError to ValueError\n\ntry-except block was using AssesrtionError in except statement while the expected error is ValueError. Fixed the same.\nNote: While raising the ValueError args are passed to it, but later added again while handling the error (See the code snippet)",
        "Changed AssertionError to ValueError",
        "Changed AssertionError to ValueError",
        "Changed AssertionError to ValueError",
        "Changed AssertionError to ValueError",
        "Changed AssertionError to ValueError",
        "Changed assert statement to ValueError based",
        "Changed assert statement to ValueError based",
        "Changed assert statement to ValueError based",
        "Merge branch 'huggingface:main' into main",
        "Changed incorrect error handling from AssertionError to ValueError",
        "Merge branch 'main' of https://github.com/SalmanHabeeb/transformers\n\nMerge other commits",
        "Undoed change from AssertionError to ValueError as it is not needed",
        "Reverted back to using AssertionError as it is not necessary to make it into ValueError",
        "Merge branch 'huggingface:main' into main",
        "Fixed erraneous comparision\n\nChanged == to !=",
        "Merge branch 'main' of https://github.com/SalmanHabeeb/transformers\nMerge all commits",
        "Fixed erraneous comparision\n\nChanged == to !=",
        "formatted the code",
        "Ran make fix-copies"
      ],
      "avg_commit_msg_length": 74.5,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 8
      },
      "review_states": {
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nI have replaced the assert statements with appropriate exceptions in the directory `src/transformers/models/` with all models beginning with `a` and `b` letters.\r\n\r\nAlso, I have corrected error handling at places where except statements were handling AssertionError, even thought it was never to be raised. Here is an example:\r\n\r\n```\r\ntry:\r\n    if pointer.shape != array.shape:\r\n        raise ValueError(f\"Pointer shape {pointer.shape} and array shape {array.shape} mismatched\")\r\nexcept AssertionError as e:    # Incorrect line\r\n    e.args += (pointer.shape, array.shape)\r\n    raise\r\n```\r\n\r\nI changed the above to:\r\n\r\n```\r\ntry:\r\n    if pointer.shape != array.shape:\r\n        raise ValueError(f\"Pointer shape {pointer.shape} and array shape {array.shape} mismatched\")\r\nexcept ValueError as e:    # Corrected the line\r\n    e.args += (pointer.shape, array.shape)\r\n    raise\r\n```\r\n\r\nFixes #12789 \r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n@ArthurZucker @sgugger",
      "body_cleaned_length": 1803,
      "template_removed_length": 3,
      "template_reduction_percentage": 0.16611295681063123,
      "author_type": "User"
    },
    "username": "syedsalman137"
  },
  {
    "pr_number": 26250,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 26126,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 26250,
      "title": "Keypoints 0.0 are confusing ../transformers/models/detr/image_processing_detr.py which are fixed",
      "body": "# What does this PR do?\r\n\r\nThis PR will fix the keypoint 0.0 at this transformers/models/detr/image_processing_detr.py as suggested by @duckheada\r\n\r\nTo fix this, I had to edit this file in transformers library:\r\n.conda/lib/python3.9/site-packages/transformers/models/detr/image_processing_detr.py\r\n\r\nI changed this as suggested by: @duckheada\r\n  \r\n```python\r\n    if annotations and \"keypoints\" in annotations[0]:\r\n       keypoints = [obj[\"keypoints\"] for obj in annotations]\r\n       print(\"keypoints\", keypoints) #TODO: remove\r\n       keypoints = np.asarray(keypoints, dtype=np.float32)\r\n       num_keypoints = keypoints.shape[0]\r\n       keypoints = keypoints.reshape((-1, 3)) if num_keypoints else keypoints\r\n       new_target[\"keypoints\"] = keypoints[keep]\r\n```\r\nTo this:\r\n```python\r\n    if annotations and \"keypoints\" in annotations[0]:\r\n     keypoints = [obj[\"keypoints\"] for obj in annotations]\r\n     # Apply the keep mask here to filter the relevant annotations\r\n     keypoints = [keypoints[i] for i in range(len(keypoints)) if keep[i]]\r\n     # converting the filtered keypoints list to a numpy array and reshape it\r\n     keypoints = np.asarray(keypoints, dtype=np.float32)\r\n     num_keypoints = keypoints.shape[0]\r\n     keypoints = keypoints.reshape((-1, 3)) if num_keypoints else keypoints\r\n     new_target[\"keypoints\"] = keypoints # We no longer apply keep mask here\r\n```\r\nWhy?\r\nTo ensure that the filtering applied to the key points respects its original structure (number of keypoints per annotation). When you reshape keypoints with key points. reshape((-1, 3)), it loses the information about which keypoints belong to which annotation.\r\n\r\nHere is what needed to be done (at least in my little hack-ish workaround):\r\n\r\nBefore reshaping the key points array, I had to apply the keep mask to retain only the annotations I was interested in. Only after this could I reshape the keypoints array to apply further operations.\r\nThen, I applied the keep mask on the keypoints list before converting it into a numpy array and reshaping it. This ensured that I only keep the keypoints corresponding to the bounding boxes that satisfy the condition in the keep mask.\r\n\r\nFixes #26126 \r\n\r\n## Who can review?\r\n\r\n@ArthurZucker, @younesbelkada, and @amyeroberts \r\nPlease let me know if I need to do anything else for this issue.\r\n",
      "body_length": 2327,
      "created_at": "2023-09-19T08:39:14Z",
      "merged_at": "2023-12-04T09:29:13Z",
      "merged": true,
      "time_to_merge_hours": 1824.8330555555556,
      "state": "MERGED",
      "additions": 20,
      "deletions": 5,
      "files_changed": 5,
      "commits_count": 12,
      "review_count": 10,
      "comment_count": 3,
      "commit_messages": [
        "Keypoints 0.0 is fixed",
        "fixed keypoints for image_processing_yolos",
        "fixed keypoints for image_processing_deta",
        "fixed keypoints for image_processing_deformable_detr",
        "fixed keypoints for image_processing_conditional_detr",
        "fixed styles",
        "Removed Comments",
        "Removed comment form conditional detr too",
        "Removed Extra code",
        "make fix-copes",
        "Fixed code quality",
        "keypoints changes"
      ],
      "avg_commit_msg_length": 28.833333333333332,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 5
      },
      "review_states": {
        "COMMENTED": 8,
        "APPROVED": 2
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nThis PR will fix the keypoint 0.0 at this transformers/models/detr/image_processing_detr.py as suggested by @duckheada\r\n\r\nTo fix this, I had to edit this file in transformers library:\r\n.conda/lib/python3.9/site-packages/transformers/models/detr/image_processing_detr.py\r\n\r\nI changed this as suggested by: @duckheada\r\n  \r\n```python\r\n    if annotations and \"keypoints\" in annotations[0]:\r\n       keypoints = [obj[\"keypoints\"] for obj in annotations]\r\n       print(\"keypoints\", keypoints) #TODO: remove\r\n       keypoints = np.asarray(keypoints, dtype=np.float32)\r\n       num_keypoints = keypoints.shape[0]\r\n       keypoints = keypoints.reshape((-1, 3)) if num_keypoints else keypoints\r\n       new_target[\"keypoints\"] = keypoints[keep]\r\n```\r\nTo this:\r\n```python\r\n    if annotations and \"keypoints\" in annotations[0]:\r\n     keypoints = [obj[\"keypoints\"] for obj in annotations]\r\n     # Apply the keep mask here to filter the relevant annotations\r\n     keypoints = [keypoints[i] for i in range(len(keypoints)) if keep[i]]\r\n     # converting the filtered keypoints list to a numpy array and reshape it\r\n     keypoints = np.asarray(keypoints, dtype=np.float32)\r\n     num_keypoints = keypoints.shape[0]\r\n     keypoints = keypoints.reshape((-1, 3)) if num_keypoints else keypoints\r\n     new_target[\"keypoints\"] = keypoints # We no longer apply keep mask here\r\n```\r\nWhy?\r\nTo ensure that the filtering applied to the key points respects its original structure (number of keypoints per annotation). When you reshape keypoints with key points. reshape((-1, 3)), it loses the information about which keypoints belong to which annotation.\r\n\r\nHere is what needed to be done (at least in my little hack-ish workaround):\r\n\r\nBefore reshaping the key points array, I had to apply the keep mask to retain only the annotations I was interested in. Only after this could I reshape the keypoints array to apply further operations.\r\nThen, I applied the keep mask on the keypoints list before converting it into a numpy array and reshaping it. This ensured that I only keep the keypoints corresponding to the bounding boxes that satisfy the condition in the keep mask.\r\n\r\nFixes #26126 \r\n\r\n## Who can review?\r\n\r\n@ArthurZucker, @younesbelkada, and @amyeroberts \r\nPlease let me know if I need to do anything else for this issue.",
      "body_cleaned_length": 2325,
      "template_removed_length": 2,
      "template_reduction_percentage": 0.08594757198109154,
      "author_type": "User"
    },
    "username": "hackpk"
  },
  {
    "pr_number": 26519,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 19487,
        "labels": [
          "Good First Issue",
          "HACKTOBERFEST-ACCEPTED"
        ]
      }
    ],
    "pr_data": {
      "number": 26519,
      "title": "[Doctest] Add `configuration_encoder_decoder.py`",
      "body": "# What does this PR do?\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes #19487 \r\n\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- text models: @ArthurZucker and @younesbelkada\r\n- vision models: @amyeroberts\r\n- speech models: @sanchit-gandhi\r\n- graph models: @clefourrier\r\n\r\nLibrary:\r\n\r\n- flax: @sanchit-gandhi\r\n- generate: @gante\r\n- pipelines: @Narsil\r\n- tensorflow: @gante and @Rocketknight1\r\n- tokenizers: @ArthurZucker\r\n- trainer: @muellerzr and @pacman100\r\n\r\nIntegrations:\r\n\r\n- deepspeed: HF Trainer/Accelerate: @pacman100\r\n- ray/raytune: @richardliaw, @amogkam\r\n- Big Model Inference: @SunMarc\r\n- quantization (bitsandbytes, autogpt): @SunMarc and @younesbelkada\r\n\r\nDocumentation: @stevhliu and @MKhalusova\r\n\r\nHF projects:\r\n\r\n- accelerate: [different repo](https://github.com/huggingface/accelerate)\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- diffusers: [different repo](https://github.com/huggingface/diffusers)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nMaintained examples (not research project or legacy):\r\n\r\n- Flax: @sanchit-gandhi\r\n- PyTorch: See Models above and tag the person corresponding to the modality of the example.\r\n- TensorFlow: @Rocketknight1\r\n\r\n -->\r\n",
      "body_length": 3307,
      "created_at": "2023-10-01T16:14:19Z",
      "merged_at": "2023-10-03T09:21:25Z",
      "merged": true,
      "time_to_merge_hours": 41.11833333333333,
      "state": "MERGED",
      "additions": 1,
      "deletions": 2,
      "files_changed": 2,
      "commits_count": 7,
      "review_count": 5,
      "comment_count": 2,
      "commit_messages": [
        "[Doctest] Add configuration_encoder_decoder.py\n\nAdded configuration_encoder_decoder.py to utils/documentation_tests.txt for doctest",
        "Revert \"[Doctest] Add configuration_encoder_decoder.py\"\n\nThis reverts commit bd653535a4356dc3c9f43e65883819079a2053b0.",
        "[Doctest] Add configuration_encoder_decoder.py\n\nadd configuration_encoder_decoder.py to utils/documentation_tests.txt",
        "[Doctest] Add configuration_encoder_decoder.py\n\nadd configuration_encoder_decoder.py to utils/documentation_tests.txt",
        "[Doctest] Add configuration_encoder_decoder.py\n\nadd configuration_encoder_decoder.py to utils/documentation_tests.txt",
        "changed as per request",
        "fixed line 46"
      ],
      "avg_commit_msg_length": 90.71428571428571,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": true,
      "test_files": [],
      "doc_files": [
        "utils/not_doctested.txt"
      ],
      "file_types": {
        "py": 1,
        "txt": 1
      },
      "review_states": {
        "COMMENTED": 4,
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\n\r\n\r\n\r\n\r\nFixes #19487 \r\n\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.",
      "body_cleaned_length": 1059,
      "template_removed_length": 2248,
      "template_reduction_percentage": 67.9770184457212,
      "author_type": "User"
    },
    "username": "SrijanSahaySrivastava"
  },
  {
    "pr_number": 26661,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 26638,
        "labels": [
          "Good First Issue",
          "HACKTOBERFEST-ACCEPTED"
        ]
      }
    ],
    "pr_data": {
      "number": 26661,
      "title": "[docstring] Fix docstring for 'BertGenerationConfig'",
      "body": "Fixes #26638\r\n## Before Submitting\r\n\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x]  Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests), Pull Request section?\r\n- [x]  Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link to it if that's the case.\r\n- [x]  Did you make sure to update the documentation with your changes? Here are the [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n## Who can Review?\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag members/contributors who may be interested in your PR.\r\n",
      "body_length": 993,
      "created_at": "2023-10-07T15:34:32Z",
      "merged_at": "2023-10-12T15:01:14Z",
      "merged": true,
      "time_to_merge_hours": 119.445,
      "state": "MERGED",
      "additions": 7,
      "deletions": 4,
      "files_changed": 2,
      "commits_count": 2,
      "review_count": 1,
      "comment_count": 3,
      "commit_messages": [
        "[docstring] Remove 'BertGenerationConfig' from OBJECTS_TO_IGNORE",
        "[docstring] Fix docstring for 'BertGenerationConfig' (#26638)"
      ],
      "avg_commit_msg_length": 62.5,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 2
      },
      "review_states": {
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "Fixes #26638\r\n## Before Submitting\r\n\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x]  Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests), Pull Request section?\r\n- [x]  Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link to it if that's the case.\r\n- [x]  Did you make sure to update the documentation with your changes? Here are the [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n## Who can Review?\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag members/contributors who may be interested in your PR.",
      "body_cleaned_length": 991,
      "template_removed_length": 2,
      "template_reduction_percentage": 0.2014098690835851,
      "author_type": "User"
    },
    "username": "AdwaitSalankar"
  },
  {
    "pr_number": 26664,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 26638,
        "labels": [
          "Good First Issue",
          "HACKTOBERFEST-ACCEPTED"
        ]
      }
    ],
    "pr_data": {
      "number": 26664,
      "title": "[docstring] Fix docstrings for `UniSpeechConfig`, `UniSpeechForCTC`, `UniSpeechSatConfig`, `UniSpeechSatForCTC` and `Wav2Vec2ForCTC`",
      "body": "Fixes #26638 \r\n\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n@ydshieh\r\n",
      "body_length": 1038,
      "created_at": "2023-10-08T00:03:34Z",
      "merged_at": "2023-10-12T14:51:35Z",
      "merged": true,
      "time_to_merge_hours": 110.80027777777778,
      "state": "MERGED",
      "additions": 54,
      "deletions": 27,
      "files_changed": 6,
      "commits_count": 11,
      "review_count": 8,
      "comment_count": 4,
      "commit_messages": [
        "Remove UniSpeechConfig",
        "Remove , at the end otherwise check_docstring changes order",
        "Auto add new docstring",
        "Update docstring for UniSpeechConfig",
        "Remove from check_docstrings",
        "Remove UniSpeechSatConfig and UniSpeechSatForCTC from check_docstrings",
        "Remove , at the end",
        "Fix docstring",
        "Update docstring for Wav2Vec2ForCTC",
        "Update Wav2Vec2ForCTC docstring\n\nCo-authored-by: Yih-Dar <2521628+ydshieh@users.noreply.github.com>",
        "fix style"
      ],
      "avg_commit_msg_length": 37.45454545454545,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 6
      },
      "review_states": {
        "COMMENTED": 7,
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "Fixes #26638 \r\n\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n@ydshieh",
      "body_cleaned_length": 1036,
      "template_removed_length": 2,
      "template_reduction_percentage": 0.1926782273603083,
      "author_type": "User"
    },
    "username": "gizemt"
  },
  {
    "pr_number": 26666,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 26638,
        "labels": [
          "Good First Issue",
          "HACKTOBERFEST-ACCEPTED"
        ]
      }
    ],
    "pr_data": {
      "number": 26666,
      "title": "[docstring] Fix docstring for `CodeLlamaTokenizerFast`",
      "body": "# What does this PR do?\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes #26638\r\n\r\n\r\n## Before submitting\r\n- [X] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [X] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- text models: @ArthurZucker and @younesbelkada\r\n- vision models: @amyeroberts\r\n- speech models: @sanchit-gandhi\r\n- graph models: @clefourrier\r\n\r\nLibrary:\r\n\r\n- flax: @sanchit-gandhi\r\n- generate: @gante\r\n- pipelines: @Narsil\r\n- tensorflow: @gante and @Rocketknight1\r\n- tokenizers: @ArthurZucker\r\n- trainer: @muellerzr and @pacman100\r\n\r\nIntegrations:\r\n\r\n- deepspeed: HF Trainer/Accelerate: @pacman100\r\n- ray/raytune: @richardliaw, @amogkam\r\n- Big Model Inference: @SunMarc\r\n- quantization (bitsandbytes, autogpt): @SunMarc and @younesbelkada\r\n\r\nDocumentation: @stevhliu and @MKhalusova\r\n\r\nHF projects:\r\n\r\n- accelerate: [different repo](https://github.com/huggingface/accelerate)\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- diffusers: [different repo](https://github.com/huggingface/diffusers)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nMaintained examples (not research project or legacy):\r\n\r\n- Flax: @sanchit-gandhi\r\n- PyTorch: See Models above and tag the person corresponding to the modality of the example.\r\n- TensorFlow: @Rocketknight1\r\n\r\n -->\r\n",
      "body_length": 382,
      "created_at": "2023-10-08T04:36:01Z",
      "updated_at": "2023-10-16T08:11:46Z",
      "closed_at": "2023-10-16T08:11:46Z",
      "merged_at": "2023-10-16T08:11:46Z",
      "merged": true,
      "state": "MERGED",
      "time_to_merge_hours": 195.59583333333333,
      "additions": 12,
      "deletions": 11,
      "files_changed": 2,
      "commits_count": 5,
      "review_count": 4,
      "comment_count": 13,
      "pr_size": 23,
      "avg_commit_msg_length": 29.4,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 2
      },
      "review_states": {
        "COMMENTED": 3,
        "APPROVED": 1
      },
      "has_changes_requested": false,
      "has_approved": true,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\n\r\n\r\n\r\n\r\nFixes #26638\r\n\r\n\r\n## Before submitting\r\n- [X] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [X] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.",
      "body_cleaned_length": 534,
      "template_removed_length": 2248,
      "template_reduction_percentage": 80.80517613227893,
      "author_type": "User"
    },
    "username": "Bojun-Feng"
  },
  {
    "pr_number": 26669,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 26638,
        "labels": [
          "Good First Issue",
          "HACKTOBERFEST-ACCEPTED"
        ]
      }
    ],
    "pr_data": {
      "number": 26669,
      "title": "[docstring] Fix docstring for `LlamaTokenizer` and `LlamaTokenizerFast`",
      "body": "# What does this PR do?\r\n\r\nFixes #26638 only for `LlamaTokenizer` and `LlamaTokenizerFast`.\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n@ArthurZucker and @younesbelkada\r\n",
      "body_length": 1138,
      "created_at": "2023-10-08T10:59:40Z",
      "merged_at": "2023-10-11T15:03:32Z",
      "merged": true,
      "time_to_merge_hours": 76.06444444444445,
      "state": "MERGED",
      "additions": 58,
      "deletions": 22,
      "files_changed": 4,
      "commits_count": 3,
      "review_count": 9,
      "comment_count": 4,
      "commit_messages": [
        "[docstring] Fix docstring for `LlamaTokenizer` and `LlamaTokenizerFast`",
        "Merge branch 'main' into chore/docstring-tokenization_llama",
        "[docstring] Fix docstring typo at `LlamaTokenizer` and `LlamaTokenizerFast`"
      ],
      "avg_commit_msg_length": 68.33333333333333,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": true,
      "test_files": [],
      "doc_files": [
        "utils/not_doctested.txt"
      ],
      "file_types": {
        "py": 3,
        "txt": 1
      },
      "review_states": {
        "COMMENTED": 8,
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nFixes #26638 only for `LlamaTokenizer` and `LlamaTokenizerFast`.\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n@ArthurZucker and @younesbelkada",
      "body_cleaned_length": 1136,
      "template_removed_length": 2,
      "template_reduction_percentage": 0.17574692442882248,
      "author_type": "User"
    },
    "username": "minhoryang"
  },
  {
    "pr_number": 26658,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 26638,
        "labels": [
          "Good First Issue",
          "HACKTOBERFEST-ACCEPTED"
        ]
      }
    ],
    "pr_data": {
      "number": 26658,
      "title": "[docstring] Fix docstring for `LlamaConfig`",
      "body": "# What does this PR do?\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes #26638  by fixing a typo in docstring of `LlamaConfig`\r\n\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n@ydshieh \r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- text models: @ArthurZucker and @younesbelkada\r\n- vision models: @amyeroberts\r\n- speech models: @sanchit-gandhi\r\n- graph models: @clefourrier\r\n\r\nLibrary:\r\n\r\n- flax: @sanchit-gandhi\r\n- generate: @gante\r\n- pipelines: @Narsil\r\n- tensorflow: @gante and @Rocketknight1\r\n- tokenizers: @ArthurZucker\r\n- trainer: @muellerzr and @pacman100\r\n\r\nIntegrations:\r\n\r\n- deepspeed: HF Trainer/Accelerate: @pacman100\r\n- ray/raytune: @richardliaw, @amogkam\r\n- Big Model Inference: @SunMarc\r\n- quantization (bitsandbytes, autogpt): @SunMarc and @younesbelkada\r\n\r\nDocumentation: @stevhliu and @MKhalusova\r\n\r\nHF projects:\r\n\r\n- accelerate: [different repo](https://github.com/huggingface/accelerate)\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- diffusers: [different repo](https://github.com/huggingface/diffusers)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nMaintained examples (not research project or legacy):\r\n\r\n- Flax: @sanchit-gandhi\r\n- PyTorch: See Models above and tag the person corresponding to the modality of the example.\r\n- TensorFlow: @Rocketknight1\r\n\r\n -->\r\n",
      "body_length": 732,
      "created_at": "2023-10-07T14:33:15Z",
      "updated_at": "2023-10-09T08:46:42Z",
      "closed_at": "2023-10-09T08:43:00Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 15,
      "deletions": 10,
      "files_changed": 2,
      "commits_count": 6,
      "review_count": 0,
      "comment_count": 6,
      "pr_size": 25,
      "avg_commit_msg_length": 45.5,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 2
      },
      "review_states": {},
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\n\r\n\r\n\r\n\r\nFixes #26638  by fixing a typo in docstring of `LlamaConfig`\r\n\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n@ydshieh \r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.",
      "body_cleaned_length": 1115,
      "template_removed_length": 2248,
      "template_reduction_percentage": 66.84507879869165,
      "author_type": "User"
    },
    "username": "pavaris-pm"
  },
  {
    "pr_number": 26643,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 26638,
        "labels": [
          "Good First Issue",
          "HACKTOBERFEST-ACCEPTED"
        ]
      }
    ],
    "pr_data": {
      "number": 26643,
      "title": "[WIP] Remove ZeroShotObjectDetectionPipeline from check_docstrings.py",
      "body": "# What does this PR do?\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes #26638 \r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- text models: @ArthurZucker and @younesbelkada\r\n- vision models: @amyeroberts\r\n- speech models: @sanchit-gandhi\r\n- graph models: @clefourrier\r\n\r\nLibrary:\r\n\r\n- flax: @sanchit-gandhi\r\n- generate: @gante\r\n- pipelines: @Narsil\r\n- tensorflow: @gante and @Rocketknight1\r\n- tokenizers: @ArthurZucker\r\n- trainer: @muellerzr and @pacman100\r\n\r\nIntegrations:\r\n\r\n- deepspeed: HF Trainer/Accelerate: @pacman100\r\n- ray/raytune: @richardliaw, @amogkam\r\n- Big Model Inference: @SunMarc\r\n- quantization (bitsandbytes, autogpt): @SunMarc and @younesbelkada\r\n\r\nDocumentation: @stevhliu and @MKhalusova\r\n\r\nHF projects:\r\n\r\n- accelerate: [different repo](https://github.com/huggingface/accelerate)\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- diffusers: [different repo](https://github.com/huggingface/diffusers)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nMaintained examples (not research project or legacy):\r\n\r\n- Flax: @sanchit-gandhi\r\n- PyTorch: See Models above and tag the person corresponding to the modality of the example.\r\n- TensorFlow: @Rocketknight1\r\n\r\n -->\r\n",
      "body_length": 677,
      "created_at": "2023-10-06T21:39:01Z",
      "updated_at": "2023-10-12T21:20:33Z",
      "closed_at": "2023-10-12T21:20:32Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 0,
      "deletions": 1,
      "files_changed": 1,
      "commits_count": 1,
      "review_count": 0,
      "comment_count": 5,
      "pr_size": 1,
      "avg_commit_msg_length": 63.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {},
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\n\r\n\r\n\r\n\r\nFixes #26638 \r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.",
      "body_cleaned_length": 1059,
      "template_removed_length": 2248,
      "template_reduction_percentage": 67.9770184457212,
      "author_type": "User"
    },
    "username": "Sparty"
  },
  {
    "pr_number": 26883,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 26638,
        "labels": [
          "Good First Issue",
          "HACKTOBERFEST-ACCEPTED"
        ]
      }
    ],
    "pr_data": {
      "number": 26883,
      "title": "[docstring] Fix docstring for speech-to-text config",
      "body": "# What does this PR do?\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes #26638 \r\n\r\nFix doc string for speech-to-text configuration.\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- text models: @ArthurZucker and @younesbelkada\r\n- vision models: @amyeroberts\r\n- speech models: @sanchit-gandhi\r\n- graph models: @clefourrier\r\n\r\nLibrary:\r\n\r\n- flax: @sanchit-gandhi\r\n- generate: @gante\r\n- pipelines: @Narsil\r\n- tensorflow: @gante and @Rocketknight1\r\n- tokenizers: @ArthurZucker\r\n- trainer: @muellerzr and @pacman100\r\n\r\nIntegrations:\r\n\r\n- deepspeed: HF Trainer/Accelerate: @pacman100\r\n- ray/raytune: @richardliaw, @amogkam\r\n- Big Model Inference: @SunMarc\r\n- quantization (bitsandbytes, autogpt): @SunMarc and @younesbelkada\r\n\r\nDocumentation: @stevhliu and @MKhalusova\r\n\r\nHF projects:\r\n\r\n- accelerate: [different repo](https://github.com/huggingface/accelerate)\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- diffusers: [different repo](https://github.com/huggingface/diffusers)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nMaintained examples (not research project or legacy):\r\n\r\n- Flax: @sanchit-gandhi\r\n- PyTorch: See Models above and tag the person corresponding to the modality of the example.\r\n- TensorFlow: @Rocketknight1\r\n\r\n -->\r\n",
      "body_length": 3357,
      "created_at": "2023-10-17T21:25:54Z",
      "merged_at": "2023-10-20T07:49:55Z",
      "merged": true,
      "time_to_merge_hours": 58.40027777777778,
      "state": "MERGED",
      "additions": 34,
      "deletions": 23,
      "files_changed": 2,
      "commits_count": 6,
      "review_count": 3,
      "comment_count": 9,
      "commit_messages": [
        "Fix docstring for speech-to-text config",
        "Refactor doc line len <= 119 char",
        "Remove Speech2TextConfig from OBJECTS_TO_IGNORE",
        "Fix Speech2TextConfig doc str",
        "Fix Speech2TextConfig doc using doc-builder",
        "Refactor Speech2TextConfig doc"
      ],
      "avg_commit_msg_length": 36.833333333333336,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 2
      },
      "review_states": {
        "COMMENTED": 2,
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\n\r\n\r\n\r\n\r\nFixes #26638 \r\n\r\nFix doc string for speech-to-text configuration.\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.",
      "body_cleaned_length": 1109,
      "template_removed_length": 2248,
      "template_reduction_percentage": 66.96455168305035,
      "author_type": "User"
    },
    "username": "R055A"
  },
  {
    "pr_number": 27128,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 26638,
        "labels": [
          "Good First Issue",
          "HACKTOBERFEST-ACCEPTED"
        ]
      }
    ],
    "pr_data": {
      "number": 27128,
      "title": "[docstring] Fix docstring for AltCLIPTextConfig, AltCLIPVisionConfig and AltCLIPConfig",
      "body": "# What does this PR do?\r\n\r\n - Fixed docstrings for AltCLIPTextConfig, AltCLIPVisionConfig and AltCLIPConfig\r\n - Cleaned few docstrings\r\n\r\nFixes #26638\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n\r\n\r\n",
      "body_length": 1165,
      "created_at": "2023-10-29T02:40:46Z",
      "merged_at": "2023-10-31T10:20:15Z",
      "merged": true,
      "time_to_merge_hours": 55.658055555555556,
      "state": "MERGED",
      "additions": 26,
      "deletions": 17,
      "files_changed": 10,
      "commits_count": 7,
      "review_count": 3,
      "comment_count": 5,
      "commit_messages": [
        "[docstring] Fix docstring for AltCLIPVisionConfig, AltCLIPTextConfig + cleaned some docstring",
        "Merge branch 'huggingface:main' into contributing-docstring",
        "Removed entries from check_docstring.py",
        "Removed entries from check_docstring.py",
        "Removed entry from check_docstring.py",
        "[docstring] Fix docstring for AltCLIPTextConfig, AltCLIPVisionConfig and AltCLIPConfig",
        "Merge branch 'huggingface:main' into contributing-docstring"
      ],
      "avg_commit_msg_length": 58.857142857142854,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 10
      },
      "review_states": {
        "APPROVED": 2,
        "COMMENTED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\n - Fixed docstrings for AltCLIPTextConfig, AltCLIPVisionConfig and AltCLIPConfig\r\n - Cleaned few docstrings\r\n\r\nFixes #26638\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.",
      "body_cleaned_length": 1157,
      "template_removed_length": 8,
      "template_reduction_percentage": 0.6866952789699571,
      "author_type": "User"
    },
    "username": "AksharGoyal"
  },
  {
    "pr_number": 27191,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 27185,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 27191,
      "title": "fixing docstring in get_resize_output_image_size function",
      "body": "# What does this PR do?\r\nFixes #27185 \r\n\r\n\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n@amyeroberts \r\n@rafaelpadilla \r\n\r\n\r\n",
      "body_length": 554,
      "created_at": "2023-10-31T18:10:03Z",
      "updated_at": "2023-11-01T12:42:41Z",
      "closed_at": "2023-11-01T12:42:41Z",
      "merged_at": "2023-11-01T12:42:41Z",
      "merged": true,
      "state": "MERGED",
      "time_to_merge_hours": 18.54388888888889,
      "additions": 15,
      "deletions": 15,
      "files_changed": 5,
      "commits_count": 1,
      "review_count": 2,
      "comment_count": 1,
      "pr_size": 30,
      "avg_commit_msg_length": 57.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 5
      },
      "review_states": {
        "APPROVED": 2
      },
      "has_changes_requested": false,
      "has_approved": true,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\nFixes #27185 \r\n\r\n\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n@amyeroberts \r\n@rafaelpadilla",
      "body_cleaned_length": 929,
      "template_removed_length": 7,
      "template_reduction_percentage": 0.7478632478632479,
      "author_type": "User"
    },
    "username": "wesleylp"
  },
  {
    "pr_number": 28884,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 27902,
        "labels": [
          "Good First Issue",
          "Good First Documentation Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 28884,
      "title": "fix: Fixed the documentation for `logging_first_step` by removing \"evaluate\"",
      "body": "# What does this PR do?\r\nDocument says that [logging_first_step](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments.logging_first_step) will evaluate on the first global_step. But it only logs on the first step, not evaluate.\r\n\r\nFixes #27902\r\n\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n",
      "body_length": 1119,
      "created_at": "2024-02-06T05:27:17Z",
      "merged_at": "2024-02-07T07:46:37Z",
      "merged": true,
      "time_to_merge_hours": 26.322222222222223,
      "state": "MERGED",
      "additions": 1,
      "deletions": 1,
      "files_changed": 1,
      "commits_count": 1,
      "review_count": 2,
      "comment_count": 2,
      "commit_messages": [
        "Fixed the documentation for logging_first_step by removing evaluate."
      ],
      "avg_commit_msg_length": 68.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {
        "APPROVED": 2
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\nDocument says that [logging_first_step](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments.logging_first_step) will evaluate on the first global_step. But it only logs on the first step, not evaluate.\r\n\r\nFixes #27902\r\n\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?",
      "body_cleaned_length": 1117,
      "template_removed_length": 2,
      "template_reduction_percentage": 0.17873100983020554,
      "author_type": "User"
    },
    "username": "Sai-Suraj-27"
  },
  {
    "pr_number": 29265,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 28098,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 29265,
      "title": "Add token type ids to CodeGenTokenizer",
      "body": "# What does this PR do?\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes #28098 \r\n\r\n## Who can review?\r\n\r\n@ArthurZucker @younesbelkada\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- text models: @ArthurZucker and @younesbelkada\r\n- vision models: @amyeroberts\r\n- speech models: @sanchit-gandhi\r\n- graph models: @clefourrier\r\n\r\nLibrary:\r\n\r\n- flax: @sanchit-gandhi\r\n- generate: @gante\r\n- pipelines: @Narsil\r\n- tensorflow: @gante and @Rocketknight1\r\n- tokenizers: @ArthurZucker\r\n- trainer: @muellerzr and @pacman100\r\n\r\nIntegrations:\r\n\r\n- deepspeed: HF Trainer/Accelerate: @pacman100\r\n- ray/raytune: @richardliaw, @amogkam\r\n- Big Model Inference: @SunMarc\r\n- quantization (bitsandbytes, autogpt): @SunMarc and @younesbelkada\r\n\r\nDocumentation: @stevhliu and @MKhalusova\r\n\r\nHF projects:\r\n\r\n- accelerate: [different repo](https://github.com/huggingface/accelerate)\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- diffusers: [different repo](https://github.com/huggingface/diffusers)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nMaintained examples (not research project or legacy):\r\n\r\n- Flax: @sanchit-gandhi\r\n- PyTorch: See Models above and tag the person corresponding to the modality of the example.\r\n- TensorFlow: @Rocketknight1\r\n\r\n -->\r\n",
      "body_length": 2350,
      "created_at": "2024-02-24T02:14:31Z",
      "merged_at": "2024-04-17T10:19:18Z",
      "merged": true,
      "time_to_merge_hours": 1280.0797222222222,
      "state": "MERGED",
      "additions": 127,
      "deletions": 0,
      "files_changed": 4,
      "commits_count": 14,
      "review_count": 11,
      "comment_count": 16,
      "commit_messages": [
        "Add create token type ids to CodeGenTokenizer",
        "Fix inconsistent length of token type ids",
        "Format source codes",
        "Fix inconsistent order of methods",
        "Update docstring",
        "add test_tokenizer_integration test",
        "Format source codes",
        "Add `copied from` comment to CodeGenTokenizerFast",
        "Add doc of create_token_type_ids_from_sequences",
        "Make return_token_type_ids False by default",
        "Make test_tokenizer_integration as slow test",
        "Add return_token_type_ids to tokenizer init arg",
        "Add test for tokenizer's init return_token_type_ids",
        "Format source codes"
      ],
      "avg_commit_msg_length": 36.285714285714285,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": true,
      "has_docs": true,
      "test_files": [
        "tests/models/codegen/test_tokenization_codegen.py"
      ],
      "doc_files": [
        "docs/source/en/model_doc/codegen.md"
      ],
      "file_types": {
        "md": 1,
        "py": 3
      },
      "review_states": {
        "COMMENTED": 10,
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\n\r\n\r\n\r\n\r\nFixes #28098 \r\n\r\n## Who can review?\r\n\r\n@ArthurZucker @younesbelkada",
      "body_cleaned_length": 102,
      "template_removed_length": 2248,
      "template_reduction_percentage": 95.65957446808511,
      "author_type": "User"
    },
    "username": "st81"
  },
  {
    "pr_number": 29661,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 27142,
        "labels": [
          "Documentation",
          "bug",
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 29661,
      "title": "Inaccurate code example within inline code-documentation",
      "body": "Changes the inline code-documentation for better and accurate example\r\n\r\nFixes #27142 \r\n\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n",
      "body_length": 911,
      "created_at": "2024-03-14T17:16:28Z",
      "merged_at": "2024-03-14T19:59:32Z",
      "merged": true,
      "time_to_merge_hours": 2.7177777777777776,
      "state": "MERGED",
      "additions": 2,
      "deletions": 2,
      "files_changed": 2,
      "commits_count": 2,
      "review_count": 1,
      "comment_count": 2,
      "commit_messages": [
        "docs:inaccurate_code_example",
        "Inaccurate code example within inline code-documentation"
      ],
      "avg_commit_msg_length": 42.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 2
      },
      "review_states": {
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "Changes the inline code-documentation for better and accurate example\r\n\r\nFixes #27142 \r\n\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?",
      "body_cleaned_length": 909,
      "template_removed_length": 2,
      "template_reduction_percentage": 0.21953896816684962,
      "author_type": "User"
    },
    "username": "MysteryManav"
  },
  {
    "pr_number": 29712,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 26099,
        "labels": [
          "Good First Issue",
          "Vision"
        ]
      }
    ],
    "pr_data": {
      "number": 29712,
      "title": "OWL-ViT box_predictor inefficiency issue",
      "body": "I am calculating box_bias at the start while initialization, and storing it in a variable, then reusing it at inference. Also, shifting it to the correct memory location at the interence time.\r\nI also converted the numpy implementation to torch implementation, and verified that both are giving the same results.\r\n\r\nFixes #26099 \r\n\r\n@5hadytru @amyeroberts\r\nCan you please review?\r\nI updated the code to the best of my knwoledge. Please let me know if you need any changes. Thanks.\r\n",
      "body_length": 482,
      "created_at": "2024-03-18T12:56:04Z",
      "merged_at": "2024-03-21T11:17:45Z",
      "merged": true,
      "time_to_merge_hours": 70.36138888888888,
      "state": "MERGED",
      "additions": 40,
      "deletions": 42,
      "files_changed": 2,
      "commits_count": 9,
      "review_count": 5,
      "comment_count": 4,
      "commit_messages": [
        "Calculating box_bias at the start once, then reusing it at inference",
        "Updating the compute_box_bias function for backwards compatibility",
        "Caching compute_box_bias function",
        "Bux fix",
        "Update owlv2 accordingly to ensure repo consistency",
        "Co-authored by: nvbinh15 <binh.pdc01@gmail.com>",
        "Fixup changes",
        "Made copied code consistent",
        "Co-authored by: nvbinh15 <binh.pdc01@gmail.com>"
      ],
      "avg_commit_msg_length": 39.888888888888886,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 2
      },
      "review_states": {
        "COMMENTED": 4,
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "I am calculating box_bias at the start while initialization, and storing it in a variable, then reusing it at inference. Also, shifting it to the correct memory location at the interence time.\r\nI also converted the numpy implementation to torch implementation, and verified that both are giving the same results.\r\n\r\nFixes #26099 \r\n\r\n@5hadytru @amyeroberts\r\nCan you please review?\r\nI updated the code to the best of my knwoledge. Please let me know if you need any changes. Thanks.",
      "body_cleaned_length": 480,
      "template_removed_length": 2,
      "template_reduction_percentage": 0.4149377593360996,
      "author_type": "User"
    },
    "username": "RVV-karma"
  },
  {
    "pr_number": 29776,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 29697,
        "labels": [
          "Examples",
          "Good First Issue",
          "Feature request"
        ]
      }
    ],
    "pr_data": {
      "number": 29776,
      "title": "Add support for `torch_dtype` in the run_mlm example",
      "body": "# What does this PR do?\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes #29697 (issue)\r\n\r\n- match the `torch_dtype` argument in [run_clm](https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_clm.py)\r\n- `max_seq_length` is very similar to `block_size` and is left unchanged\r\n\r\n## Who can review?\r\n\r\n@galtay and @amyeroberts\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- text models: @ArthurZucker and @younesbelkada\r\n- vision models: @amyeroberts\r\n- speech models: @sanchit-gandhi\r\n- graph models: @clefourrier\r\n\r\nLibrary:\r\n\r\n- flax: @sanchit-gandhi\r\n- generate: @gante\r\n- pipelines: @Narsil\r\n- tensorflow: @gante and @Rocketknight1\r\n- tokenizers: @ArthurZucker\r\n- trainer: @muellerzr and @pacman100\r\n\r\nIntegrations:\r\n\r\n- deepspeed: HF Trainer/Accelerate: @pacman100\r\n- ray/raytune: @richardliaw, @amogkam\r\n- Big Model Inference: @SunMarc\r\n- quantization (bitsandbytes, autogpt): @SunMarc and @younesbelkada\r\n\r\nDocumentation: @stevhliu and @MKhalusova\r\n\r\nHF projects:\r\n\r\n- accelerate: [different repo](https://github.com/huggingface/accelerate)\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- diffusers: [different repo](https://github.com/huggingface/diffusers)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nMaintained examples (not research project or legacy):\r\n\r\n- Flax: @sanchit-gandhi\r\n- PyTorch: See Models above and tag the person corresponding to the modality of the example.\r\n- TensorFlow: @Rocketknight1\r\n\r\n -->\r\n",
      "body_length": 2579,
      "created_at": "2024-03-21T09:41:42Z",
      "merged_at": "2024-03-21T15:09:35Z",
      "merged": true,
      "time_to_merge_hours": 5.464722222222222,
      "state": "MERGED",
      "additions": 17,
      "deletions": 0,
      "files_changed": 1,
      "commits_count": 1,
      "review_count": 1,
      "comment_count": 0,
      "commit_messages": [
        "feat: add support for torch_dtype"
      ],
      "avg_commit_msg_length": 33.0,
      "has_conventional_commits": true,
      "conventional_commit_ratio": 1.0,
      "commit_types": [
        "feat"
      ],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\n\r\n\r\n\r\n\r\nFixes #29697 (issue)\r\n\r\n- match the `torch_dtype` argument in [run_clm](https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_clm.py)\r\n- `max_seq_length` is very similar to `block_size` and is left unchanged\r\n\r\n## Who can review?\r\n\r\n@galtay and @amyeroberts",
      "body_cleaned_length": 331,
      "template_removed_length": 2248,
      "template_reduction_percentage": 87.16556804963163,
      "author_type": "User"
    },
    "username": "jla524"
  },
  {
    "pr_number": 29838,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 29016,
        "labels": [
          "Good First Issue",
          "trainer",
          "Feature request"
        ]
      }
    ],
    "pr_data": {
      "number": 29838,
      "title": "add functions to inspect model and optimizer status to trainer.py",
      "body": "# What does this PR do?\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\nAdd functions `get_num_trainable_parameters` to return the number of parameters which require grad, `get_learning_rates` to return the learning rates of parameter groups and `get_optimizer_group` to return optimizer groups for parameters.\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes #29016 \r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- text models: @ArthurZucker and @younesbelkada\r\n- vision models: @amyeroberts\r\n- speech models: @sanchit-gandhi\r\n- graph models: @clefourrier\r\n\r\nLibrary:\r\n\r\n- flax: @sanchit-gandhi\r\n- generate: @gante\r\n- pipelines: @Narsil\r\n- tensorflow: @gante and @Rocketknight1\r\n- tokenizers: @ArthurZucker\r\n- trainer: @muellerzr and @pacman100\r\n\r\nIntegrations:\r\n\r\n- deepspeed: HF Trainer/Accelerate: @pacman100\r\n- ray/raytune: @richardliaw, @amogkam\r\n- Big Model Inference: @SunMarc\r\n- quantization (bitsandbytes, autogpt): @SunMarc and @younesbelkada\r\n\r\nDocumentation: @stevhliu and @MKhalusova\r\n\r\nHF projects:\r\n\r\n- accelerate: [different repo](https://github.com/huggingface/accelerate)\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- diffusers: [different repo](https://github.com/huggingface/diffusers)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nMaintained examples (not research project or legacy):\r\n\r\n- Flax: @sanchit-gandhi\r\n- PyTorch: See Models above and tag the person corresponding to the modality of the example.\r\n- TensorFlow: @Rocketknight1\r\n\r\n -->\r\n@amyeroberts @muellerzr ",
      "body_length": 3562,
      "created_at": "2024-03-24T10:58:01Z",
      "merged_at": "2024-03-28T10:37:16Z",
      "merged": true,
      "time_to_merge_hours": 95.65416666666667,
      "state": "MERGED",
      "additions": 68,
      "deletions": 0,
      "files_changed": 2,
      "commits_count": 6,
      "review_count": 8,
      "comment_count": 7,
      "commit_messages": [
        "add functions to get number of params which require grad, get optimizer group for parameters and get learning rates of param groups to trainer.py",
        "add tests and raise ValueError when optimizer is None",
        "add second layer to test and freeze its weigths",
        "check if torch is available before running tests",
        "use decorator to check if torch is available\n\nCo-authored-by: amyeroberts <22614925+amyeroberts@users.noreply.github.com>",
        "fix test indentation\n\nCo-authored-by: Zach Mueller <muellerzr@gmail.com>"
      ],
      "avg_commit_msg_length": 81.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": true,
      "has_docs": false,
      "test_files": [
        "tests/trainer/test_trainer.py"
      ],
      "doc_files": [],
      "file_types": {
        "py": 2
      },
      "review_states": {
        "COMMENTED": 6,
        "APPROVED": 2
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\n\r\n\r\nAdd functions `get_num_trainable_parameters` to return the number of parameters which require grad, `get_learning_rates` to return the learning rates of parameter groups and `get_optimizer_group` to return optimizer groups for parameters.\r\n\r\n\r\n\r\nFixes #29016 \r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n\r\n@amyeroberts @muellerzr",
      "body_cleaned_length": 1319,
      "template_removed_length": 2243,
      "template_reduction_percentage": 62.970241437394726,
      "author_type": "User"
    },
    "username": "CKeibel"
  },
  {
    "pr_number": 29947,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 29174,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 29947,
      "title": "Update installs in image classification doc",
      "body": "# What does this PR do?\r\n\r\nTrainer with PyTorch now requires accelerate to be installed. Therefore, accelerate is added to the list of libraries to be installed.\r\n\r\nFixes #29174 (partly)\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n## Who can review?\r\n\r\n@stevhliu and @MKhalusova\r\n",
      "body_length": 1060,
      "created_at": "2024-03-28T19:15:33Z",
      "merged_at": "2024-03-28T21:26:28Z",
      "merged": true,
      "time_to_merge_hours": 2.1819444444444445,
      "state": "MERGED",
      "additions": 1,
      "deletions": 1,
      "files_changed": 1,
      "commits_count": 1,
      "review_count": 1,
      "comment_count": 1,
      "commit_messages": [
        "Update installs in image classification doc\n\nTrainer with PyTorch now requires accelerate to be installed.\n\nPartly resolves huggingface/transformers#29174"
      ],
      "avg_commit_msg_length": 154.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": true,
      "test_files": [],
      "doc_files": [
        "docs/source/en/tasks/image_classification.md"
      ],
      "file_types": {
        "md": 1
      },
      "review_states": {
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nTrainer with PyTorch now requires accelerate to be installed. Therefore, accelerate is added to the list of libraries to be installed.\r\n\r\nFixes #29174 (partly)\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n## Who can review?\r\n\r\n@stevhliu and @MKhalusova",
      "body_cleaned_length": 1058,
      "template_removed_length": 2,
      "template_reduction_percentage": 0.18867924528301888,
      "author_type": "User"
    },
    "username": "MariaHei"
  },
  {
    "pr_number": 30088,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 30034,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 30088,
      "title": "fixing issue 30034 - adding data format for run_ner.py",
      "body": "# What does this PR do?\r\n\r\nThis PR adds the data format in the README for explaining data format for run_ner.py script.\r\n\r\nFixes #30034 \r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n@NielsRogge @ArthurZucker \r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n",
      "body_length": 1166,
      "created_at": "2024-04-06T16:14:37Z",
      "merged_at": "2024-04-08T11:49:59Z",
      "merged": true,
      "time_to_merge_hours": 43.589444444444446,
      "state": "MERGED",
      "additions": 14,
      "deletions": 0,
      "files_changed": 1,
      "commits_count": 1,
      "review_count": 1,
      "comment_count": 1,
      "commit_messages": [
        "fixing issue 30034 - adding data format for run_ner.py"
      ],
      "avg_commit_msg_length": 54.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": true,
      "test_files": [],
      "doc_files": [
        "examples/pytorch/token-classification/README.md"
      ],
      "file_types": {
        "md": 1
      },
      "review_states": {
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nThis PR adds the data format in the README for explaining data format for run_ner.py script.\r\n\r\nFixes #30034 \r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n@NielsRogge @ArthurZucker \r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.",
      "body_cleaned_length": 1164,
      "template_removed_length": 2,
      "template_reduction_percentage": 0.17152658662092624,
      "author_type": "User"
    },
    "username": "JINO-ROHIT"
  },
  {
    "pr_number": 30635,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 30579,
        "labels": [
          "Good First Issue",
          "Vision"
        ]
      }
    ],
    "pr_data": {
      "number": 30635,
      "title": "Interpolate pos encode for altclip",
      "body": "# What does this PR do?\r\n\r\nAdds **interpolate_pos_encode** and **a test case** for the said feature for the model altclip.\r\n\r\nFixes #30579 (altclip)\r\n\r\n## Who can review?\r\n\r\n@amyeroberts ",
      "body_length": 161,
      "created_at": "2024-05-03T14:21:54Z",
      "updated_at": "2024-05-08T08:33:14Z",
      "closed_at": "2024-05-08T08:33:14Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 92,
      "deletions": 3,
      "files_changed": 2,
      "commits_count": 3,
      "review_count": 0,
      "comment_count": 4,
      "pr_size": 95,
      "avg_commit_msg_length": 84.33333333333333,
      "has_conventional_commits": true,
      "conventional_commit_ratio": 1.0,
      "commit_types": [
        "feat",
        "test",
        "chore"
      ],
      "has_tests": true,
      "has_docs": false,
      "test_files": [
        "tests/models/altclip/test_modeling_altclip.py"
      ],
      "doc_files": [],
      "file_types": {
        "py": 2
      },
      "review_states": {},
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nAdds **interpolate_pos_encode** and **a test case** for the said feature for the model altclip.\r\n\r\nFixes #30579 (altclip)\r\n\r\n## Who can review?\r\n\r\n@amyeroberts",
      "body_cleaned_length": 186,
      "template_removed_length": 1,
      "template_reduction_percentage": 0.53475935828877,
      "author_type": "User"
    },
    "username": "bhuvanmdev"
  },
  {
    "pr_number": 29541,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 28882,
        "labels": [
          "bug",
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 29541,
      "title": "Fix BatchEncoding not prepending batch axis when tensor_type is None",
      "body": "# Fix BatchEncoding not prepending batch axis to python list when tensor_type is None\r\n\r\nFixes #28882\r\n\r\n## Who can review?\r\n@ArthurZucker\r\n",
      "body_length": 126,
      "created_at": "2024-03-08T18:50:16Z",
      "updated_at": "2024-05-03T08:04:17Z",
      "closed_at": "2024-05-03T08:04:17Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 2,
      "deletions": 0,
      "files_changed": 1,
      "commits_count": 1,
      "review_count": 1,
      "comment_count": 1,
      "pr_size": 2,
      "avg_commit_msg_length": 77.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {
        "COMMENTED": 1
      },
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# Fix BatchEncoding not prepending batch axis to python list when tensor_type is None\r\n\r\nFixes #28882\r\n\r\n## Who can review?\r\n@ArthurZucker",
      "body_cleaned_length": 138,
      "template_removed_length": 2,
      "template_reduction_percentage": 1.4285714285714286,
      "author_type": "User"
    },
    "username": "mig-mfreitas"
  },
  {
    "pr_number": 32105,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 31036,
        "labels": [
          "Good First Issue",
          "Feature request"
        ]
      }
    ],
    "pr_data": {
      "number": 32105,
      "title": "support 3D attention mask in bert",
      "body": "# What does this PR do?\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes #31036\r\nTry to fix with minimal change as mentioned in #31302\r\n\r\n3D attention masks are used in [GroundingDINO](https://github.com/IDEA-Research/GroundingDINO)\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [x] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n- text models: @ArthurZucker\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- text models: @ArthurZucker\r\n- vision models: @amyeroberts\r\n- speech models: @sanchit-gandhi\r\n- graph models: @clefourrier\r\n\r\nLibrary:\r\n\r\n- flax: @sanchit-gandhi\r\n- generate: @zucchini-nlp (visual-language models) or @gante (all others)\r\n- pipelines: @Narsil\r\n- tensorflow: @gante and @Rocketknight1\r\n- tokenizers: @ArthurZucker\r\n- trainer: @muellerzr and @SunMarc\r\n\r\nIntegrations:\r\n\r\n- deepspeed: HF Trainer/Accelerate: @muellerzr\r\n- ray/raytune: @richardliaw, @amogkam\r\n- Big Model Inference: @SunMarc\r\n- quantization (bitsandbytes, autogpt): @SunMarc\r\n\r\nDocumentation: @stevhliu\r\n\r\nHF projects:\r\n\r\n- accelerate: [different repo](https://github.com/huggingface/accelerate)\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- diffusers: [different repo](https://github.com/huggingface/diffusers)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nMaintained examples (not research project or legacy):\r\n\r\n- Flax: @sanchit-gandhi\r\n- PyTorch: See Models above and tag the person corresponding to the modality of the example.\r\n- TensorFlow: @Rocketknight1\r\n\r\n -->\r\n",
      "body_length": 3479,
      "created_at": "2024-07-20T05:13:05Z",
      "merged_at": "2024-09-06T12:20:48Z",
      "merged": true,
      "time_to_merge_hours": 1159.128611111111,
      "state": "MERGED",
      "additions": 42,
      "deletions": 4,
      "files_changed": 2,
      "commits_count": 5,
      "review_count": 4,
      "comment_count": 14,
      "commit_messages": [
        "support 3D/4D attention mask in bert",
        "test cases",
        "update doc",
        "fix doc",
        "Merge branch 'main' of github.com:gathierry/transformers into bert-sdpa-4d-mask"
      ],
      "avg_commit_msg_length": 28.4,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": true,
      "has_docs": false,
      "test_files": [
        "tests/models/bert/test_modeling_bert.py"
      ],
      "doc_files": [],
      "file_types": {
        "py": 2
      },
      "review_states": {
        "COMMENTED": 3,
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\n\r\n\r\n\r\n\r\nFixes #31036\r\nTry to fix with minimal change as mentioned in #31302\r\n\r\n3D attention masks are used in [GroundingDINO](https://github.com/IDEA-Research/GroundingDINO)\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [x] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n- text models: @ArthurZucker",
      "body_cleaned_length": 1232,
      "template_removed_length": 2247,
      "template_reduction_percentage": 64.58752515090544,
      "author_type": "User"
    },
    "username": "gathierry"
  },
  {
    "pr_number": 28767,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 28241,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 28767,
      "title": "added support for llama v2 and codellama in weight conversion for issue #28241",
      "body": "# What does this PR do?\r\n\r\nThis PR adds support for LLaMa V2 and CodeLLaMa while maintaining backwards compatibility for LLaMa V1 in the LLaMa-HuggingFace weight conversion script `src/transformers/models/llama/convert_llama_weights_to_hf.py`. This PR changes the max_position_embeddings for LLaMa V2 to 4096, and for CodeLLaMa to 16384, while maintaining a default max_position_embeddings of 2048 for LLaMa V1.\r\n\r\n\r\n\r\nFixes #28241 \r\n\r\n\r\n## Who can review?\r\n\r\n@ArthurZucker @amyeroberts \r\n",
      "body_length": 460,
      "created_at": "2024-01-29T23:44:46Z",
      "updated_at": "2024-03-08T08:03:41Z",
      "closed_at": "2024-03-08T08:03:41Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 11,
      "deletions": 3,
      "files_changed": 1,
      "commits_count": 3,
      "review_count": 0,
      "comment_count": 4,
      "pr_size": 14,
      "avg_commit_msg_length": 25.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {},
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nThis PR adds support for LLaMa V2 and CodeLLaMa while maintaining backwards compatibility for LLaMa V1 in the LLaMa-HuggingFace weight conversion script `src/transformers/models/llama/convert_llama_weights_to_hf.py`. This PR changes the max_position_embeddings for LLaMa V2 to 4096, and for CodeLLaMa to 16384, while maintaining a default max_position_embeddings of 2048 for LLaMa V1.\r\n\r\n\r\n\r\nFixes #28241 \r\n\r\n\r\n## Who can review?\r\n\r\n@ArthurZucker @amyeroberts",
      "body_cleaned_length": 486,
      "template_removed_length": 3,
      "template_reduction_percentage": 0.6134969325153374,
      "author_type": "User"
    },
    "username": "christoukmaji"
  },
  {
    "pr_number": 32550,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 30917,
        "labels": [
          "Good First Issue",
          "Vision"
        ]
      }
    ],
    "pr_data": {
      "number": 32550,
      "title": "Add post_process_depth_estimation to image processors and support ZoeDepth's inference intricacies",
      "body": "# What does this PR do?\r\n\r\nThis PR adds a `post_process_depth_estimation` method for the image processors of depth estimation models, similar to the `post_process_semantic_segmentation` methods for the segmentation models. Also, it updates the depth estimation pipeline to use the new `post_process_depth_estimation` method. Lastly, it adds full support for the ZoeDepth *special* inference (dynamically padded input + inference of the flipped of the input). A small update to the documentation is pending.\r\n\r\nFixes #30917 #32381 \r\n\r\n## Before submitting\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [x] Did you write any new necessary tests?\r\n\r\n## Who can review?\r\n@NielsRogge @amyeroberts @Narsil",
      "body_length": 1303,
      "created_at": "2024-08-09T02:12:26Z",
      "merged_at": "2024-10-22T13:50:54Z",
      "merged": true,
      "time_to_merge_hours": 1787.641111111111,
      "state": "MERGED",
      "additions": 446,
      "deletions": 212,
      "files_changed": 13,
      "commits_count": 24,
      "review_count": 43,
      "comment_count": 21,
      "commit_messages": [
        "add colorize_depth and matplotlib availability check",
        "add post_process_depth_estimation for zoedepth + tests",
        "add post_process_depth_estimation for DPT + tests",
        "add post_process_depth_estimation in DepthEstimationPipeline & special case for zoedepth",
        "run `make fixup`",
        "fix import related error on tests",
        "fix more import related errors on test",
        "forgot some `torch` calls in declerations",
        "remove `torch` call in zoedepth tests that caused error",
        "updated docs for depth estimation",
        "small fix for `colorize` input/output types",
        "remove `colorize_depth`, fix various names, remove matplotlib dependency",
        "fix formatting",
        "run fixup",
        "different images for test",
        "update examples in `forward` functions",
        "fixed broken links",
        "fix output types for docs",
        "possible format fix inside `<Tip>`",
        "Readability related updates\n\nCo-authored-by: Pavel Iakubovskii <qubvel@gmail.com>",
        "Readability related update",
        "cleanup after merge",
        "refactor `post_process_depth_estimation` to return dict; simplify ZoeDepth's `post_process_depth_estimation`",
        "rewrite dict merging to support python 3.8"
      ],
      "avg_commit_msg_length": 42.208333333333336,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": true,
      "has_docs": true,
      "test_files": [
        "tests/models/dpt/test_modeling_dpt.py",
        "tests/models/zoedepth/test_modeling_zoedepth.py",
        "tests/pipelines/test_pipelines_depth_estimation.py"
      ],
      "doc_files": [
        "docs/source/en/model_doc/depth_anything.md",
        "docs/source/en/model_doc/depth_anything_v2.md",
        "docs/source/en/model_doc/zoedepth.md",
        "docs/source/en/tasks/monocular_depth_estimation.md"
      ],
      "file_types": {
        "md": 4,
        "py": 9
      },
      "review_states": {
        "COMMENTED": 40,
        "APPROVED": 3
      },
      "labels": [
        {
          "name": "Vision",
          "color": "C079EF",
          "description": ""
        },
        {
          "name": "Processing",
          "color": "1E17DF",
          "description": ""
        }
      ],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nThis PR adds a `post_process_depth_estimation` method for the image processors of depth estimation models, similar to the `post_process_semantic_segmentation` methods for the segmentation models. Also, it updates the depth estimation pipeline to use the new `post_process_depth_estimation` method. Lastly, it adds full support for the ZoeDepth *special* inference (dynamically padded input + inference of the flipped of the input). A small update to the documentation is pending.\r\n\r\nFixes #30917 #32381 \r\n\r\n## Before submitting\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [x] Did you write any new necessary tests?\r\n\r\n## Who can review?\r\n@NielsRogge @amyeroberts @Narsil",
      "body_cleaned_length": 1303,
      "template_removed_length": 0,
      "template_reduction_percentage": 0.0,
      "author_type": "User"
    },
    "username": "alex-bene"
  },
  {
    "pr_number": 32652,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 16627,
        "labels": [
          "Core: Tokenization",
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 32652,
      "title": "Add `SplinterTokenizer` unit test",
      "body": "# What does this PR do?\r\n* Add `SplinterTokenizer` unit test\r\n* Pass `question_token` in `SplinterTokenizer.save_pretrained`, to ensure the saved tokenizer_config will have the same parameter.\r\n\r\nFixes #16627\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [x] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n@ArthurZucker \r\n\r\n\r\n\r\n\r\n\r\n",
      "body_length": 1085,
      "created_at": "2024-08-13T11:16:03Z",
      "merged_at": "2024-10-03T12:49:56Z",
      "merged": true,
      "time_to_merge_hours": 1225.5647222222221,
      "state": "MERGED",
      "additions": 175,
      "deletions": 0,
      "files_changed": 2,
      "commits_count": 5,
      "review_count": 5,
      "comment_count": 3,
      "commit_messages": [
        "add unit tests for splinter_tokenizer",
        "add unit test for splinter tokenizer, pass in the question_token to be saved on save_pretrained called",
        "remove unused import",
        "remove vocab_splinter.txt, add Copied from, use fmt:on and fmt:off to prevent autoformatting on long lines",
        "remove all the spaces\n\nCo-authored-by: Arthur <48595927+ArthurZucker@users.noreply.github.com>"
      ],
      "avg_commit_msg_length": 71.8,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": true,
      "has_docs": false,
      "test_files": [
        "tests/models/splinter/test_tokenization_splinter.py"
      ],
      "doc_files": [],
      "file_types": {
        "py": 2
      },
      "review_states": {
        "COMMENTED": 5
      },
      "labels": [
        {
          "name": "Core: Tokenization",
          "color": "FF4446",
          "description": "Internals of the library; Tokenization."
        }
      ],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n* Add `SplinterTokenizer` unit test\r\n* Pass `question_token` in `SplinterTokenizer.save_pretrained`, to ensure the saved tokenizer_config will have the same parameter.\r\n\r\nFixes #16627\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [x] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n@ArthurZucker",
      "body_cleaned_length": 1072,
      "template_removed_length": 13,
      "template_reduction_percentage": 1.19815668202765,
      "author_type": "User"
    },
    "username": "ariepratama"
  },
  {
    "pr_number": 33339,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 29818,
        "labels": [
          "Should Fix",
          "Good First Issue",
          "Vision"
        ]
      }
    ],
    "pr_data": {
      "number": 33339,
      "title": "Move weight initilization deformabledetr",
      "body": "# What does this PR do?\r\n\r\nMoves the weight initialization of DeformableDetr, RtDetr and GroundingDino. \r\n\r\nFixes #29818 \r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n@amyeroberts 🤗 ",
      "body_length": 985,
      "created_at": "2024-09-06T08:00:12Z",
      "merged_at": "2024-10-01T19:08:57Z",
      "merged": true,
      "time_to_merge_hours": 611.1458333333334,
      "state": "MERGED",
      "additions": 65,
      "deletions": 71,
      "files_changed": 3,
      "commits_count": 5,
      "review_count": 2,
      "comment_count": 6,
      "commit_messages": [
        "fix(copy): fixup copy",
        "fix(deformable_detr): move weight initialization to the right place",
        "fix(grounding_dino): move weight initialization to the right place",
        "fix(rt_detr): move weight initialization to the right place",
        "[run-slow] deformable_detr, grounding_dino, rt_detr"
      ],
      "avg_commit_msg_length": 52.8,
      "has_conventional_commits": true,
      "conventional_commit_ratio": 0.8,
      "commit_types": [
        "fix"
      ],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 3
      },
      "review_states": {
        "COMMENTED": 1,
        "APPROVED": 1
      },
      "labels": [
        {
          "name": "Core: Modeling",
          "color": "FF8446",
          "description": "Internals of the library; Models."
        },
        {
          "name": "Vision",
          "color": "C079EF",
          "description": ""
        },
        {
          "name": "run-slow",
          "color": "E1D519",
          "description": ""
        }
      ],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": "low",
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nMoves the weight initialization of DeformableDetr, RtDetr and GroundingDino. \r\n\r\nFixes #29818 \r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n@amyeroberts 🤗",
      "body_cleaned_length": 984,
      "template_removed_length": 1,
      "template_reduction_percentage": 0.10152284263959391,
      "author_type": "User"
    },
    "username": "g-prz"
  },
  {
    "pr_number": 34856,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 34847,
        "labels": [
          "bug",
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 34856,
      "title": "Remove quantization related config from dequantized model",
      "body": "# What does this PR do?\r\n\r\nFixes #34847\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n @SunMarc\r\n",
      "body_length": 901,
      "created_at": "2024-11-21T14:07:31Z",
      "merged_at": "2024-11-22T09:06:29Z",
      "merged": true,
      "time_to_merge_hours": 18.982777777777777,
      "state": "MERGED",
      "additions": 3,
      "deletions": 0,
      "files_changed": 1,
      "commits_count": 2,
      "review_count": 4,
      "comment_count": 0,
      "commit_messages": [
        "Remove quantization related config from dequantized model",
        "Fix whitespace"
      ],
      "avg_commit_msg_length": 35.5,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {
        "COMMENTED": 2,
        "APPROVED": 2
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nFixes #34847\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n @SunMarc",
      "body_cleaned_length": 899,
      "template_removed_length": 2,
      "template_reduction_percentage": 0.22197558268590456,
      "author_type": "User"
    },
    "username": "konradkalita"
  },
  {
    "pr_number": 35557,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 22694,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 35557,
      "title": "PR for Issue #22694: Fixed Training Evaluation table display for VSCode",
      "body": "# What does this PR do?\r\nThis fixes the display of html table rendering and progress bar display during training/fine tuning a model in VSCode\r\nAfter a lot of experimentation with `IPython.display`, my conclusion is that VSCode is slightly slower than normal jupyter notebook at rendering updates, so by adjusting `update_every` everything else works fine. Tested on 3 different device (win,mac,linux) on vscode version: 1.96.2\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes #22694\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [X] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. \r\n@Rocketknight1 @sgugger \r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- text models: @ArthurZucker\r\n- vision models: @amyeroberts, @qubvel\r\n- speech models: @ylacombe, @eustlb\r\n- graph models: @clefourrier\r\n\r\nLibrary:\r\n\r\n- flax: @sanchit-gandhi\r\n- generate: @zucchini-nlp (visual-language models) or @gante (all others)\r\n- pipelines: @Rocketknight1\r\n- tensorflow: @gante and @Rocketknight1\r\n- tokenizers: @ArthurZucker\r\n- trainer: @muellerzr and @SunMarc\r\n- chat templates: @Rocketknight1\r\n\r\nIntegrations:\r\n\r\n- deepspeed: HF Trainer/Accelerate: @muellerzr\r\n- ray/raytune: @richardliaw, @amogkam\r\n- Big Model Inference: @SunMarc\r\n- quantization (bitsandbytes, autogpt): @SunMarc @MekkCyber\r\n\r\nDocumentation: @stevhliu\r\n\r\nHF projects:\r\n\r\n- accelerate: [different repo](https://github.com/huggingface/accelerate)\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- diffusers: [different repo](https://github.com/huggingface/diffusers)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nMaintained examples (not research project or legacy):\r\n\r\n- Flax: @sanchit-gandhi\r\n- PyTorch: See Models above and tag the person corresponding to the modality of the example.\r\n- TensorFlow: @Rocketknight1\r\n\r\n -->\r\n",
      "body_length": 3716,
      "created_at": "2025-01-07T22:31:02Z",
      "merged_at": "2025-01-09T15:05:47Z",
      "merged": true,
      "time_to_merge_hours": 40.579166666666666,
      "state": "MERGED",
      "additions": 5,
      "deletions": 2,
      "files_changed": 2,
      "commits_count": 1,
      "review_count": 1,
      "comment_count": 1,
      "commit_messages": [
        "PR for Issue #22694: Fixed Training Evaluation table display for VSCode"
      ],
      "avg_commit_msg_length": 71.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 2
      },
      "review_states": {
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\nThis fixes the display of html table rendering and progress bar display during training/fine tuning a model in VSCode\r\nAfter a lot of experimentation with `IPython.display`, my conclusion is that VSCode is slightly slower than normal jupyter notebook at rendering updates, so by adjusting `update_every` everything else works fine. Tested on 3 different device (win,mac,linux) on vscode version: 1.96.2\r\n\r\n\r\n\r\n\r\n\r\nFixes #22694\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [X] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. \r\n@Rocketknight1 @sgugger",
      "body_cleaned_length": 1404,
      "template_removed_length": 2312,
      "template_reduction_percentage": 62.21743810548978,
      "author_type": "User"
    },
    "username": "dedsec995"
  },
  {
    "pr_number": 35517,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 35290,
        "labels": [
          "bug",
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 35517,
      "title": "Add support for 4D custom attention masks in GPT-2",
      "body": "## Problem Statement\r\nCurrently, GPT-2's attention mechanism only supports 2D attention masks, limiting its flexibility for advanced use cases like packed sequence processing. When users attempt to use 4D attention masks (shape [batch_size, num_heads, seq_length, seq_length]), the model raises dimension mismatch errors.\r\n\r\nIssue #35290  demonstrates this limitation when trying to process packed sequences with custom attention patterns.\r\n\r\n## Proposed Solution\r\nExtend GPT-2's attention mechanism to properly handle both 2D and 4D attention masks while maintaining backward compatibility. This allows for:\r\n- Direct support for packed sequence processing\r\n- More flexible attention patterns\r\n- Compatibility with existing 2D mask implementations\r\n\r\n## Implementation Details\r\nThe changes focus on the GPT2Attention class, specifically:\r\n1. Updated attention mask handling in the forward pass\r\n2. Maintained compatibility with existing 2D attention masks\r\n3. Preserved causal attention behavior when required\r\n\r\n## Testing Strategy\r\nAdded comprehensive test suite (`test_modeling_4D_attention_mask.py`) that verifies:\r\n- Shape compatibility with 4D masks\r\n- Correctness of attention patterns\r\n- Consistency between 2D and 4D mask results\r\n- Causal attention preservation\r\n- Batch processing consistency\r\n- Edge cases (empty sequences, single tokens, maximum length)\r\n\r\n## Test Results\r\nAll tests passed successfully. Screenshot of test results:\r\n<img width=\"1242\" alt=\"Screenshot 2025-01-06 at 3 49 52 AM\" src=\"https://github.com/user-attachments/assets/6e48d191-7b5b-45ea-a3e8-278f02b41cbe\" />\r\n\r\n## Impact and Benefits\r\nThis enhancement:\r\n1. Enables efficient packed sequence processing\r\n2. Provides more flexibility in attention pattern design\r\n3. Maintains backward compatibility\r\n4. Improves model versatility without performance overhead\r\n\r\n## Validation\r\n- ✅ New test suite validates 4D mask functionality\r\n- ✅ Backward compatible with existing 2D masks\r\n- ✅ No performance regression\r\n\r\n## Related Issues\r\nCloses #35290  - Support for 4D attention masks in GPT-2\r\n\r\n## Additional Notes\r\n- No breaking changes introduced\r\n- Existing model weights remain compatible\r\n- Performance impact is negligible\r\n\r\nrequested reviewers - @ArthurZucker ",
      "body_length": 1972,
      "created_at": "2025-01-05T22:22:28Z",
      "updated_at": "2025-02-11T15:38:56Z",
      "closed_at": null,
      "merged_at": null,
      "merged": false,
      "state": "OPEN",
      "time_to_merge_hours": null,
      "additions": 220,
      "deletions": 0,
      "files_changed": 2,
      "commits_count": 18,
      "review_count": 1,
      "comment_count": 3,
      "pr_size": 220,
      "avg_commit_msg_length": 38.5,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": true,
      "has_docs": false,
      "test_files": [
        "tests/models/gpt2/test_modeling_4D_attention_mask.py"
      ],
      "doc_files": [],
      "file_types": {
        "py": 2
      },
      "review_states": {
        "COMMENTED": 1
      },
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "## Problem Statement\r\nCurrently, GPT-2's attention mechanism only supports 2D attention masks, limiting its flexibility for advanced use cases like packed sequence processing. When users attempt to use 4D attention masks (shape [batch_size, num_heads, seq_length, seq_length]), the model raises dimension mismatch errors.\r\n\r\nIssue #35290  demonstrates this limitation when trying to process packed sequences with custom attention patterns.\r\n\r\n## Proposed Solution\r\nExtend GPT-2's attention mechanism to properly handle both 2D and 4D attention masks while maintaining backward compatibility. This allows for:\r\n- Direct support for packed sequence processing\r\n- More flexible attention patterns\r\n- Compatibility with existing 2D mask implementations\r\n\r\n## Implementation Details\r\nThe changes focus on the GPT2Attention class, specifically:\r\n1. Updated attention mask handling in the forward pass\r\n2. Maintained compatibility with existing 2D attention masks\r\n3. Preserved causal attention behavior when required\r\n\r\n## Testing Strategy\r\nAdded comprehensive test suite (`test_modeling_4D_attention_mask.py`) that verifies:\r\n- Shape compatibility with 4D masks\r\n- Correctness of attention patterns\r\n- Consistency between 2D and 4D mask results\r\n- Causal attention preservation\r\n- Batch processing consistency\r\n- Edge cases (empty sequences, single tokens, maximum length)\r\n\r\n## Test Results\r\nAll tests passed successfully. Screenshot of test results:\r\n<img width=\"1242\" alt=\"Screenshot 2025-01-06 at 3 49 52 AM\" src=\"https://github.com/user-attachments/assets/6e48d191-7b5b-45ea-a3e8-278f02b41cbe\" />\r\n\r\n## Impact and Benefits\r\nThis enhancement:\r\n1. Enables efficient packed sequence processing\r\n2. Provides more flexibility in attention pattern design\r\n3. Maintains backward compatibility\r\n4. Improves model versatility without performance overhead\r\n\r\n## Validation\r\n- ✅ New test suite validates 4D mask functionality\r\n- ✅ Backward compatible with existing 2D masks\r\n- ✅ No performance regression\r\n\r\n## Related Issues\r\nCloses #35290  - Support for 4D attention masks in GPT-2\r\n\r\n## Additional Notes\r\n- No breaking changes introduced\r\n- Existing model weights remain compatible\r\n- Performance impact is negligible\r\n\r\nrequested reviewers - @ArthurZucker",
      "body_cleaned_length": 2248,
      "template_removed_length": 1,
      "template_reduction_percentage": 0.044464206313917294,
      "author_type": "User"
    },
    "username": "sambhavnoobcoder"
  },
  {
    "pr_number": 37052,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 36979,
        "labels": [
          "Good First Issue",
          "Good First Documentation Issue",
          "contributions-welcome"
        ]
      }
    ],
    "pr_data": {
      "number": 37052,
      "title": "Update Model Card for ModernBERT",
      "body": "# What does this PR do?\r\n\r\nAs described in the issue, this PR updates the model card for ModernBERT. Please let me know if any modifications are required and I will make the necessary changes.\r\n\r\nFixes #36979\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n\r\n## Who can review?\r\n@stevhliu \r\n",
      "body_length": 372,
      "created_at": "2025-03-27T19:03:28Z",
      "merged_at": "2025-04-03T17:14:03Z",
      "merged": true,
      "time_to_merge_hours": 166.17638888888888,
      "state": "MERGED",
      "additions": 55,
      "deletions": 31,
      "files_changed": 1,
      "commits_count": 7,
      "review_count": 7,
      "comment_count": 3,
      "commit_messages": [
        "Modify Model Card for ModernBERT.",
        "Merge branch 'main' into Model-Card-For-ModernBERT",
        "Update as per code review.\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
        "Update model card.",
        "Merge branch 'main' into Model-Card-For-ModernBERT",
        "Update model card.",
        "Merge branch 'Model-Card-For-ModernBERT' of https://github.com/ParagEkbote/transformers into Model-Card-For-ModernBERT"
      ],
      "avg_commit_msg_length": 55.142857142857146,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": true,
      "test_files": [],
      "doc_files": [
        "docs/source/en/model_doc/modernbert.md"
      ],
      "file_types": {
        "md": 1
      },
      "review_states": {
        "COMMENTED": 6,
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nAs described in the issue, this PR updates the model card for ModernBERT. Please let me know if any modifications are required and I will make the necessary changes.\r\n\r\nFixes #36979\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n\r\n## Who can review?\r\n@stevhliu",
      "body_cleaned_length": 369,
      "template_removed_length": 3,
      "template_reduction_percentage": 0.8064516129032258,
      "author_type": "User"
    },
    "username": "ParagEkbote"
  },
  {
    "pr_number": 37076,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 36979,
        "labels": [
          "Good First Issue",
          "Good First Documentation Issue",
          "contributions-welcome"
        ]
      }
    ],
    "pr_data": {
      "number": 37076,
      "title": "Improvements in Gemma2 model card",
      "body": "# What does this PR do?\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes #36979, \r\nThis PR aims to improve model card for Gemma2 based on the given format mentioned [here](https://github.com/huggingface/transformers/issues/36979).\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n@stevhliu, Please let me know, if there are any changes needed here.\r\n",
      "body_length": 1978,
      "created_at": "2025-03-28T13:55:35Z",
      "merged_at": "2025-04-07T17:51:26Z",
      "merged": true,
      "time_to_merge_hours": 243.93083333333334,
      "state": "MERGED",
      "additions": 113,
      "deletions": 16,
      "files_changed": 1,
      "commits_count": 5,
      "review_count": 6,
      "comment_count": 5,
      "commit_messages": [
        "Improved Model card for Gemma2",
        "Made changes in gemma2 as suggested",
        "Made more changes in the doc (adding image, notes, closing hfoptions)",
        "Merge branch 'main' into gemma2_model_card",
        "minor fixes"
      ],
      "avg_commit_msg_length": 37.4,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": true,
      "test_files": [],
      "doc_files": [
        "docs/source/en/model_doc/gemma2.md"
      ],
      "file_types": {
        "md": 1
      },
      "review_states": {
        "COMMENTED": 5,
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\n\r\n\r\n\r\nFixes #36979, \r\nThis PR aims to improve model card for Gemma2 based on the given format mentioned [here](https://github.com/huggingface/transformers/issues/36979).\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n@stevhliu, Please let me know, if there are any changes needed here.",
      "body_cleaned_length": 1111,
      "template_removed_length": 867,
      "template_reduction_percentage": 43.83215369059656,
      "author_type": "User"
    },
    "username": "devesh-2002"
  },
  {
    "pr_number": 37184,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 36979,
        "labels": [
          "Good First Issue",
          "Good First Documentation Issue",
          "contributions-welcome"
        ]
      }
    ],
    "pr_data": {
      "number": 37184,
      "title": "Update falcon model card",
      "body": "Fixes #36979 \r\n\r\n* Updated the Falcon model card\r\n* Did not update Falcon3 as it is not explicitly listed, but can do it also\r\n* Did not include the attention visualizer as I was not able to implement it for Falcon models in a straightforward way.\r\n* First contrib, thank you for your patience <3\r\n\r\n## Before submitting\r\n- [X] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [X] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [X] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [X] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [] Did you write any new necessary tests? NA\r\n",
      "body_length": 1121,
      "created_at": "2025-04-01T19:11:31Z",
      "merged_at": "2025-04-03T00:30:37Z",
      "merged": true,
      "time_to_merge_hours": 29.31833333333333,
      "state": "MERGED",
      "additions": 94,
      "deletions": 31,
      "files_changed": 1,
      "commits_count": 17,
      "review_count": 3,
      "comment_count": 4,
      "commit_messages": [
        "feat: updated model card for falcon",
        "fix:rewrite model description",
        "fix: add link to conversion script",
        "Update docs/source/en/model_doc/falcon.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
        "Update docs/source/en/model_doc/falcon.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
        "Update docs/source/en/model_doc/falcon.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
        "Update docs/source/en/model_doc/falcon.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
        "Update docs/source/en/model_doc/falcon.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
        "Update docs/source/en/model_doc/falcon.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
        "Update docs/source/en/model_doc/falcon.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
        "Update docs/source/en/model_doc/falcon.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
        "fix: Add suggested changes",
        "fix: typo in link for quantization",
        "Update docs/source/en/model_doc/falcon.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
        "Update docs/source/en/model_doc/falcon.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
        "fix: fix indent and close ticks",
        "fix: add indent"
      ],
      "avg_commit_msg_length": 79.05882352941177,
      "has_conventional_commits": true,
      "conventional_commit_ratio": 0.35294117647058826,
      "commit_types": [
        "fix",
        "feat"
      ],
      "has_tests": false,
      "has_docs": true,
      "test_files": [],
      "doc_files": [
        "docs/source/en/model_doc/falcon.md"
      ],
      "file_types": {
        "md": 1
      },
      "review_states": {
        "COMMENTED": 2,
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "Fixes #36979 \r\n\r\n* Updated the Falcon model card\r\n* Did not update Falcon3 as it is not explicitly listed, but can do it also\r\n* Did not include the attention visualizer as I was not able to implement it for Falcon models in a straightforward way.\r\n* First contrib, thank you for your patience <3\r\n\r\n## Before submitting\r\n- [X] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [X] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [X] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [X] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [] Did you write any new necessary tests? NA",
      "body_cleaned_length": 1119,
      "template_removed_length": 2,
      "template_reduction_percentage": 0.17841213202497772,
      "author_type": "User"
    },
    "username": "ricalanis"
  },
  {
    "pr_number": 37261,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 36979,
        "labels": [
          "Good First Issue",
          "Good First Documentation Issue",
          "contributions-welcome"
        ]
      }
    ],
    "pr_data": {
      "number": 37261,
      "title": "Updated T5 model card with standardized format",
      "body": "# What does this PR do?\r\n\r\nUpdated T5 model card with standardized format\r\n\r\nFixes #36979\r\n\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n @stevhliu\r\n\r\n",
      "body_length": 954,
      "created_at": "2025-04-03T18:46:18Z",
      "merged_at": "2025-04-04T22:23:09Z",
      "merged": true,
      "time_to_merge_hours": 27.614166666666666,
      "state": "MERGED",
      "additions": 68,
      "deletions": 313,
      "files_changed": 1,
      "commits_count": 16,
      "review_count": 4,
      "comment_count": 3,
      "commit_messages": [
        "Updated T5 model card with standardized format",
        "Updated T5 model card with standardized format, fixed typo",
        "Merge branch 'main' into t5-contribution",
        "Update docs/source/en/model_doc/t5.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
        "Update docs/source/en/model_doc/t5.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
        "Update docs/source/en/model_doc/t5.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
        "Update docs/source/en/model_doc/t5.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
        "Update docs/source/en/model_doc/t5.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
        "Update docs/source/en/model_doc/t5.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
        "Update docs/source/en/model_doc/t5.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
        "Update docs/source/en/model_doc/t5.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
        "Update docs/source/en/model_doc/t5.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
        "Update docs/source/en/model_doc/t5.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
        "Apply reviewer suggestions",
        "Merge branch 'main' into t5-contribution",
        "Update docs/source/en/model_doc/t5.md\n\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>"
      ],
      "avg_commit_msg_length": 88.75,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": true,
      "test_files": [],
      "doc_files": [
        "docs/source/en/model_doc/t5.md"
      ],
      "file_types": {
        "md": 1
      },
      "review_states": {
        "COMMENTED": 3,
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nUpdated T5 model card with standardized format\r\n\r\nFixes #36979\r\n\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n @stevhliu",
      "body_cleaned_length": 950,
      "template_removed_length": 4,
      "template_reduction_percentage": 0.41928721174004197,
      "author_type": "User"
    },
    "username": "ShararehY"
  },
  {
    "pr_number": 37898,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 36979,
        "labels": [
          "Good First Issue",
          "Good First Documentation Issue",
          "contributions-welcome"
        ]
      }
    ],
    "pr_data": {
      "number": 37898,
      "title": "Updated Zoedepth model card",
      "body": "# What does this PR do?\r\n\r\nUpdated zoedepth model card\r\nFixes #36979 \r\n\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\nModels:\r\n- vision models: @amyeroberts \r\n\r\nDocumentation: @stevhliu",
      "body_length": 1140,
      "created_at": "2025-04-30T17:45:54Z",
      "merged_at": "2025-05-27T17:06:54Z",
      "merged": true,
      "time_to_merge_hours": 647.35,
      "state": "MERGED",
      "additions": 82,
      "deletions": 81,
      "files_changed": 1,
      "commits_count": 3,
      "review_count": 2,
      "comment_count": 6,
      "commit_messages": [
        "Edited zoedepth model card according to specifications.",
        "Edited Zoedepth model file",
        "made suggested changes."
      ],
      "avg_commit_msg_length": 34.666666666666664,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": true,
      "test_files": [],
      "doc_files": [
        "docs/source/en/model_doc/zoedepth.md"
      ],
      "file_types": {
        "md": 1
      },
      "review_states": {
        "COMMENTED": 1,
        "APPROVED": 1
      },
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nUpdated zoedepth model card\r\nFixes #36979 \r\n\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\nModels:\r\n- vision models: @amyeroberts \r\n\r\nDocumentation: @stevhliu",
      "body_cleaned_length": 1140,
      "template_removed_length": 0,
      "template_reduction_percentage": 0.0,
      "author_type": "User"
    },
    "username": "miniMaddy"
  },
  {
    "pr_number": 38857,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 38484,
        "labels": [
          "bug",
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 38857,
      "title": "Clarify per_device_train_batch_size scaling in TrainingArguments (#38…",
      "body": "## What does this PR do?\r\n\r\nThis PR clarifies in the `TrainingArguments` docstring that `per_device_train_batch_size`\r\nis multiplied by the number of devices when training on multiple GPUs or with distributed training.\r\n\r\nCloses #38484\r\n\r\n## Before submitting\r\n\r\n- [x] This PR fixes a typo or improves the docs\r\n\r\n## Who can review?\r\n\r\n- @zach-huggingface  \r\n- @SunMarc  \r\n- @qgallouedec  \r\n",
      "body_length": 341,
      "created_at": "2025-06-17T09:51:49Z",
      "updated_at": "2025-07-08T00:23:02Z",
      "closed_at": "2025-07-07T16:57:42Z",
      "merged_at": "2025-07-07T16:57:42Z",
      "merged": true,
      "state": "MERGED",
      "time_to_merge_hours": 487.09805555555556,
      "additions": 2,
      "deletions": 1,
      "files_changed": 1,
      "commits_count": 1,
      "review_count": 2,
      "comment_count": 3,
      "pr_size": 3,
      "avg_commit_msg_length": 67.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {
        "COMMENTED": 1,
        "APPROVED": 1
      },
      "has_changes_requested": false,
      "has_approved": true,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "## What does this PR do?\r\n\r\nThis PR clarifies in the `TrainingArguments` docstring that `per_device_train_batch_size`\r\nis multiplied by the number of devices when training on multiple GPUs or with distributed training.\r\n\r\nCloses #38484\r\n\r\n## Before submitting\r\n\r\n- [x] This PR fixes a typo or improves the docs\r\n\r\n## Who can review?\r\n\r\n- @zach-huggingface  \r\n- @SunMarc  \r\n- @qgallouedec",
      "body_cleaned_length": 387,
      "template_removed_length": 4,
      "template_reduction_percentage": 1.0230179028132993,
      "author_type": "User"
    },
    "username": "Shohail-Ismail"
  },
  {
    "pr_number": 14030,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 13972,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 14030,
      "title": "Add `LayoutXLMTokenizer` and `LayoutXLMTokenizerFast`",
      "body": "# What does this PR do?\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes #13972 (issue)\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [X] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/master/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [X] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [X] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/master/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/master/docs#writing-source-documentation).\r\n- [X] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- albert, bert, xlm: @LysandreJik\r\n- blenderbot, bart, marian, pegasus, encoderdecoder,  t5: @patrickvonplaten, @patil-suraj\r\n- longformer, reformer, transfoxl, xlnet: @patrickvonplaten\r\n- fsmt: @stas00\r\n- funnel: @sgugger\r\n- gpt2: @patrickvonplaten, @LysandreJik\r\n- rag: @patrickvonplaten, @lhoestq\r\n- tensorflow: @LysandreJik\r\n\r\nLibrary:\r\n\r\n- benchmarks: @patrickvonplaten\r\n- deepspeed: @stas00\r\n- ray/raytune: @richardliaw, @amogkam\r\n- text generation: @patrickvonplaten\r\n- tokenizers: @n1t0, @LysandreJik\r\n- trainer: @sgugger\r\n- pipelines: @LysandreJik\r\n\r\nDocumentation: @sgugger\r\n\r\nHF projects:\r\n\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nExamples:\r\n\r\n- maintained examples (not research project or legacy): @sgugger, @patil-suraj\r\n- research_projects/bert-loses-patience: @JetRunner\r\n- research_projects/distillation: @VictorSanh\r\n\r\n -->\r\n",
      "body_length": 685,
      "created_at": "2021-10-15T21:07:46Z",
      "updated_at": "2021-10-22T17:09:06Z",
      "closed_at": "2021-10-22T17:09:06Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 4013,
      "deletions": 22,
      "files_changed": 11,
      "commits_count": 12,
      "review_count": 3,
      "comment_count": 9,
      "pr_size": 4035,
      "avg_commit_msg_length": 20.166666666666668,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": true,
      "has_docs": true,
      "test_files": [
        "tests/test_processor_layoutlmv2.py",
        "tests/test_tokenization_layoutxlm.py"
      ],
      "doc_files": [
        "docs/source/model_doc/layoutxlm.rst"
      ],
      "file_types": {
        "rst": 1,
        "py": 10
      },
      "review_states": {
        "COMMENTED": 3
      },
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\n\r\n\r\n\r\n\r\nFixes #13972 (issue)\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [X] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/master/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [X] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [X] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/master/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/master/docs#writing-source-documentation).\r\n- [X] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.",
      "body_cleaned_length": 1072,
      "template_removed_length": 2087,
      "template_reduction_percentage": 66.06521050965496,
      "author_type": "User"
    },
    "username": "kingyiusuen"
  },
  {
    "pr_number": 14928,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 14712,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 14928,
      "title": "[WIP] Fast tokenizer for debertaV2",
      "body": "# What does this PR do?\r\n\r\nImplements a fast tokenizer for deberta v2. Loosely based on #11387\r\n\r\nFixes #11529\r\nFixes #14712 \r\n\r\nThis is a draft as there are some failing tests (not super clear to me why atm, will have to investigate)\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/master/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/master/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/master/docs#writing-source-documentation).\r\n- [x] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n@LysandreJik\r\n",
      "body_length": 726,
      "created_at": "2021-12-26T00:56:42Z",
      "updated_at": "2022-04-25T16:44:05Z",
      "closed_at": "2022-04-25T15:03:30Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 309,
      "deletions": 9,
      "files_changed": 11,
      "commits_count": 4,
      "review_count": 7,
      "comment_count": 13,
      "pr_size": 318,
      "avg_commit_msg_length": 16.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": true,
      "has_docs": true,
      "test_files": [
        "tests/test_tokenization_deberta_v2.py"
      ],
      "doc_files": [
        "docs/source/index.mdx",
        "docs/source/main_classes/tokenizer.mdx",
        "docs/source/model_doc/deberta_v2.mdx"
      ],
      "file_types": {
        "mdx": 3,
        "py": 8
      },
      "review_states": {
        "COMMENTED": 6,
        "CHANGES_REQUESTED": 1
      },
      "has_changes_requested": true,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nImplements a fast tokenizer for deberta v2. Loosely based on #11387\r\n\r\nFixes #11529\r\nFixes #14712 \r\n\r\nThis is a draft as there are some failing tests (not super clear to me why atm, will have to investigate)\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/master/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/master/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/master/docs#writing-source-documentation).\r\n- [x] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n@LysandreJik",
      "body_cleaned_length": 1114,
      "template_removed_length": 2,
      "template_reduction_percentage": 0.17921146953405018,
      "author_type": "User"
    },
    "username": "alcinos"
  },
  {
    "pr_number": 18601,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 18436,
        "labels": [
          "Examples",
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 18601,
      "title": "Update run_mlm_no_trainer.py",
      "body": "Fixes #18436 \r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n@muellerzr \r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- albert, bert, xlm: @LysandreJik\r\n- blenderbot, bart, marian, pegasus, encoderdecoder,  t5: @patrickvonplaten, @patil-suraj\r\n- longformer, reformer, transfoxl, xlnet: @patrickvonplaten\r\n- fsmt: @stas00\r\n- funnel: @sgugger\r\n- gpt2: @patrickvonplaten, @LysandreJik\r\n- rag: @patrickvonplaten, @lhoestq\r\n- tensorflow: @LysandreJik\r\n\r\nLibrary:\r\n\r\n- benchmarks: @patrickvonplaten\r\n- deepspeed: @stas00\r\n- ray/raytune: @richardliaw, @amogkam\r\n- text generation: @patrickvonplaten\r\n- tokenizers: @n1t0, @LysandreJik\r\n- trainer: @sgugger\r\n- pipelines: @LysandreJik\r\n\r\nDocumentation: @sgugger\r\n\r\nHF projects:\r\n\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nExamples:\r\n\r\n- maintained examples (not research project or legacy): @sgugger, @patil-suraj\r\n- research_projects/bert-loses-patience: @JetRunner\r\n- research_projects/distillation: @VictorSanh\r\n\r\n -->\r\n",
      "body_length": 664,
      "created_at": "2022-08-12T12:24:33Z",
      "updated_at": "2022-12-29T17:07:58Z",
      "closed_at": "2022-08-18T19:45:29Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 4,
      "deletions": 3,
      "files_changed": 1,
      "commits_count": 1,
      "review_count": 0,
      "comment_count": 3,
      "pr_size": 7,
      "avg_commit_msg_length": 28.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {},
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "Fixes #18436 \r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n@muellerzr \r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.",
      "body_cleaned_length": 1035,
      "template_removed_length": 1222,
      "template_reduction_percentage": 54.14266725742135,
      "author_type": "User"
    },
    "username": "vedant-z"
  },
  {
    "pr_number": 19667,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 19568,
        "labels": [
          "New model",
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 19667,
      "title": "Swin2sr",
      "body": "# What does this PR do?\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes #19568\r\n\r\n\r\n## Who can review?\r\n@NielsRogge \r\n\r\n",
      "body_length": 64,
      "created_at": "2022-10-17T10:50:48Z",
      "updated_at": "2022-10-21T08:48:07Z",
      "closed_at": "2022-10-21T08:48:06Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 1928,
      "deletions": 0,
      "files_changed": 4,
      "commits_count": 2,
      "review_count": 0,
      "comment_count": 9,
      "pr_size": 1928,
      "avg_commit_msg_length": 18.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 4
      },
      "review_states": {},
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\n\r\n\r\n\r\n\r\nFixes #19568\r\n\r\n\r\n## Who can review?\r\n@NielsRogge",
      "body_cleaned_length": 84,
      "template_removed_length": 870,
      "template_reduction_percentage": 91.19496855345912,
      "author_type": "User"
    },
    "username": "venkat-natchi"
  },
  {
    "pr_number": 20940,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 18436,
        "labels": [
          "Examples",
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 20940,
      "title": "Update run_wav2vec2_pretraining_no_trainer.py",
      "body": "# What does this PR do?\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes #18436  (issue)\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a [link](https://github.com/huggingface/transformers/issues/18436) if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n@muellerzr\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- text models: @ArthurZucker and @younesbelkada\r\n- vision models: @amyeroberts and @NielsRogge\r\n- speech models: @sanchit-gandhi\r\n\r\nLibrary:\r\n\r\n- flax: @sanchit-gandhi\r\n- generate: @gante\r\n- pipelines: @Narsil\r\n- tensorflow: @gante and @Rocketknight1\r\n- tokenizers: @ArthurZucker\r\n- trainer: @sgugger\r\n\r\nIntegrations:\r\n\r\n- deepspeed: @stas00\r\n- ray/raytune: @richardliaw, @amogkam\r\n\r\nDocumentation: @sgugger and @stevhliu\r\n\r\nHF projects:\r\n\r\n- accelerate: [different repo](https://github.com/huggingface/accelerate)\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- diffusers: [different repo](https://github.com/huggingface/diffusers)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nMaintained examples (not research project or legacy):\r\n\r\n- Flax: @sanchit-gandhi\r\n- PyTorch: @sgugger\r\n- TensorFlow: @Rocketknight1\r\n\r\n -->\r\n",
      "body_length": 691,
      "created_at": "2022-12-29T17:08:38Z",
      "updated_at": "2023-02-06T15:02:09Z",
      "closed_at": "2023-02-06T15:02:09Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 3,
      "deletions": 2,
      "files_changed": 1,
      "commits_count": 1,
      "review_count": 0,
      "comment_count": 2,
      "pr_size": 5,
      "avg_commit_msg_length": 45.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {},
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\n\r\n\r\n\r\n\r\nFixes #18436  (issue)\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a [link](https://github.com/huggingface/transformers/issues/18436) if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n@muellerzr\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.",
      "body_cleaned_length": 1124,
      "template_removed_length": 2013,
      "template_reduction_percentage": 64.1695887790883,
      "author_type": "User"
    },
    "username": "Snimm"
  },
  {
    "pr_number": 23541,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 16059,
        "labels": [
          "Good First Issue",
          "HACKTOBERFEST-ACCEPTED"
        ]
      }
    ],
    "pr_data": {
      "number": 23541,
      "title": "Add type hints for PyTorch BERT.",
      "body": "# What does this PR do?\r\n\r\nAdd type hints for PyTorch BERT.\r\n\r\nFixes #16059 for PyTorch BERT\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [x] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n- text models: @ArthurZucker and @younesbelkada\r\n- type hints: @Rocketknight1\r\n",
      "body_length": 799,
      "created_at": "2023-05-20T18:31:58Z",
      "updated_at": "2023-08-11T15:02:50Z",
      "closed_at": "2023-08-11T15:02:50Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 91,
      "deletions": 77,
      "files_changed": 8,
      "commits_count": 8,
      "review_count": 1,
      "comment_count": 10,
      "pr_size": 168,
      "avg_commit_msg_length": 13.625,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 8
      },
      "review_states": {
        "APPROVED": 1
      },
      "has_changes_requested": false,
      "has_approved": true,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nAdd type hints for PyTorch BERT.\r\n\r\nFixes #16059 for PyTorch BERT\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [x] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n- text models: @ArthurZucker and @younesbelkada\r\n- type hints: @Rocketknight1",
      "body_cleaned_length": 1184,
      "template_removed_length": 2,
      "template_reduction_percentage": 0.16863406408094433,
      "author_type": "User"
    },
    "username": "coledie"
  },
  {
    "pr_number": 25048,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 24783,
        "labels": [
          "Good First Issue",
          "Good First Documentation Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 25048,
      "title": "[DOCS] add docstrings  to TypicalLogitsWarper",
      "body": "# What does this PR do?\r\nAdded some doc string to TypicalLogitsWarper with some examples as well.\r\n@gante let me know if there's anything else  should be add or remove from the docs.\r\n\r\n\r\nFixes #24783 \r\n\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n\r\n\r\n\r\n",
      "body_length": 308,
      "created_at": "2023-07-24T14:17:35Z",
      "updated_at": "2023-07-27T11:40:05Z",
      "closed_at": "2023-07-27T11:40:05Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 40,
      "deletions": 8,
      "files_changed": 1,
      "commits_count": 2,
      "review_count": 1,
      "comment_count": 1,
      "pr_size": 48,
      "avg_commit_msg_length": 24.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {
        "CHANGES_REQUESTED": 1
      },
      "has_changes_requested": true,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\nAdded some doc string to TypicalLogitsWarper with some examples as well.\r\n@gante let me know if there's anything else  should be add or remove from the docs.\r\n\r\n\r\nFixes #24783 \r\n\r\n\r\n## Before submitting\r\n- [x] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).",
      "body_cleaned_length": 331,
      "template_removed_length": 8,
      "template_reduction_percentage": 2.359882005899705,
      "author_type": "User"
    },
    "username": "akshayamadhuri"
  },
  {
    "pr_number": 26662,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 26638,
        "labels": [
          "Good First Issue",
          "HACKTOBERFEST-ACCEPTED"
        ]
      }
    ],
    "pr_data": {
      "number": 26662,
      "title": "fixed Docstring for configuration_bert.py file",
      "body": "# What does this PR do?\r\nfixes #26638 issue\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes # (issue)\r\n\r\n\r\n## Before submitting\r\n- [] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n@ydshieh \r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- text models: @ArthurZucker and @younesbelkada\r\n- vision models: @amyeroberts\r\n- speech models: @sanchit-gandhi\r\n- graph models: @clefourrier\r\n\r\nLibrary:\r\n\r\n- flax: @sanchit-gandhi\r\n- generate: @gante\r\n- pipelines: @Narsil\r\n- tensorflow: @gante and @Rocketknight1\r\n- tokenizers: @ArthurZucker\r\n- trainer: @muellerzr and @pacman100\r\n\r\nIntegrations:\r\n\r\n- deepspeed: HF Trainer/Accelerate: @pacman100\r\n- ray/raytune: @richardliaw, @amogkam\r\n- Big Model Inference: @SunMarc\r\n- quantization (bitsandbytes, autogpt): @SunMarc and @younesbelkada\r\n\r\nDocumentation: @stevhliu and @MKhalusova\r\n\r\nHF projects:\r\n\r\n- accelerate: [different repo](https://github.com/huggingface/accelerate)\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- diffusers: [different repo](https://github.com/huggingface/diffusers)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nMaintained examples (not research project or legacy):\r\n\r\n- Flax: @sanchit-gandhi\r\n- PyTorch: See Models above and tag the person corresponding to the modality of the example.\r\n- TensorFlow: @Rocketknight1\r\n\r\n -->\r\n",
      "body_length": 712,
      "created_at": "2023-10-07T16:11:21Z",
      "updated_at": "2023-10-10T21:04:09Z",
      "closed_at": "2023-10-10T14:42:38Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 618,
      "deletions": 8,
      "files_changed": 3,
      "commits_count": 2,
      "review_count": 0,
      "comment_count": 10,
      "pr_size": 626,
      "avg_commit_msg_length": 41.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 3
      },
      "review_states": {},
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\nfixes #26638 issue\r\n\r\n\r\n\r\n\r\n\r\nFixes # (issue)\r\n\r\n\r\n## Before submitting\r\n- [] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n@ydshieh \r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.",
      "body_cleaned_length": 1090,
      "template_removed_length": 2248,
      "template_reduction_percentage": 67.34571599760335,
      "author_type": "User"
    },
    "username": "neet-14"
  },
  {
    "pr_number": 26693,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 26638,
        "labels": [
          "Good First Issue",
          "HACKTOBERFEST-ACCEPTED"
        ]
      }
    ],
    "pr_data": {
      "number": 26693,
      "title": "[docstring] Fix docstring for `ASTFeatureExtractor`",
      "body": "# What does this PR do?\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes #26638\r\n\r\n## Who can review?\r\n\r\n@ydshieh \r\n",
      "body_length": 61,
      "created_at": "2023-10-09T13:43:58Z",
      "updated_at": "2023-10-11T13:58:05Z",
      "closed_at": "2023-10-09T18:04:25Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 0,
      "deletions": 1,
      "files_changed": 1,
      "commits_count": 3,
      "review_count": 0,
      "comment_count": 12,
      "pr_size": 1,
      "avg_commit_msg_length": 32.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {},
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\n\r\n\r\n\r\n\r\nFixes #26638\r\n\r\n## Who can review?\r\n\r\n@ydshieh",
      "body_cleaned_length": 81,
      "template_removed_length": 868,
      "template_reduction_percentage": 91.46469968387777,
      "author_type": "User"
    },
    "username": "imsoumya18"
  },
  {
    "pr_number": 27734,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 20815,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 27734,
      "title": "Deberta can now be exported to TorchScript ",
      "body": "# What does this PR do?\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes #20815\r\n\r\nGenerally, `torch.autograd.Functions` cannot be traced in Torch, as per this open issue: https://github.com/pytorch/pytorch/issues/32822\r\nThis issue is thus more of a PyTorch problem, but nevertheless can be resolved. 🤗 Transformers' implementation is basically the same as the original https://github.com/microsoft/DeBERTa, which was tracable with a dirty trick of using a tracing context: \r\nhttps://github.com/microsoft/DeBERTa/blob/4d7fe0bd4fb3c7d4f4005a7cafabde9800372098/DeBERTa/utils/jit_tracing.py#L10C1-L17C6\r\nOf course such a solution is not applicable here as it would conflict with the existing API and usage of the 🤗 Transformers. I have decided to explore a bit the recent development in PyTorch and it seems `is_tracing` is now publicly accessible through `torch.jit` (though it is not yet documented), which gets rid of the context problem. So I have basically implemented the original solution but with the newly available `is_tracing` call. \r\n\r\nI have also added tests to check if the traced model outputs the same tensors as the model that is being traced.\r\nThis was not mentioned in the issue but I have applied the same changes to Deberta_v2 since it is obviously also affected.\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [x] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n@ArthurZucker \r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- text models: @ArthurZucker and @younesbelkada\r\n- vision models: @amyeroberts\r\n- speech models: @sanchit-gandhi\r\n- graph models: @clefourrier\r\n\r\nLibrary:\r\n\r\n- flax: @sanchit-gandhi\r\n- generate: @gante\r\n- pipelines: @Narsil\r\n- tensorflow: @gante and @Rocketknight1\r\n- tokenizers: @ArthurZucker\r\n- trainer: @muellerzr and @pacman100\r\n\r\nIntegrations:\r\n\r\n- deepspeed: HF Trainer/Accelerate: @pacman100\r\n- ray/raytune: @richardliaw, @amogkam\r\n- Big Model Inference: @SunMarc\r\n- quantization (bitsandbytes, autogpt): @SunMarc and @younesbelkada\r\n\r\nDocumentation: @stevhliu and @MKhalusova\r\n\r\nHF projects:\r\n\r\n- accelerate: [different repo](https://github.com/huggingface/accelerate)\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- diffusers: [different repo](https://github.com/huggingface/diffusers)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nMaintained examples (not research project or legacy):\r\n\r\n- Flax: @sanchit-gandhi\r\n- PyTorch: See Models above and tag the person corresponding to the modality of the example.\r\n- TensorFlow: @Rocketknight1\r\n\r\n -->\r\n",
      "body_length": 1847,
      "created_at": "2023-11-27T20:48:20Z",
      "updated_at": "2024-10-12T21:38:37Z",
      "closed_at": null,
      "merged_at": null,
      "merged": false,
      "state": "OPEN",
      "time_to_merge_hours": null,
      "additions": 331,
      "deletions": 78,
      "files_changed": 5,
      "commits_count": 4,
      "review_count": 2,
      "comment_count": 21,
      "pr_size": 409,
      "avg_commit_msg_length": 35.5,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": true,
      "has_docs": false,
      "test_files": [
        "tests/models/deberta/test_modeling_deberta.py",
        "tests/models/deberta_v2/test_modeling_deberta_v2.py"
      ],
      "doc_files": [],
      "file_types": {
        "py": 5
      },
      "review_states": {
        "COMMENTED": 2
      },
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\n\r\n\r\n\r\n\r\nFixes #20815\r\n\r\nGenerally, `torch.autograd.Functions` cannot be traced in Torch, as per this open issue: https://github.com/pytorch/pytorch/issues/32822\r\nThis issue is thus more of a PyTorch problem, but nevertheless can be resolved. 🤗 Transformers' implementation is basically the same as the original https://github.com/microsoft/DeBERTa, which was tracable with a dirty trick of using a tracing context: \r\nhttps://github.com/microsoft/DeBERTa/blob/4d7fe0bd4fb3c7d4f4005a7cafabde9800372098/DeBERTa/utils/jit_tracing.py#L10C1-L17C6\r\nOf course such a solution is not applicable here as it would conflict with the existing API and usage of the 🤗 Transformers. I have decided to explore a bit the recent development in PyTorch and it seems `is_tracing` is now publicly accessible through `torch.jit` (though it is not yet documented), which gets rid of the context problem. So I have basically implemented the original solution but with the newly available `is_tracing` call. \r\n\r\nI have also added tests to check if the traced model outputs the same tensors as the model that is being traced.\r\nThis was not mentioned in the issue but I have applied the same changes to Deberta_v2 since it is obviously also affected.\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [x] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n@ArthurZucker",
      "body_cleaned_length": 2273,
      "template_removed_length": 2249,
      "template_reduction_percentage": 49.734630694383014,
      "author_type": "User"
    },
    "username": "Szustarol"
  },
  {
    "pr_number": 28231,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 28224,
        "labels": [
          "Documentation",
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 28231,
      "title": "Update docs related to generate() method in transformers/pipelines",
      "body": "# What does this PR do?\r\n\r\nFixes #28224\r\n\r\nIn the issue, it is suggested to change the link to [this](https://huggingface.co/docs/transformers/generation_strategies), but I find [this](https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/text_generation) to be a better fit.\r\n\r\n@stevhliu and @MKhalusova",
      "body_length": 154,
      "created_at": "2023-12-24T07:41:29Z",
      "updated_at": "2024-01-25T17:36:30Z",
      "closed_at": "2024-01-10T07:38:49Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 5,
      "deletions": 5,
      "files_changed": 3,
      "commits_count": 5,
      "review_count": 2,
      "comment_count": 6,
      "pr_size": 10,
      "avg_commit_msg_length": 62.8,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 3
      },
      "review_states": {
        "APPROVED": 2
      },
      "has_changes_requested": false,
      "has_approved": true,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nFixes #28224\r\n\r\nIn the issue, it is suggested to change the link to [this](https://huggingface.co/docs/transformers/generation_strategies), but I find [this](https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/text_generation) to be a better fit.\r\n\r\n@stevhliu and @MKhalusova",
      "body_cleaned_length": 315,
      "template_removed_length": 0,
      "template_reduction_percentage": 0.0,
      "author_type": "User"
    },
    "username": "coolyashas"
  },
  {
    "pr_number": 28315,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 28309,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 28315,
      "title": "Accelerate support added to Object Detection & Segmentation Models",
      "body": "# What does this PR do?\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes #28309\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- text models: @ArthurZucker and @younesbelkada\r\n- vision models: @amyeroberts\r\n- speech models: @sanchit-gandhi\r\n- graph models: @clefourrier\r\n\r\nLibrary:\r\n\r\n- flax: @sanchit-gandhi\r\n- generate: @gante\r\n- pipelines: @Narsil\r\n- tensorflow: @gante and @Rocketknight1\r\n- tokenizers: @ArthurZucker\r\n- trainer: @muellerzr and @pacman100\r\n\r\nIntegrations:\r\n\r\n- deepspeed: HF Trainer/Accelerate: @pacman100\r\n- ray/raytune: @richardliaw, @amogkam\r\n- Big Model Inference: @SunMarc\r\n- quantization (bitsandbytes, autogpt): @SunMarc and @younesbelkada\r\n\r\nDocumentation: @stevhliu and @MKhalusova\r\n\r\nHF projects:\r\n\r\n- accelerate: [different repo](https://github.com/huggingface/accelerate)\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- diffusers: [different repo](https://github.com/huggingface/diffusers)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nMaintained examples (not research project or legacy):\r\n\r\n- Flax: @sanchit-gandhi\r\n- PyTorch: See Models above and tag the person corresponding to the modality of the example.\r\n- TensorFlow: @Rocketknight1\r\n\r\n -->\r\n\r\n@NielsRogge ",
      "body_length": 690,
      "created_at": "2024-01-02T20:40:49Z",
      "updated_at": "2024-03-08T09:56:01Z",
      "closed_at": "2024-03-08T09:56:01Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 93,
      "deletions": 30,
      "files_changed": 9,
      "commits_count": 3,
      "review_count": 0,
      "comment_count": 5,
      "pr_size": 123,
      "avg_commit_msg_length": 51.333333333333336,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 9
      },
      "review_states": {},
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\n\r\n\r\n\r\n\r\nFixes #28309\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#start-contributing-pull-requests),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n\r\n\r\n@NielsRogge",
      "body_cleaned_length": 1077,
      "template_removed_length": 2243,
      "template_reduction_percentage": 67.56024096385542,
      "author_type": "User"
    },
    "username": "sam99dave"
  },
  {
    "pr_number": 29713,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 26099,
        "labels": [
          "Good First Issue",
          "Vision"
        ]
      }
    ],
    "pr_data": {
      "number": 29713,
      "title": "OWL-ViT precompute box_bias",
      "body": "Fixes #26099.\r\n\r\nPrecompute box_bias at initialization using the number of ViT patches and move it to the correct device at inference.\r\n\r\nAppreciate your review @amyeroberts @5hadytru!\r\n\r\n\r\n",
      "body_length": 178,
      "created_at": "2024-03-18T15:29:41Z",
      "updated_at": "2024-04-26T08:03:38Z",
      "closed_at": "2024-04-26T08:03:38Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 56,
      "deletions": 46,
      "files_changed": 2,
      "commits_count": 7,
      "review_count": 0,
      "comment_count": 3,
      "pr_size": 102,
      "avg_commit_msg_length": 61.142857142857146,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 2
      },
      "review_states": {},
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "Fixes #26099.\r\n\r\nPrecompute box_bias at initialization using the number of ViT patches and move it to the correct device at inference.\r\n\r\nAppreciate your review @amyeroberts @5hadytru!",
      "body_cleaned_length": 184,
      "template_removed_length": 6,
      "template_reduction_percentage": 3.1578947368421053,
      "author_type": "User"
    },
    "username": "nvbinh15"
  },
  {
    "pr_number": 30075,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 28882,
        "labels": [
          "bug",
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 30075,
      "title": "resolving the wrapper bug on the 759th line",
      "body": "# What does this PR do?\r\nthis PR resolve the error that was on the 759 line .\r\nThe error was \"\"\"<BatchEncoding won't prepend batch axis to python list, even prepend_batch_axis is True>\"\"\" \r\nThe below is the test case you told the users to try\r\n![Screenshot 2024-04-06 003841](https://github.com/huggingface/transformers/assets/138205342/f8df8294-82d2-46df-8882-388f589509d3)\r\n![Screenshot 2024-04-06 003849](https://github.com/huggingface/transformers/assets/138205342/7b385b1c-53e2-41e2-9e26-289fb377b4c9)\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes #28882\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- text models: @ArthurZucker and @younesbelkada\r\n- vision models: @amyeroberts\r\n- speech models: @sanchit-gandhi\r\n- graph models: @clefourrier\r\n\r\nLibrary:\r\n\r\n- flax: @sanchit-gandhi\r\n- generate: @gante\r\n- pipelines: @Narsil\r\n- tensorflow: @gante and @Rocketknight1\r\n- tokenizers: @ArthurZucker\r\n- trainer: @muellerzr and @pacman100\r\n\r\nIntegrations:\r\n\r\n- deepspeed: HF Trainer/Accelerate: @pacman100\r\n- ray/raytune: @richardliaw, @amogkam\r\n- Big Model Inference: @SunMarc\r\n- quantization (bitsandbytes, autogpt): @SunMarc and @younesbelkada\r\n\r\nDocumentation: @stevhliu and @MKhalusova\r\n\r\nHF projects:\r\n\r\n- accelerate: [different repo](https://github.com/huggingface/accelerate)\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- diffusers: [different repo](https://github.com/huggingface/diffusers)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nMaintained examples (not research project or legacy):\r\n\r\n- Flax: @sanchit-gandhi\r\n- PyTorch: See Models above and tag the person corresponding to the modality of the example.\r\n- TensorFlow: @Rocketknight1\r\n\r\n -->\r\n",
      "body_length": 894,
      "created_at": "2024-04-05T19:11:57Z",
      "updated_at": "2024-05-21T08:03:46Z",
      "closed_at": "2024-05-21T08:03:46Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 4,
      "deletions": 1,
      "files_changed": 1,
      "commits_count": 1,
      "review_count": 1,
      "comment_count": 2,
      "pr_size": 5,
      "avg_commit_msg_length": 43.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {
        "COMMENTED": 1
      },
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\nthis PR resolve the error that was on the 759 line .\r\nThe error was \"\"\"<BatchEncoding won't prepend batch axis to python list, even prepend_batch_axis is True>\"\"\" \r\nThe below is the test case you told the users to try\r\n![Screenshot 2024-04-06 003841](https://github.com/huggingface/transformers/assets/138205342/f8df8294-82d2-46df-8882-388f589509d3)\r\n![Screenshot 2024-04-06 003849](https://github.com/huggingface/transformers/assets/138205342/7b385b1c-53e2-41e2-9e26-289fb377b4c9)\r\n\r\n\r\n\r\n\r\n\r\nFixes #28882\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.",
      "body_cleaned_length": 1530,
      "template_removed_length": 2248,
      "template_reduction_percentage": 59.502382212811014,
      "author_type": "User"
    },
    "username": "pratyakshagarwal"
  },
  {
    "pr_number": 33143,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 32560,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 33143,
      "title": "fix: Fix optimizer bug in ModelCard",
      "body": "# What does this PR do?\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes #32560 \r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- text models: @ArthurZucker\r\n- vision models: @amyeroberts\r\n- speech models: @sanchit-gandhi\r\n- graph models: @clefourrier\r\n\r\nLibrary:\r\n\r\n- flax: @sanchit-gandhi\r\n- generate: @zucchini-nlp (visual-language models) or @gante (all others)\r\n- pipelines: @Narsil\r\n- tensorflow: @gante and @Rocketknight1\r\n- tokenizers: @ArthurZucker\r\n- trainer: @muellerzr and @SunMarc\r\n\r\nIntegrations:\r\n\r\n- deepspeed: HF Trainer/Accelerate: @muellerzr\r\n- ray/raytune: @richardliaw, @amogkam\r\n- Big Model Inference: @SunMarc\r\n- quantization (bitsandbytes, autogpt): @SunMarc\r\n\r\nDocumentation: @stevhliu\r\n\r\nHF projects:\r\n\r\n- accelerate: [different repo](https://github.com/huggingface/accelerate)\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- diffusers: [different repo](https://github.com/huggingface/diffusers)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nMaintained examples (not research project or legacy):\r\n\r\n- Flax: @sanchit-gandhi\r\n- PyTorch: See Models above and tag the person corresponding to the modality of the example.\r\n- TensorFlow: @Rocketknight1\r\n\r\n -->\r\n\r\n@SunMarc, @muellerzr\r\n\r\n",
      "body_length": 699,
      "created_at": "2024-08-27T13:12:03Z",
      "updated_at": "2024-10-08T04:31:27Z",
      "closed_at": "2024-10-02T11:45:22Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 8,
      "deletions": 5,
      "files_changed": 1,
      "commits_count": 2,
      "review_count": 11,
      "comment_count": 4,
      "pr_size": 13,
      "avg_commit_msg_length": 24.0,
      "has_conventional_commits": true,
      "conventional_commit_ratio": 1.0,
      "commit_types": [
        "fix"
      ],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {
        "COMMENTED": 11
      },
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\n\r\n\r\n\r\n\r\nFixes #32560 \r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n\r\n\r\n@SunMarc, @muellerzr",
      "body_cleaned_length": 1076,
      "template_removed_length": 2245,
      "template_reduction_percentage": 67.6001204456489,
      "author_type": "User"
    },
    "username": "relic-yuexi"
  },
  {
    "pr_number": 34321,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 34204,
        "labels": [
          "bug",
          "Good First Issue",
          "Vision",
          "Multimodal"
        ]
      }
    ],
    "pr_data": {
      "number": 34321,
      "title": "Fix PixtralProcessor to return outputs for all examples in a batch",
      "body": "Fixes #34204\n\nUpdate `PixtralProcessor` to handle batches of images and text prompts correctly.\n\n* Modify the `__call__` method in `src/transformers/models/pixtral/processing_pixtral.py` to process each example in a batch individually.\n* Update the handling of images to correctly iterate over the zip of images, image sizes, and text.\n* Add a test case in `tests/models/pixtral/test_processor_pixtral.py` to verify the `PixtralProcessor` returns the outputs corresponding to all prompts and images in a batch.\n* Ensure the test case includes multiple images and text prompts in a batch and verifies the outputs match the expected outputs for all examples in the batch.\n\n---\n\nFor more details, open the [Copilot Workspace session](https://copilot-workspace.githubnext.com/huggingface/transformers/issues/34204?shareId=09fc5267-4419-410b-ad6f-87d460569bf7).",
      "body_length": 706,
      "created_at": "2024-10-22T21:03:55Z",
      "updated_at": "2024-10-29T09:10:19Z",
      "closed_at": null,
      "merged_at": null,
      "merged": false,
      "state": "OPEN",
      "time_to_merge_hours": null,
      "additions": 122,
      "deletions": 0,
      "files_changed": 1,
      "commits_count": 2,
      "review_count": 2,
      "comment_count": 1,
      "pr_size": 122,
      "avg_commit_msg_length": 637.5,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": true,
      "has_docs": false,
      "test_files": [
        "tests/models/pixtral/test_processor_pixtral.py"
      ],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {
        "COMMENTED": 2
      },
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "Fixes #34204\n\nUpdate `PixtralProcessor` to handle batches of images and text prompts correctly.\n\n* Modify the `__call__` method in `src/transformers/models/pixtral/processing_pixtral.py` to process each example in a batch individually.\n* Update the handling of images to correctly iterate over the zip of images, image sizes, and text.\n* Add a test case in `tests/models/pixtral/test_processor_pixtral.py` to verify the `PixtralProcessor` returns the outputs corresponding to all prompts and images in a batch.\n* Ensure the test case includes multiple images and text prompts in a batch and verifies the outputs match the expected outputs for all examples in the batch.\n\n---\n\nFor more details, open the [Copilot Workspace session](https://copilot-workspace.githubnext.com/huggingface/transformers/issues/34204?shareId=09fc5267-4419-410b-ad6f-87d460569bf7).",
      "body_cleaned_length": 856,
      "template_removed_length": 0,
      "template_reduction_percentage": 0.0,
      "author_type": "User"
    },
    "username": "Ryukijano"
  },
  {
    "pr_number": 34646,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 33290,
        "labels": [
          "Usage",
          "bug",
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 34646,
      "title": "Aryan_33290",
      "body": "# What does this PR do?\r\nMinimized Gradient Casting to float32:\r\n\r\nInstead of casting gradients to float32 upfront, the optimizer now retains the original precision of grad (float16 or bfloat16), using that precision for all calculations unless a specific operation demands higher precision.\r\nPrecision Management for Moment States:\r\n\r\nThe moment estimates (exp_avg, exp_avg_sq_row, exp_avg_sq_col, exp_avg_sq) are initialized and updated in the same precision as grad, reducing the memory overhead compared to float32 calculations.\r\nIn-place Operations for Intermediate Calculations:\r\n\r\nOperations like grad**2 + group[\"eps\"][0] and mean calculations are now done in-place (e.g., add_ instead of +), which avoids temporary tensor creation and reduces memory consumption.\r\nStreamlined Factored Updates:\r\n\r\nFor factored updates, the calculations of exp_avg_sq_row and exp_avg_sq_col mean values are done in place, reducing the peak memory usage at each step.\r\nReusing update after calculating exp_avg_sq_row and exp_avg_sq_col saves memory by avoiding multiple copies.\r\nDirect In-Place Updates for p_data_fp32:\r\n\r\nInstead of copying p_data_fp32 back and forth, we update it directly in place, and only if p was initially in float16 or bfloat16, we convert p_data_fp32 back at the end.\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes #33290 \r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- text models: @ArthurZucker\r\n- vision models: @amyeroberts, @qubvel\r\n- speech models: @ylacombe, @eustlb\r\n- graph models: @clefourrier\r\n\r\nLibrary:\r\n\r\n- flax: @sanchit-gandhi\r\n- generate: @zucchini-nlp (visual-language models) or @gante (all others)\r\n- pipelines: @Rocketknight1\r\n- tensorflow: @gante and @Rocketknight1\r\n- tokenizers: @ArthurZucker\r\n- trainer: @muellerzr and @SunMarc\r\n- chat templates: @Rocketknight1\r\n\r\nIntegrations:\r\n\r\n- deepspeed: HF Trainer/Accelerate: @muellerzr\r\n- ray/raytune: @richardliaw, @amogkam\r\n- Big Model Inference: @SunMarc\r\n- quantization (bitsandbytes, autogpt): @SunMarc @MekkCyber\r\n\r\nDocumentation: @stevhliu\r\n\r\nHF projects:\r\n\r\n- accelerate: [different repo](https://github.com/huggingface/accelerate)\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- diffusers: [different repo](https://github.com/huggingface/diffusers)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nMaintained examples (not research project or legacy):\r\n\r\n- Flax: @sanchit-gandhi\r\n- PyTorch: See Models above and tag the person corresponding to the modality of the example.\r\n- TensorFlow: @Rocketknight1\r\n\r\n -->\r\n",
      "body_length": 1916,
      "created_at": "2024-11-07T22:59:40Z",
      "updated_at": "2025-06-19T02:20:55Z",
      "closed_at": null,
      "merged_at": null,
      "merged": false,
      "state": "OPEN",
      "time_to_merge_hours": null,
      "additions": 82,
      "deletions": 73,
      "files_changed": 1,
      "commits_count": 3,
      "review_count": 1,
      "comment_count": 0,
      "pr_size": 155,
      "avg_commit_msg_length": 34.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {
        "COMMENTED": 1
      },
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\nMinimized Gradient Casting to float32:\r\n\r\nInstead of casting gradients to float32 upfront, the optimizer now retains the original precision of grad (float16 or bfloat16), using that precision for all calculations unless a specific operation demands higher precision.\r\nPrecision Management for Moment States:\r\n\r\nThe moment estimates (exp_avg, exp_avg_sq_row, exp_avg_sq_col, exp_avg_sq) are initialized and updated in the same precision as grad, reducing the memory overhead compared to float32 calculations.\r\nIn-place Operations for Intermediate Calculations:\r\n\r\nOperations like grad**2 + group[\"eps\"][0] and mean calculations are now done in-place (e.g., add_ instead of +), which avoids temporary tensor creation and reduces memory consumption.\r\nStreamlined Factored Updates:\r\n\r\nFor factored updates, the calculations of exp_avg_sq_row and exp_avg_sq_col mean values are done in place, reducing the peak memory usage at each step.\r\nReusing update after calculating exp_avg_sq_row and exp_avg_sq_col saves memory by avoiding multiple copies.\r\nDirect In-Place Updates for p_data_fp32:\r\n\r\nInstead of copying p_data_fp32 back and forth, we update it directly in place, and only if p was initially in float16 or bfloat16, we convert p_data_fp32 back at the end.\r\n\r\n\r\n\r\n\r\n\r\nFixes #33290 \r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.",
      "body_cleaned_length": 2308,
      "template_removed_length": 2311,
      "template_reduction_percentage": 50.03247456159342,
      "author_type": "User"
    },
    "username": "Aryan8912"
  },
  {
    "pr_number": 36782,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 35290,
        "labels": [
          "bug",
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 36782,
      "title": "Fix attention_mask dimension issue in GPT2Model",
      "body": "# What does this PR do?\r\n\r\nThis PR fixes a bug in GPT2Model where the 'attention_mask' was incorrectly reshaped from 4D to 2D.\r\nthe fix ensures that 'attention_mask.view()' is only applied when the dimension is 2, preventing shape mismatches.\r\n\r\nFixes #35290\r\n\r\n\r\n## Before submitting\r\n\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      [issue link](https://github.com/huggingface/transformers/issues/35290)\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n@ArthurZucker, since this PR affects text models.\r\n@Rocketknight1, since this PR modifies attention mask handling.\r\n",
      "body_length": 840,
      "created_at": "2025-03-18T04:03:39Z",
      "updated_at": "2025-03-20T09:47:38Z",
      "closed_at": null,
      "merged_at": null,
      "merged": false,
      "state": "OPEN",
      "time_to_merge_hours": null,
      "additions": 2,
      "deletions": 1,
      "files_changed": 1,
      "commits_count": 2,
      "review_count": 1,
      "comment_count": 2,
      "pr_size": 3,
      "avg_commit_msg_length": 45.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {
        "COMMENTED": 1
      },
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nThis PR fixes a bug in GPT2Model where the 'attention_mask' was incorrectly reshaped from 4D to 2D.\r\nthe fix ensures that 'attention_mask.view()' is only applied when the dimension is 2, preventing shape mismatches.\r\n\r\nFixes #35290\r\n\r\n\r\n## Before submitting\r\n\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      [issue link](https://github.com/huggingface/transformers/issues/35290)\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n@ArthurZucker, since this PR affects text models.\r\n@Rocketknight1, since this PR modifies attention mask handling.",
      "body_cleaned_length": 1270,
      "template_removed_length": 2,
      "template_reduction_percentage": 0.15723270440251574,
      "author_type": "User"
    },
    "username": "sukwoojang"
  },
  {
    "pr_number": 36916,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 31561,
        "labels": [
          "Good First Issue",
          "trainer",
          "Feature request"
        ]
      }
    ],
    "pr_data": {
      "number": 36916,
      "title": "Limit number of evaluation samples processed during training",
      "body": "# What does this PR do?\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\ncloses #31561 \r\n\r\n\r\n## Before submitting\r\n- [no ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [yes ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [yes ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\ncloses #31561 \r\n- [ no] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\nThere seems to be no documentation for TrainingArgument. I added a line in the training_args.py to explain the new argument. \r\n- [yes ] Did you write any new necessary tests?\r\ntest_number_of_eval_samples_set and test_number_of_eval_samples_unset in tests/trainer/test_trainer.py\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- text models: @ArthurZucker\r\n- vision models: @amyeroberts, @qubvel\r\n- speech models: @eustlb\r\n- graph models: @clefourrier\r\n\r\nLibrary:\r\n\r\n- flax: @gante and @Rocketknight1\r\n- generate: @zucchini-nlp (visual-language models) or @gante (all others)\r\n- pipelines: @Rocketknight1\r\n- tensorflow: @gante and @Rocketknight1\r\n- tokenizers: @ArthurZucker\r\n- trainer: @muellerzr and @SunMarc\r\n- chat templates: @Rocketknight1\r\n\r\nIntegrations:\r\n\r\n- deepspeed: HF Trainer/Accelerate: @muellerzr\r\n- ray/raytune: @richardliaw, @amogkam\r\n- Big Model Inference: @SunMarc\r\n- quantization (bitsandbytes, autogpt): @SunMarc @MekkCyber\r\n\r\nDocumentation: @stevhliu\r\n\r\nHF projects:\r\n\r\n- accelerate: [different repo](https://github.com/huggingface/accelerate)\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- diffusers: [different repo](https://github.com/huggingface/diffusers)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nMaintained examples (not research project or legacy):\r\n\r\n- Flax: @Rocketknight1\r\n- PyTorch: See Models above and tag the person corresponding to the modality of the example.\r\n- TensorFlow: @Rocketknight1\r\n\r\n -->\r\n",
      "body_length": 948,
      "created_at": "2025-03-24T06:07:53Z",
      "updated_at": "2025-08-26T15:04:43Z",
      "closed_at": null,
      "merged_at": null,
      "merged": false,
      "state": "OPEN",
      "time_to_merge_hours": null,
      "additions": 104,
      "deletions": 3,
      "files_changed": 3,
      "commits_count": 100,
      "review_count": 9,
      "comment_count": 13,
      "pr_size": 107,
      "avg_commit_msg_length": 215.96,
      "has_conventional_commits": true,
      "conventional_commit_ratio": 0.03,
      "commit_types": [
        "ci",
        "fix"
      ],
      "has_tests": true,
      "has_docs": false,
      "test_files": [
        "tests/trainer/test_trainer.py"
      ],
      "doc_files": [],
      "file_types": {
        "py": 3
      },
      "review_states": {
        "COMMENTED": 6,
        "APPROVED": 3
      },
      "has_changes_requested": false,
      "has_approved": true,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\n\r\n\r\n\r\n\r\ncloses #31561 \r\n\r\n\r\n## Before submitting\r\n- [no ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [yes ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [yes ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\ncloses #31561 \r\n- [ no] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\nThere seems to be no documentation for TrainingArgument. I added a line in the training_args.py to explain the new argument. \r\n- [yes ] Did you write any new necessary tests?\r\ntest_number_of_eval_samples_set and test_number_of_eval_samples_unset in tests/trainer/test_trainer.py\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.",
      "body_cleaned_length": 1309,
      "template_removed_length": 2309,
      "template_reduction_percentage": 63.81978993919293,
      "author_type": "User"
    },
    "username": "soghomon-b"
  },
  {
    "pr_number": 37174,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 30718,
        "labels": [
          "Good First Issue",
          "Feature request",
          "Vision"
        ]
      }
    ],
    "pr_data": {
      "number": 37174,
      "title": "add image processor for table transformer, and fix value inconsistency",
      "body": "# What does this PR do?\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes #30718\r\n\r\n\r\n## Before submitting\r\n- [] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [x] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\n\r\nModels:\r\n\r\n- text models: @ArthurZucker\r\n- vision models: @amyeroberts, @qubvel\r\n- speech models: @eustlb\r\n- graph models: @clefourrier\r\n\r\nLibrary:\r\n\r\n- flax: @gante and @Rocketknight1\r\n- generate: @zucchini-nlp (visual-language models) or @gante (all others)\r\n- pipelines: @Rocketknight1\r\n- tensorflow: @gante and @Rocketknight1\r\n- tokenizers: @ArthurZucker\r\n- trainer: @zach-huggingface and @SunMarc\r\n- chat templates: @Rocketknight1\r\n\r\nIntegrations:\r\n\r\n- deepspeed: HF Trainer/Accelerate: @SunMarc @zach-huggingface\r\n- ray/raytune: @richardliaw, @amogkam\r\n- Big Model Inference: @SunMarc\r\n- quantization (bitsandbytes, autogpt): @SunMarc @MekkCyber\r\n\r\nDocumentation: @stevhliu\r\n\r\nHF projects:\r\n\r\n- accelerate: [different repo](https://github.com/huggingface/accelerate)\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- diffusers: [different repo](https://github.com/huggingface/diffusers)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nMaintained examples (not research project or legacy):\r\n\r\n- Flax: @Rocketknight1\r\n- PyTorch: See Models above and tag the person corresponding to the modality of the example.\r\n- TensorFlow: @Rocketknight1\r\n\r\n -->\r\n@NielsRogge\r\n",
      "body_length": 692,
      "created_at": "2025-04-01T14:41:06Z",
      "updated_at": "2025-04-01T15:57:34Z",
      "closed_at": "2025-04-01T15:57:34Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 2764,
      "deletions": 11,
      "files_changed": 9,
      "commits_count": 12,
      "review_count": 0,
      "comment_count": 2,
      "pr_size": 2775,
      "avg_commit_msg_length": 384.9166666666667,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": true,
      "has_docs": true,
      "test_files": [
        "tests/models/table_transformer/test_image_processing_table_transformer.py"
      ],
      "doc_files": [
        "docs/source/en/model_doc/table-transformer.md"
      ],
      "file_types": {
        "md": 1,
        "py": 8
      },
      "review_states": {},
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\n\r\n\r\n\r\n\r\nFixes #30718\r\n\r\n\r\n## Before submitting\r\n- [] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [x] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [x] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n\r\n@NielsRogge",
      "body_cleaned_length": 1063,
      "template_removed_length": 2330,
      "template_reduction_percentage": 68.67079280872385,
      "author_type": "User"
    },
    "username": "zhouksh"
  },
  {
    "pr_number": 37460,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 28180,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 37460,
      "title": "Fix interpolation of convnext image processor",
      "body": "# What does this PR do?\r\nImage processors do not have the same interpolation method used in the actual models (reference to actual models: timm). This PR fixes:\r\n- the interpolation method for ConvNext\r\n- updates the conversion script to use timm models instead of downloading checkpoints from url. This was necessary to overcome the AssertionError thrown from comparing the logits to the hard-coded logits from the checkpoint url and fixes the bug in #37461 \r\n- Convnext model (in timm) seems to use `IMAGENET_DEFAULT_MEAN/STD` to normalize image. But the default value set in `ConvNextImageProcessor` and `ConvNextImageProcessorFast` are `IMAGENET_STANDARD_MEAN/STD`. This has been fixed in this PR.\r\n\r\nFor the 2nd point above, the following timm models were tested to pass all assertions in the script. The following table summarizes the equivalence between the timm models and the checkpoint urls in the original script.\r\n\r\n### Some noteworthy changes\r\n(!) Default interpolator was updated on `ConvNextImageProcessorFast`. But `timm_pixel_values` do not match and raise an AssertionError. This is outside the scope of this PR.\r\n\r\n| Checkpoint URL      | TIMM model name |\r\n| ----------- | ----------- |\r\n| [convnext_tiny_1k_224_ema.pth](https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth) | [convnext_tiny.fb_in1k](https://huggingface.co/timm/convnext_tiny.fb_in1k) |\r\n| [convnext_small_1k_224_ema.pth](https://dl.fbaipublicfiles.com/convnext/convnext_small_1k_224_ema.pth) | [convnext_small.fb_in1k](https://huggingface.co/timm/convnext_small.fb_in1k) |\r\n| [convnext_base_1k_224_ema.pth](https://dl.fbaipublicfiles.com/convnext/convnext_base_1k_224_ema.pth) | [convnext_base.fb_in1k](https://huggingface.co/timm/convnext_base.fb_in1k) |\r\n| [convnext_base_1k_384.pth](https://dl.fbaipublicfiles.com/convnext/convnext_base_1k_384.pth) | Not available |\r\n| [convnext_large_1k_224_ema.pth](https://dl.fbaipublicfiles.com/convnext/convnext_large_1k_224_ema.pth) | [convnext_large.fb_in1k](https://huggingface.co/timm/convnext_large.fb_in1k) |\r\n| [convnext_large_1k_384.pth](https://dl.fbaipublicfiles.com/convnext/convnext_large_1k_384.pth) | Not available |\r\n| [convnext_base_22k_224.pth](https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_224.pth) | [convnext_base.fb_in22k](https://huggingface.co/timm/convnext_base.fb_in22k) |\r\n| [convnext_large_22k_224.pth](https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_224.pth) | [convnext_large.fb_in22k](https://huggingface.co/timm/convnext_large.fb_in22k) |\r\n| [convnext_xlarge_22k_224.pth](https://dl.fbaipublicfiles.com/convnext/convnext_xlarge_22k_224.pth) | [convnext_xlarge.fb_in22k](https://huggingface.co/timm/convnext_xlarge.fb_in22k) |\r\n| [convnext_base_22k_1k_224.pth](https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_1k_224.pth) | [convnext_base.fb_in22k_ft_in1k](https://huggingface.co/timm/convnext_base.fb_in22k_ft_in1k) |\r\n| [convnext_base_22k_1k_384.pth](https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_1k_384.pth) | [convnext_base.fb_in22k_ft_in1k_384](https://huggingface.co/timm/convnext_base.fb_in22k_ft_in1k_384) |\r\n| [convnext_large_22k_1k_224.pth](https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_1k_224.pth) | [convnext_large.fb_in22k_ft_in1k](https://huggingface.co/timm/convnext_large.fb_in22k_ft_in1k) |\r\n| [convnext_large_22k_1k_384.pth](https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_1k_384.pth) | [convnext_large.fb_in22k_ft_in1k_384](https://huggingface.co/timm/convnext_large.fb_in22k_ft_in1k_384) |\r\n| [convnext_xlarge_22k_1k_224_ema.pth](https://dl.fbaipublicfiles.com/convnext/convnext_xlarge_22k_1k_224_ema.pth) | [convnext_xlarge.fb_in22k_ft_in1k](https://huggingface.co/timm/convnext_xlarge.fb_in22k_ft_in1k) |\r\n| [convnext_xlarge_22k_1k_384_ema.pth](https://dl.fbaipublicfiles.com/convnext/convnext_xlarge_22k_1k_384_ema.pth) | [convnext_xlarge.fb_in22k_ft_in1k_384](https://huggingface.co/timm/convnext_xlarge.fb_in22k_ft_in1k_384) |\r\n\r\nThe following were not tested:\r\n- `model.save_pretrained` and `image_processor.save_pretrained`\r\n- `model.push_to_hub`\r\n\r\nFixes #28180 , #37461\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n@NielsRogge @amyeroberts \r\n\r\n",
      "body_length": 2645,
      "created_at": "2025-04-11T20:37:44Z",
      "updated_at": "2025-07-07T12:08:22Z",
      "closed_at": null,
      "merged_at": null,
      "merged": false,
      "state": "OPEN",
      "time_to_merge_hours": null,
      "additions": 140,
      "deletions": 55,
      "files_changed": 3,
      "commits_count": 34,
      "review_count": 3,
      "comment_count": 12,
      "pr_size": 195,
      "avg_commit_msg_length": 58.8235294117647,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 3
      },
      "review_states": {
        "COMMENTED": 3
      },
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\nImage processors do not have the same interpolation method used in the actual models (reference to actual models: timm). This PR fixes:\r\n- the interpolation method for ConvNext\r\n- updates the conversion script to use timm models instead of downloading checkpoints from url. This was necessary to overcome the AssertionError thrown from comparing the logits to the hard-coded logits from the checkpoint url and fixes the bug in #37461 \r\n- Convnext model (in timm) seems to use `IMAGENET_DEFAULT_MEAN/STD` to normalize image. But the default value set in `ConvNextImageProcessor` and `ConvNextImageProcessorFast` are `IMAGENET_STANDARD_MEAN/STD`. This has been fixed in this PR.\r\n\r\nFor the 2nd point above, the following timm models were tested to pass all assertions in the script. The following table summarizes the equivalence between the timm models and the checkpoint urls in the original script.\r\n\r\n### Some noteworthy changes\r\n(!) Default interpolator was updated on `ConvNextImageProcessorFast`. But `timm_pixel_values` do not match and raise an AssertionError. This is outside the scope of this PR.\r\n\r\n| Checkpoint URL      | TIMM model name |\r\n| ----------- | ----------- |\r\n| [convnext_tiny_1k_224_ema.pth](https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth) | [convnext_tiny.fb_in1k](https://huggingface.co/timm/convnext_tiny.fb_in1k) |\r\n| [convnext_small_1k_224_ema.pth](https://dl.fbaipublicfiles.com/convnext/convnext_small_1k_224_ema.pth) | [convnext_small.fb_in1k](https://huggingface.co/timm/convnext_small.fb_in1k) |\r\n| [convnext_base_1k_224_ema.pth](https://dl.fbaipublicfiles.com/convnext/convnext_base_1k_224_ema.pth) | [convnext_base.fb_in1k](https://huggingface.co/timm/convnext_base.fb_in1k) |\r\n| [convnext_base_1k_384.pth](https://dl.fbaipublicfiles.com/convnext/convnext_base_1k_384.pth) | Not available |\r\n| [convnext_large_1k_224_ema.pth](https://dl.fbaipublicfiles.com/convnext/convnext_large_1k_224_ema.pth) | [convnext_large.fb_in1k](https://huggingface.co/timm/convnext_large.fb_in1k) |\r\n| [convnext_large_1k_384.pth](https://dl.fbaipublicfiles.com/convnext/convnext_large_1k_384.pth) | Not available |\r\n| [convnext_base_22k_224.pth](https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_224.pth) | [convnext_base.fb_in22k](https://huggingface.co/timm/convnext_base.fb_in22k) |\r\n| [convnext_large_22k_224.pth](https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_224.pth) | [convnext_large.fb_in22k](https://huggingface.co/timm/convnext_large.fb_in22k) |\r\n| [convnext_xlarge_22k_224.pth](https://dl.fbaipublicfiles.com/convnext/convnext_xlarge_22k_224.pth) | [convnext_xlarge.fb_in22k](https://huggingface.co/timm/convnext_xlarge.fb_in22k) |\r\n| [convnext_base_22k_1k_224.pth](https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_1k_224.pth) | [convnext_base.fb_in22k_ft_in1k](https://huggingface.co/timm/convnext_base.fb_in22k_ft_in1k) |\r\n| [convnext_base_22k_1k_384.pth](https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_1k_384.pth) | [convnext_base.fb_in22k_ft_in1k_384](https://huggingface.co/timm/convnext_base.fb_in22k_ft_in1k_384) |\r\n| [convnext_large_22k_1k_224.pth](https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_1k_224.pth) | [convnext_large.fb_in22k_ft_in1k](https://huggingface.co/timm/convnext_large.fb_in22k_ft_in1k) |\r\n| [convnext_large_22k_1k_384.pth](https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_1k_384.pth) | [convnext_large.fb_in22k_ft_in1k_384](https://huggingface.co/timm/convnext_large.fb_in22k_ft_in1k_384) |\r\n| [convnext_xlarge_22k_1k_224_ema.pth](https://dl.fbaipublicfiles.com/convnext/convnext_xlarge_22k_1k_224_ema.pth) | [convnext_xlarge.fb_in22k_ft_in1k](https://huggingface.co/timm/convnext_xlarge.fb_in22k_ft_in1k) |\r\n| [convnext_xlarge_22k_1k_384_ema.pth](https://dl.fbaipublicfiles.com/convnext/convnext_xlarge_22k_1k_384_ema.pth) | [convnext_xlarge.fb_in22k_ft_in1k_384](https://huggingface.co/timm/convnext_xlarge.fb_in22k_ft_in1k_384) |\r\n\r\nThe following were not tested:\r\n- `model.save_pretrained` and `image_processor.save_pretrained`\r\n- `model.push_to_hub`\r\n\r\nFixes #28180 , #37461\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n@NielsRogge @amyeroberts",
      "body_cleaned_length": 5013,
      "template_removed_length": 5,
      "template_reduction_percentage": 0.09964129135113592,
      "author_type": "User"
    },
    "username": "chandrusuresh"
  },
  {
    "pr_number": 37582,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 16135,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 37582,
      "title": "Add code examples for creating & fine‑tuning EncoderDecoderModel (fixes #16135)",
      "body": "This PR implements the first two code‑example requests from Issue #16135:\r\n\r\n1. Create & Save an EncoderDecoderModel\r\n   - Shows how to load pre‑trained encoder & decoder, then save the combined model.\r\n\r\n2. Fine‑Tune an EncoderDecoderModel\r\n   - Demonstrates a one‑epoch training loop on a tiny sample dataset.\r\n\r\nBoth snippets are inserted under the appropriate bullets in `docs/source/model_doc/encoder-decoder.mdx` and have been verified by a local `make docs` build.  \r\n\r\nCloses #16135.\r\n",
      "body_length": 465,
      "created_at": "2025-04-17T13:45:33Z",
      "updated_at": "2025-04-17T21:34:15Z",
      "closed_at": null,
      "merged_at": null,
      "merged": false,
      "state": "OPEN",
      "time_to_merge_hours": null,
      "additions": 66,
      "deletions": 0,
      "files_changed": 1,
      "commits_count": 1,
      "review_count": 0,
      "comment_count": 3,
      "pr_size": 66,
      "avg_commit_msg_length": 64.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": true,
      "test_files": [],
      "doc_files": [
        "docs/source/model_doc/encoder-decoder.mdx"
      ],
      "file_types": {
        "mdx": 1
      },
      "review_states": {},
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "This PR implements the first two code‑example requests from Issue #16135:\r\n\r\n1. Create & Save an EncoderDecoderModel\r\n   - Shows how to load pre‑trained encoder & decoder, then save the combined model.\r\n\r\n2. Fine‑Tune an EncoderDecoderModel\r\n   - Demonstrates a one‑epoch training loop on a tiny sample dataset.\r\n\r\nBoth snippets are inserted under the appropriate bullets in `docs/source/model_doc/encoder-decoder.mdx` and have been verified by a local `make docs` build.  \r\n\r\nCloses #16135.",
      "body_cleaned_length": 491,
      "template_removed_length": 2,
      "template_reduction_percentage": 0.4056795131845842,
      "author_type": "User"
    },
    "username": "HarshitaTechWizard"
  },
  {
    "pr_number": 37987,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 21110,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 37987,
      "title": "Add BLIP and GIT model support to image-to-text pipeline",
      "body": "# What does this PR do?\r\nThis PR adds support for using BLIP and GIT models with the `image-to-text` pipeline.\r\n\r\nBoth model types already had underlying compatibility in `ImageToTextPipeline`, but they were not formally registered in `SUPPORTED_TASKS`, which prevented `pipeline(..., model=\"Salesforce/blip-image-captioning-base\")` from working directly.\r\n\r\n### Changes:\r\n- Updated `SUPPORTED_TASKS[\"image-to-text\"][\"pt\"]` to include `\"blip\"` and `\"git\"` model types.\r\n\r\n### Motivation:\r\nThis enables easier access to popular models like BLIP and GIT via the pipeline interface, improving usability for multimodal captioning tasks.\r\n\r\n---\r\n\r\nFixes: #21110 \r\n\r\n## Before submitting\r\n- [x] I’ve tested the change locally with BLIP models and it works correctly.\r\n- [x] I’ve read the [contributor guidelines](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request).\r\n\r\n## Who can review?\r\n\r\n@Rocketknight1 @zucchini-nlp (for visual-language model pipelines)\r\n",
      "body_length": 826,
      "created_at": "2025-05-06T23:04:29Z",
      "updated_at": "2025-05-07T19:01:28Z",
      "closed_at": "2025-05-07T19:01:28Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 1,
      "deletions": 0,
      "files_changed": 1,
      "commits_count": 1,
      "review_count": 1,
      "comment_count": 2,
      "pr_size": 1,
      "avg_commit_msg_length": 56.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {
        "COMMENTED": 1
      },
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\nThis PR adds support for using BLIP and GIT models with the `image-to-text` pipeline.\r\n\r\nBoth model types already had underlying compatibility in `ImageToTextPipeline`, but they were not formally registered in `SUPPORTED_TASKS`, which prevented `pipeline(..., model=\"Salesforce/blip-image-captioning-base\")` from working directly.\r\n\r\n### Changes:\r\n- Updated `SUPPORTED_TASKS[\"image-to-text\"][\"pt\"]` to include `\"blip\"` and `\"git\"` model types.\r\n\r\n### Motivation:\r\nThis enables easier access to popular models like BLIP and GIT via the pipeline interface, improving usability for multimodal captioning tasks.\r\n\r\n---\r\n\r\nFixes: #21110 \r\n\r\n## Before submitting\r\n- [x] I’ve tested the change locally with BLIP models and it works correctly.\r\n- [x] I’ve read the [contributor guidelines](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request).\r\n\r\n## Who can review?\r\n\r\n@Rocketknight1 @zucchini-nlp (for visual-language model pipelines)",
      "body_cleaned_length": 992,
      "template_removed_length": 2,
      "template_reduction_percentage": 0.2012072434607646,
      "author_type": "User"
    },
    "username": "mayankdhingra02"
  },
  {
    "pr_number": 38031,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 37333,
        "labels": [
          "bug",
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 38031,
      "title": "Fix: Use deep copy for bbox_embed layers when decoder_bbox_embed_share is False",
      "body": "# What does this PR do?\r\n\r\nThis PR fixes a bug in the `GroundingDino` model implementation related to how the `bbox_embed` layers are instantiated when `decoder_bbox_embed_share=False`.\r\n\r\nIn the previous code, the same `GroundingDinoMLPPredictionHead` instance was reused across decoder layers, resulting in a shallow copy. This behavior is unintended when `decoder_bbox_embed_share` is set to `False`, as each decoder layer should have its own unique prediction head.\r\n\r\nThe fix ensures a deep copy by creating a new instance of the `GroundingDinoMLPPredictionHead` for each decoder layer.\r\n\r\nFixes #37333\r\n\r\n## Motivation\r\n\r\nThis bug prevents proper support for models like `LLMDet`, which rely on separate bbox prediction heads per decoder layer. Fixing this improves extensibility and aligns with expected behavior.\r\n\r\n## Before submitting\r\n\r\n- [x] I have read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request).\r\n- [x] This PR was discussed in Issue #37333.\r\n- [x] I’ve made the necessary code changes in `modeling_grounding_dino.py`.\r\n- [x] This fix improves model compatibility with `LLMDet` variants.\r\n\r\n## Who can review?\r\n\r\nVision models: @qubvel, @NielsRogge\r\n",
      "body_length": 1063,
      "created_at": "2025-05-08T23:57:35Z",
      "updated_at": "2025-05-09T00:00:31Z",
      "closed_at": "2025-05-09T00:00:31Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 8,
      "deletions": 5,
      "files_changed": 1,
      "commits_count": 1,
      "review_count": 0,
      "comment_count": 1,
      "pr_size": 13,
      "avg_commit_msg_length": 79.0,
      "has_conventional_commits": true,
      "conventional_commit_ratio": 1.0,
      "commit_types": [
        "fix"
      ],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 1
      },
      "review_states": {},
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "# What does this PR do?\r\n\r\nThis PR fixes a bug in the `GroundingDino` model implementation related to how the `bbox_embed` layers are instantiated when `decoder_bbox_embed_share=False`.\r\n\r\nIn the previous code, the same `GroundingDinoMLPPredictionHead` instance was reused across decoder layers, resulting in a shallow copy. This behavior is unintended when `decoder_bbox_embed_share` is set to `False`, as each decoder layer should have its own unique prediction head.\r\n\r\nThe fix ensures a deep copy by creating a new instance of the `GroundingDinoMLPPredictionHead` for each decoder layer.\r\n\r\nFixes #37333\r\n\r\n## Motivation\r\n\r\nThis bug prevents proper support for models like `LLMDet`, which rely on separate bbox prediction heads per decoder layer. Fixing this improves extensibility and aligns with expected behavior.\r\n\r\n## Before submitting\r\n\r\n- [x] I have read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request).\r\n- [x] This PR was discussed in Issue #37333.\r\n- [x] I’ve made the necessary code changes in `modeling_grounding_dino.py`.\r\n- [x] This fix improves model compatibility with `LLMDet` variants.\r\n\r\n## Who can review?\r\n\r\nVision models: @qubvel, @NielsRogge",
      "body_cleaned_length": 1240,
      "template_removed_length": 2,
      "template_reduction_percentage": 0.1610305958132045,
      "author_type": "User"
    },
    "username": "byteakp"
  },
  {
    "pr_number": 38502,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 36978,
        "labels": [
          "Good First Issue",
          "Good Second Issue",
          "Vision",
          "contributions-welcome",
          "Processing"
        ]
      }
    ],
    "pr_data": {
      "number": 38502,
      "title": "Add fast imageprocessor vitpose",
      "body": "Adding Fast Image processor for VitPose\r\nFixes #36978 \r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [X] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [X] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n@yonigozlan ",
      "body_length": 556,
      "created_at": "2025-05-31T02:49:59Z",
      "updated_at": "2025-08-01T16:22:39Z",
      "closed_at": "2025-08-01T16:22:39Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 1112,
      "deletions": 106,
      "files_changed": 16,
      "commits_count": 4,
      "review_count": 0,
      "comment_count": 1,
      "pr_size": 1218,
      "avg_commit_msg_length": 22.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": true,
      "has_docs": true,
      "test_files": [
        "tests/models/vitpose/test_image_processing_vitpose.py"
      ],
      "doc_files": [
        "docs/source/en/model_doc/vitpose.md"
      ],
      "file_types": {
        "gitignore": 1,
        "md": 1,
        "py": 4,
        "ps1": 1,
        "bat": 2,
        "exe": 5,
        "cfg": 1
      },
      "review_states": {},
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "Adding Fast Image processor for VitPose\r\nFixes #36978 \r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [X] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [X] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\n@yonigozlan",
      "body_cleaned_length": 916,
      "template_removed_length": 1,
      "template_reduction_percentage": 0.10905125408942204,
      "author_type": "User"
    },
    "username": "AnimeshMaheshwari22"
  },
  {
    "pr_number": 38626,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 28180,
        "labels": [
          "Good First Issue"
        ]
      }
    ],
    "pr_data": {
      "number": 38626,
      "title": "fix: Added code to match interpolation of Google's ViT implementation…",
      "body": "Fixes #28180\r\n\r\n# What does this PR do?\r\n\r\nFixes the interpolation method in ViT image processors to match the original Google ViT implementation. Changes the default resampling from BILINEAR to BICUBIC interpolation.\r\n\r\n## Implementation Notes\r\n\r\nThis implementation follows @NielsRogge's comments from #28180:\r\n- Added pixel value verification using `torch.allclose` similar to the DINOv2 conversion  \r\n- Verification ensures HuggingFace preprocessing matches the reference implementation\r\n- DeiT verification is currently skipped with `pass` - can be updated in a follow-up PR if needed\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n## Who can review?\r\n\r\n@NielsRogge @amyeroberts @qubvel \r\n",
      "body_length": 1084,
      "created_at": "2025-06-05T23:04:14Z",
      "updated_at": "2025-06-07T11:31:57Z",
      "closed_at": null,
      "merged_at": null,
      "merged": false,
      "state": "OPEN",
      "time_to_merge_hours": null,
      "additions": 57,
      "deletions": 9,
      "files_changed": 4,
      "commits_count": 3,
      "review_count": 0,
      "comment_count": 6,
      "pr_size": 66,
      "avg_commit_msg_length": 46.666666666666664,
      "has_conventional_commits": true,
      "conventional_commit_ratio": 0.6666666666666666,
      "commit_types": [
        "fix",
        "style"
      ],
      "has_tests": false,
      "has_docs": false,
      "test_files": [],
      "doc_files": [],
      "file_types": {
        "py": 4
      },
      "review_states": {},
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [
        {
          "name": "Vision",
          "color": "C079EF",
          "description": ""
        }
      ],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "Fixes #28180\r\n\r\n# What does this PR do?\r\n\r\nFixes the interpolation method in ViT image processors to match the original Google ViT implementation. Changes the default resampling from BILINEAR to BICUBIC interpolation.\r\n\r\n## Implementation Notes\r\n\r\nThis implementation follows @NielsRogge's comments from #28180:\r\n- Added pixel value verification using `torch.allclose` similar to the DINOv2 conversion  \r\n- Verification ensures HuggingFace preprocessing matches the reference implementation\r\n- DeiT verification is currently skipped with `pass` - can be updated in a follow-up PR if needed\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [x] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [x] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n## Who can review?\r\n\r\n@NielsRogge @amyeroberts @qubvel",
      "body_cleaned_length": 1468,
      "template_removed_length": 3,
      "template_reduction_percentage": 0.20394289598912305,
      "author_type": "User"
    },
    "username": "lerolynn"
  },
  {
    "pr_number": 39046,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 37939,
        "labels": [
          "Good First Issue",
          "Vision"
        ]
      }
    ],
    "pr_data": {
      "number": 39046,
      "title": "Fix deprecated max_size parameter handling in DETR image processors",
      "body": "Fixes #37939\r\n\r\nThe deprecated max_size parameter was incorrectly overriding the size parameter completely instead of being properly handled. This affected both ConditionalDetrImageProcessor and DetrImageProcessor.\r\n\r\nChanges:\r\n- Fixed __init__ method to properly handle max_size parameter by setting longest_edge when size dict doesn't have it, instead of replacing size\r\n- Fixed preprocess method to handle max_size parameter correctly\r\n- Added max_size as explicit parameter to __init__ for proper from_dict support\r\n- Added comprehensive tests for max_size parameter handling\r\n\r\nThe fix ensures backward compatibility while properly deprecating the max_size parameter in favor of size['longest_edge'].\r\n\r\n# What does this PR do?\r\n\r\n<!--\r\nCongratulations! You've made it this far! You're not quite done yet though.\r\n\r\nOnce merged, your PR is going to appear in the release notes with the title you set, so make sure it's a great title that fully reflects the extent of your awesome contribution.\r\n\r\nThen, please replace this with a description of the change and which issue is fixed (if applicable). Please also include relevant motivation and context. List any dependencies (if any) that are required for this change.\r\n\r\nOnce you're done, someone will review your PR shortly (see the section \"Who can review?\" below to tag some potential reviewers). They may suggest changes to make the code even better. If no one reviewed your PR after a week has passed, don't hesitate to post a new comment @-mentioning the same persons---sometimes notifications get lost.\r\n-->\r\n\r\n<!-- Remove if not applicable -->\r\n\r\nFixes # (issue)\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- text models: @ArthurZucker\r\n- vision models: @amyeroberts, @qubvel\r\n- speech models: @eustlb\r\n- graph models: @clefourrier\r\n\r\nLibrary:\r\n\r\n- flax: @gante and @Rocketknight1\r\n- generate: @zucchini-nlp (visual-language models) or @gante (all others)\r\n- pipelines: @Rocketknight1\r\n- tensorflow: @gante and @Rocketknight1\r\n- tokenizers: @ArthurZucker\r\n- trainer: @zach-huggingface, @SunMarc and @qgallouedec\r\n- chat templates: @Rocketknight1\r\n\r\nIntegrations:\r\n\r\n- deepspeed: HF Trainer/Accelerate: @SunMarc @zach-huggingface\r\n- ray/raytune: @richardliaw, @amogkam\r\n- Big Model Inference: @SunMarc\r\n- quantization (bitsandbytes, autogpt): @SunMarc @MekkCyber\r\n\r\nDocumentation: @stevhliu\r\n\r\nHF projects:\r\n\r\n- accelerate: [different repo](https://github.com/huggingface/accelerate)\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- diffusers: [different repo](https://github.com/huggingface/diffusers)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nMaintained examples (not research project or legacy):\r\n\r\n- Flax: @Rocketknight1\r\n- PyTorch: See Models above and tag the person corresponding to the modality of the example.\r\n- TensorFlow: @Rocketknight1\r\n\r\n -->\r\n",
      "body_length": 1359,
      "created_at": "2025-06-26T00:06:34Z",
      "updated_at": "2025-06-27T10:01:22Z",
      "closed_at": null,
      "merged_at": null,
      "merged": false,
      "state": "OPEN",
      "time_to_merge_hours": null,
      "additions": 2319,
      "deletions": 106,
      "files_changed": 10,
      "commits_count": 6,
      "review_count": 0,
      "comment_count": 2,
      "pr_size": 2425,
      "avg_commit_msg_length": 437.1666666666667,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": true,
      "has_docs": false,
      "test_files": [
        "test_fix_verification.py",
        "tests/models/conditional_detr/test_image_processing_conditional_detr.py"
      ],
      "doc_files": [],
      "file_types": {
        "py": 9,
        "backup": 1
      },
      "review_states": {},
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "Fixes #37939\r\n\r\nThe deprecated max_size parameter was incorrectly overriding the size parameter completely instead of being properly handled. This affected both ConditionalDetrImageProcessor and DetrImageProcessor.\r\n\r\nChanges:\r\n- Fixed __init__ method to properly handle max_size parameter by setting longest_edge when size dict doesn't have it, instead of replacing size\r\n- Fixed preprocess method to handle max_size parameter correctly\r\n- Added max_size as explicit parameter to __init__ for proper from_dict support\r\n- Added comprehensive tests for max_size parameter handling\r\n\r\nThe fix ensures backward compatibility while properly deprecating the max_size parameter in favor of size['longest_edge'].\r\n\r\n# What does this PR do?\r\n\r\n\r\n\r\n\r\n\r\nFixes # (issue)\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.",
      "body_cleaned_length": 1759,
      "template_removed_length": 2346,
      "template_reduction_percentage": 57.14981729598051,
      "author_type": "User"
    },
    "username": "nck90"
  },
  {
    "pr_number": 39113,
    "pr_type": "newcomer",
    "referenced_gfi_issues": [
      {
        "issue_number": 36979,
        "labels": [
          "Good First Issue",
          "Good First Documentation Issue",
          "contributions-welcome"
        ]
      }
    ],
    "pr_data": {
      "number": 39113,
      "title": "Improve Code Llama documentation with explanations and helpful links",
      "body": "## What does this PR do?\r\n\r\nImproves the Code Llama model documentation following the standardized format outlined in #36979.\r\n\r\n## Changes Made\r\n- ✅ Added explanatory comments to code examples explaining imports and parameters\r\n- ✅ Added \"Quick Links\" section with popular Code Llama models on HuggingFace Hub  \r\n- ✅ Included additional resources (paper links, model collection)\r\n- ✅ Improved accessibility for beginners learning to use Code Llama\r\n\r\n## Before and After\r\n**Before**: Basic code examples without explanations\r\n**After**: Commented code that teaches users what each line does + easy access to models\r\n\r\nFixes #36979\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.\r\n\r\n<!-- Your PR will be replied to more quickly if you can figure out the right person to tag with @\r\n\r\n If you know how to use git blame, that is the easiest way, otherwise, here is a rough guide of **who to tag**.\r\n Please tag fewer than 3 people.\r\n\r\nModels:\r\n\r\n- text models: @ArthurZucker\r\n- vision models: @amyeroberts, @qubvel\r\n- speech models: @eustlb\r\n- graph models: @clefourrier\r\n\r\nLibrary:\r\n\r\n- flax: @gante and @Rocketknight1\r\n- generate: @zucchini-nlp (visual-language models) or @gante (all others)\r\n- pipelines: @Rocketknight1\r\n- tensorflow: @gante and @Rocketknight1\r\n- tokenizers: @ArthurZucker\r\n- trainer: @zach-huggingface, @SunMarc and @qgallouedec\r\n- chat templates: @Rocketknight1\r\n\r\nIntegrations:\r\n\r\n- deepspeed: HF Trainer/Accelerate: @SunMarc @zach-huggingface\r\n- ray/raytune: @richardliaw, @amogkam\r\n- Big Model Inference: @SunMarc\r\n- quantization (bitsandbytes, autogpt): @SunMarc @MekkCyber\r\n\r\nDocumentation: @stevhliu\r\n\r\nHF projects:\r\n\r\n- accelerate: [different repo](https://github.com/huggingface/accelerate)\r\n- datasets: [different repo](https://github.com/huggingface/datasets)\r\n- diffusers: [different repo](https://github.com/huggingface/diffusers)\r\n- rust tokenizers: [different repo](https://github.com/huggingface/tokenizers)\r\n\r\nMaintained examples (not research project or legacy):\r\n\r\n- Flax: @Rocketknight1\r\n- PyTorch: See Models above and tag the person corresponding to the modality of the example.\r\n- TensorFlow: @Rocketknight1\r\n\r\n -->\r\n",
      "body_length": 1229,
      "created_at": "2025-06-29T22:23:27Z",
      "updated_at": "2025-06-30T14:38:43Z",
      "closed_at": "2025-06-30T14:38:43Z",
      "merged_at": null,
      "merged": false,
      "state": "CLOSED",
      "time_to_merge_hours": null,
      "additions": 20,
      "deletions": 6,
      "files_changed": 1,
      "commits_count": 1,
      "review_count": 0,
      "comment_count": 1,
      "pr_size": 26,
      "avg_commit_msg_length": 60.0,
      "has_conventional_commits": false,
      "conventional_commit_ratio": 0.0,
      "commit_types": [],
      "has_tests": false,
      "has_docs": true,
      "test_files": [],
      "doc_files": [
        "docs/source/en/model_doc/code_llama.md"
      ],
      "file_types": {
        "md": 1
      },
      "review_states": {},
      "has_changes_requested": false,
      "has_approved": false,
      "labels": [],
      "label_categories": [],
      "is_bug_fix": false,
      "is_feature": false,
      "is_documentation": false,
      "is_refactor": false,
      "priority_level": null,
      "difficulty_level": null,
      "body_cleaned": "## What does this PR do?\r\n\r\nImproves the Code Llama model documentation following the standardized format outlined in #36979.\r\n\r\n## Changes Made\r\n- ✅ Added explanatory comments to code examples explaining imports and parameters\r\n- ✅ Added \"Quick Links\" section with popular Code Llama models on HuggingFace Hub  \r\n- ✅ Included additional resources (paper links, model collection)\r\n- ✅ Improved accessibility for beginners learning to use Code Llama\r\n\r\n## Before and After\r\n**Before**: Basic code examples without explanations\r\n**After**: Commented code that teaches users what each line does + easy access to models\r\n\r\nFixes #36979\r\n\r\n\r\n## Before submitting\r\n- [ ] This PR fixes a typo or improves the docs (you can dismiss the other checks if that's the case).\r\n- [ ] Did you read the [contributor guideline](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md#create-a-pull-request),\r\n      Pull Request section?\r\n- [ ] Was this discussed/approved via a Github issue or the [forum](https://discuss.huggingface.co/)? Please add a link\r\n      to it if that's the case.\r\n- [ ] Did you make sure to update the documentation with your changes? Here are the\r\n      [documentation guidelines](https://github.com/huggingface/transformers/tree/main/docs), and\r\n      [here are tips on formatting docstrings](https://github.com/huggingface/transformers/tree/main/docs#writing-source-documentation).\r\n- [ ] Did you write any new necessary tests?\r\n\r\n\r\n## Who can review?\r\n\r\nAnyone in the community is free to review the PR once the tests have passed. Feel free to tag\r\nmembers/contributors who may be interested in your PR.",
      "body_cleaned_length": 1631,
      "template_removed_length": 1481,
      "template_reduction_percentage": 47.58997429305913,
      "author_type": "User"
    },
    "username": "PrakyathMC"
  }
]